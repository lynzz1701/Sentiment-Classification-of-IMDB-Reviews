{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43070e6e",
   "metadata": {},
   "source": [
    "### Sentiment Classification of IMDB Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d40e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82785d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n",
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.experimental.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26154498",
   "metadata": {},
   "source": [
    "## 1. Text Classification\n",
    "\n",
    "### (a) Data Exploration and Pre-processing\n",
    "#### Use binary encoding for the sentiments , y = 1 for positive sentiments and y = âˆ’1 for negative sentiments.\n",
    "\n",
    "- Note: we are using y = 1 for pos and y = 0 for neg instead, cuz Sigmoid is used a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80eed6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1400 files belonging to 2 classes.\n",
      "Found 600 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_train = keras.preprocessing.text_dataset_from_directory(\n",
    "    \"data/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=None,\n",
    "    validation_split=None,\n",
    "    #shuffle=False,\n",
    "    class_names=[\"neg_train\",\"pos_train\"]\n",
    ")\n",
    "raw_test = keras.preprocessing.text_dataset_from_directory(\n",
    "    \"data/test\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    batch_size=None,\n",
    "    validation_split=None,\n",
    "    #shuffle=False,\n",
    "    class_names=[\"neg_test\",\"pos_test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab8f3a",
   "metadata": {},
   "source": [
    "#### Remove the punctuation and numbers from the data.\n",
    "- Realized by RegEx replace (string methods of tf)\n",
    "\n",
    "#### Use text files 0-699 in each class for training and 700-999 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fcbeeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample output after regex:\n",
      " every year every year at the festival i wait for that film to come along that one that just pulls me out of my seat sticks its face up next to my nose and roars sur prise into my bewildered visage it s almost always a surprise it sure as niflheim was this time amazing grace and chuck is being advertised as a modern fairy tale of a boy in montana who quits his little league team for a very unusual reason and in the hands of anyone less careful than the creative staff of this film it might very well be nothing more than a fairy tale where we roll our eyes occasionally smirk to ourselves and maybe get a forced tear out of the eyes and a boy i wish that could happen sigh out of the lips upon exiting the theater and tossing the empty pepsi cup into the trash another e t another short circuit this film floored me for the simple reason that while it has a fairy tale concept the rest of the film takes itself seriously enough and presents itself well enough to make it more of an american folk tale with characters who are both icons and real people at the same time america has always had its mythical heros its paul bunyans and john waynes this film presents us with more general but still universal ideals the honest innocent children who have their own inner wisdom the athletes who seem to be amalgamations of courage honor and love for their respective sport the venerable elected official who leads with kindness and understanding but has the grit to get things done when they need doin does the latter sound familiar amazing grace and chuck is a showcase for these characters but it never leaves you with the feeling that it s artificial that it stands behind glass or that any sharp breeze or more importantly sharp thought will shatter the wax facade of the panorama this is a very sturdy scenario the principals are always given dialogue and always give performances always it just blows me away which made them seem real yet enforces their particular mythic role the writer producer david field seems to literally take all the yeah but in real life this would have happen thoughts you get in your head sticks them in the movie and uses them to bend the plot around to his original heading in a stronger way then before astounding he uses obstacles to the plot to enforce it i am truly impressed indeed envious with the skill in which he wrote the story and screenplay it s so very unusual especially in a hollywood film i don t want to give too much away but the basic premise is that chuck joshua zuehlke the little league pitcher decides to give up baseball because of nuclear weapons his decision begins an unlikely series of events that involve another athlete a boston basketball player alex english amazing grace smith and well i m leaving it at that because i wouldn t spoil this film for you for the world let me just say this though i am not recommending this film because i think it has a great message or because of any political positions it might imply i don t give a rat s ass for the political point of view this film expresses one way or another i m recommending you go see this film because and only because it s an excellent story told with excellence no i don t believe what happens in this film could happen in real life while i tend to believe the arms control policy of this country is stilted i believe in careful negotiations mutual verification etc screw what i think the point is this film is able to suspend my disbelief and tell a story that is one of the most finely crafted pieces of american dream i have ever seen on the movie screen this is the natural and more all the mythic qualities without the pretentiousness or the forced feeling of the conclusion and a much better script to boot it carried me into the beliefs and ideals of my boyhood and more importantly without any bumps or jolts that would snap me out of the trance with some hint of self consciousness special kudos to both zuehlke a real life little league pitcher who was picked for the part and english a forward for the denver nuggets for their seamless personification of their characters jamie lee curtis who takes a surprisingly small role and makes it exceedingly memorable as amazing s manager and friend william l peterson in a big change from his role in to live and die in l a as a father who shows principles without having to stand up and wave a flag doing it and gregory peck as the guy we wish ronald reagan really was and who some numbskulls still probably think he is\n"
     ]
    }
   ],
   "source": [
    "def regex(text):\n",
    "    tmp = tf.strings.strip(tf.strings.regex_replace(tf.strings.regex_replace(text,'[[:^alpha:]]', ' '),' +', ' '))\n",
    "    return tmp\n",
    "\n",
    "raw_train_list = list(raw_train)\n",
    "raw_test_list = list(raw_test)\n",
    "\n",
    "#tensor list\n",
    "train_X_list = list(map(lambda x: regex(x[0]), raw_train_list))\n",
    "train_y_list = list(map(lambda x: x[1], raw_train_list))\n",
    "test_X_list = list(map(lambda x: regex(x[0]), raw_test_list))\n",
    "test_y_list = list(map(lambda x: x[1], raw_test_list))\n",
    "\n",
    "#pure utf-8 text list\n",
    "train_X = [d.numpy().decode('utf-8') for d in train_X_list]\n",
    "test_X = [d.numpy().decode('utf-8') for d in test_X_list]\n",
    "\n",
    "#numpy array targets\n",
    "train_y = np.array(train_y_list)\n",
    "test_y = np.array(test_y_list)\n",
    "\n",
    "print(\"sample output after regex:\\n\", train_X[717])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846786c",
   "metadata": {},
   "source": [
    "#### Count the number of unique words in the whole dataset (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042c40e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set alone:\n",
      "    number of unique words: 33688\n",
      "    number of words (length): 927742\n",
      "test set alone:\n",
      "    number of unique words: 23687\n",
      "    number of words (length): 403530\n",
      "train + test:\n",
      "    number of unique words: 38911\n",
      "    number of words (length): 1331272\n"
     ]
    }
   ],
   "source": [
    "def unique_word_count(dataset):\n",
    "    t = keras.preprocessing.text.Tokenizer()\n",
    "    t.fit_on_texts(dataset)\n",
    "    print(\"    number of unique words:\", len(t.word_counts))\n",
    "    print(\"    number of words (length):\", sum(t.word_counts.values()))\n",
    "\n",
    "print(\"train set alone:\")\n",
    "unique_word_count(train_X)\n",
    "print(\"test set alone:\")\n",
    "unique_word_count(test_X)\n",
    "print(\"train + test:\")\n",
    "unique_word_count(train_X + test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff44c7",
   "metadata": {},
   "source": [
    "#### Calculate the average review length and the standard deviation of review lengths. \n",
    "\n",
    "#### Plot the histogram of review lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d95daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set alone:\n",
      "    average review length: 662.6728571428572\n",
      "    std of review lengths: 293.8986124603559\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set alone:\n",
      "    average review length: 672.55\n",
      "    std of review lengths: 292.98901145492357\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train + test:\n",
      "    average review length: 665.636\n",
      "    std of review lengths: 293.66091245516486\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_len_list(dataset):\n",
    "    len_list = []\n",
    "    for text in dataset:\n",
    "        t = keras.preprocessing.text.Tokenizer()\n",
    "        t.fit_on_texts([text])\n",
    "        len_list.append(sum(t.word_counts.values()))\n",
    "    mean_std(len_list)\n",
    "    len_hist(len_list)\n",
    "    return len_list\n",
    "\n",
    "def mean_std(len_list):\n",
    "    mean = np.mean(len_list)\n",
    "    std = np.std(len_list)\n",
    "    print(\"    average review length:\", mean)\n",
    "    print(\"    std of review lengths:\", std)\n",
    "    \n",
    "def len_hist(len_list):\n",
    "    plt.hist(len_list)\n",
    "    plt.xlabel(\"Length\")\n",
    "    plt.ylabel(\"#counts\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"train set alone:\")\n",
    "train_len_list = get_len_list(train_X)\n",
    "print(\"test set alone:\")\n",
    "test_len_list = get_len_list(test_X)\n",
    "print(\"train + test:\")\n",
    "whole_len_list = get_len_list(train_X + test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4901b3",
   "metadata": {},
   "source": [
    "#### Tokenization.\n",
    "- Note: EACH text sample is tokernized separately here, they each formed a dictionary of their own vocabulary. \n",
    "- However, to fit the model we'll need a dictionary of the whole training set, see different implementation in function get_sequences( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d1f7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing train set...\n",
      "  sample output:\n",
      " {'a': 1, 'the': 2, 'of': 3, 'to': 4, 'in': 5, 'dance': 6, 'it': 7, 'shall': 8, 'we': 9, 'and': 10, 'with': 11, 's': 12, 'sugiyama': 13, 'is': 14, 'his': 15, 'as': 16, 'story': 17, 'up': 18, 'suo': 19, 'which': 20, 'be': 21, 'its': 22, 'he': 23, 'school': 24, 'her': 25, 'that': 26, 'rather': 27, 'an': 28, 'you': 29, 't': 30, 'japanese': 31, 'koji': 32, 'yakusho': 33, 'one': 34, 'when': 35, 'mai': 36, 'by': 37, 'for': 38, 'dancing': 39, 'wife': 40, 'becomes': 41, 'on': 42, 'hollywood': 43, 'film': 44, 'can': 45, 'into': 46, 'comedy': 47, 'matter': 48, 'than': 49, 'does': 50, 'some': 51, 'new': 52, 'personalities': 53, 'most': 54, 'small': 55, 'steps': 56, 'feel': 57, 'good': 58, 'formulaic': 59, 'may': 60, 'own': 61, 'way': 62, 'also': 63, 'demonstrates': 64, 'kind': 65, 'charming': 66, 'restraint': 67, 'don': 68, 'often': 69, 'find': 70, 'american': 71, 'films': 72, 'this': 73, 'import': 74, 'tells': 75, 'middle': 76, 'aged': 77, 'accountant': 78, 'named': 79, 'whose': 80, 'mundane': 81, 'life': 82, 'shaken': 83, 'night': 84, 'spots': 85, 'beautiful': 86, 'kishikawa': 87, 'tamiyo': 88, 'kusakari': 89, 'window': 90, 'intrigued': 91, 'melancholy': 92, 'demeanor': 93, 'slightly': 94, 'infatuated': 95, 'signs': 96, 'weekly': 97, 'classes': 98, 'at': 99, 'much': 100, 'amazement': 101, 'ends': 102, 'attracted': 103, 'itself': 104, 'young': 105, 'sensei': 106, 'meanwhile': 107, 'hideko': 108, 'hara': 109, 'suspicious': 110, 'late': 111, 'wednesday': 112, 'nights': 113, 'sets': 114, 'private': 115, 'detective': 116, 'husband': 117, 'trail': 118, 'bet': 119, 'sub': 120, 'plot': 121, 'would': 122, 'turned': 123, 'stream': 124, 'slapstick': 125, 'crazy': 126, 'misunderstandings': 127, 'writer': 128, 'director': 129, 'masayuki': 130, 'dispenses': 131, 'minutes': 132, 'using': 133, 'set': 134, 'later': 135, 'character': 136, 'interactions': 137, 'letting': 138, 'overwhelm': 139, 'pratfalls': 140, 'neither': 141, 'make': 142, 'climactic': 143, 'moment': 144, 'victory': 145, 'competition': 146, 'between': 147, 'hero': 148, 'mean': 149, 'spirited': 150, 'token': 151, 'rival': 152, 'gives': 153, 'graceful': 154, 'movements': 155, 'subject': 156, 'allowing': 157, 'humor': 158, 'flow': 159, 'from': 160, 'characters': 161, 'forcing': 162, 'upon': 163, 'them': 164, 'opening': 165, 'prologue': 166, 'goes': 167, 'effort': 168, 'place': 169, 'sociological': 170, 'perspective': 171, 'explaining': 172, 'how': 173, 'contrary': 174, 'ballroom': 175, 'sense': 176, 'propriety': 177, 'forced': 178, 'message': 179, 'doesn': 180, 'need': 181, 'such': 182, 'culture': 183, 'specific': 184, 'angle': 185, 'plays': 186, 'role': 187, 'singles': 188, 'mixer': 189, 'everyone': 190, 'vaguely': 191, 'embarrassed': 192, 'there': 193, 'yet': 194, 'taking': 195, 'opportunity': 196, 'try': 197, 'amusing': 198, 'among': 199, 'these': 200, 'adopted': 201, 'co': 202, 'worker': 203, 'mr': 204, 'aoki': 205, 'naoto': 206, 'takenaka': 207, 'balding': 208, 'systems': 209, 'analyst': 210, 'who': 211, 'fiery': 212, 'latin': 213, 'lover': 214, 'dons': 215, 'frizzy': 216, 'wig': 217, 'begins': 218, 'rumba': 219, 'awakening': 220, 'less': 221, 'overt': 222, 'but': 223, 'wonderful': 224, 'job': 225, 'showing': 226, 'transformation': 227, 'delicate': 228, 'performance': 229, 'huge': 230, 'heart': 231, 'fairly': 232, 'lightweight': 233, 'experience': 234, 'makes': 235, 'final': 236, 'half': 237, 'hour': 238, 'long': 239, 'sit': 240, 'crams': 241, 'lot': 242, 'exposition': 243, 'very': 244, 'little': 245, 'time': 246, 'including': 247, 'unnecessarily': 248, 'detailed': 249, 'back': 250, 'resulting': 251, 'sluggish': 252, 'march': 253, 'towards': 254, 'resolution': 255, 'here': 256, 'feels': 257, 'conventional': 258, 'attempting': 259, 'blind': 260, 'side': 261, 'audience': 262, 'truckload': 263, 'emotional': 264, 'catharsis': 265, 'might': 266, 'have': 267, 'been': 268, 'better': 269, 'advised': 270, 'conclude': 271, 'gem': 272, 'scene': 273, 'take': 274, 'their': 275, 'first': 276, 'tentative': 277, 'together': 278, 'real': 279, 'joy': 280, 'conveys': 281, 'ability': 282, 'create': 283, 'intoxicating': 284, 'mood': 285, 'romance': 286, 'soften': 287, 'stiffest': 288, 'shirt': 289}\n",
      "\n",
      "tockenizing test set...\n",
      "  sample output:\n",
      " {'the': 1, 'to': 2, 'and': 3, 'is': 4, 'a': 5, 'it': 6, 'for': 7, 'of': 8, 'on': 9, 'in': 10, 'be': 11, 'end': 12, 'they': 13, 's': 14, 'film': 15, 'i': 16, 'world': 17, 'know': 18, 'but': 19, 'people': 20, 'are': 21, 'some': 22, 'do': 23, 'just': 24, 'that': 25, 't': 26, 'or': 27, 'has': 28, 'all': 29, 'their': 30, 'them': 31, 'sun': 32, 'don': 33, 'why': 34, 'no': 35, 'this': 36, 'as': 37, 'have': 38, 'toronto': 39, 'final': 40, 'mckellar': 41, 'characters': 42, 'last': 43, 'night': 44, 'earth': 45, 'gas': 46, 'will': 47, 'very': 48, 'by': 49, 'even': 50, 'up': 51, 'you': 52, 'not': 53, 'moments': 54, 'from': 55, 'home': 56, 'never': 57, 'at': 58, 'midnight': 59, 'still': 60, 'street': 61, 'over': 62, 'well': 63, 'll': 64, 'damned': 65, 'canadians': 66, 'can': 67, 'make': 68, 'good': 69, 'movie': 70, 'coming': 71, 'an': 72, 'we': 73, 'how': 74, 'apparently': 75, 'there': 76, 'way': 77, 'stop': 78, 'had': 79, 'information': 80, 'months': 81, 'most': 82, 'rioting': 83, 'other': 84, 'assorted': 85, 'chaos': 86, 'passed': 87, 'governments': 88, 'shut': 89, 'down': 90, 'operations': 91, 'yet': 92, 'handful': 93, 'citizens': 94, 'life': 95, 'goes': 96, 'aren': 97, 'going': 98, 'crazy': 99, 'attacking': 100, 'streets': 101, 'instead': 102, 'simply': 103, 'preparing': 104, 'themselves': 105, 'engaging': 106, 'activities': 107, 've': 108, 'always': 109, 'wanted': 110, 'gathering': 111, 'with': 112, 'family': 113, 'friends': 114, 'others': 115, 'seeking': 116, 'alone': 117, 'these': 118, 'lives': 119, 'however': 120, 'intersect': 121, 'during': 122, 'six': 123, 'hours': 124, 'writer': 125, 'director': 126, 'star': 127, 'crafted': 128, 'highly': 129, 'unique': 130, 'emotional': 131, 'main': 132, 'compelling': 133, 'try': 134, 'whatever': 135, 'need': 136, 'craig': 137, 'callum': 138, 'keith': 139, 'rennie': 140, 'tries': 141, 'fulfill': 142, 'his': 143, 'sexual': 144, 'fantasies': 145, 'company': 146, 'employee': 147, 'david': 148, 'cronenberg': 149, 'calls': 150, 'every': 151, 'customer': 152, 'letting': 153, 'flowing': 154, 'until': 155, 'thanks': 156, 'business': 157, 'patrick': 158, 'wants': 159, 'himself': 160, 'isn': 161, 'having': 162, 'much': 163, 'success': 164, 'minor': 165, 'keep': 166, 'popping': 167, 'where': 168, 'least': 169, 'expect': 170, 'tying': 171, 'everyone': 172, 'closer': 173, 'things': 174, 'seemed': 175, 'little': 176, 'hokey': 177, 'towards': 178, 'beginning': 179, 'ultimately': 180, 'everything': 181, 'comes': 182, 'together': 183, 'nicely': 184, 'although': 185, 'happy': 186, 'understandably': 187, 'gut': 188, 'wrenching': 189, 'story': 190, 'enhanced': 191, 'unexpected': 192, 'humor': 193, 'realistic': 194, 'performances': 195, 'particularly': 196, 'sandra': 197, 'oh': 198, 'whose': 199, 'character': 200, 'trying': 201, 'get': 202, 'her': 203, 'husband': 204, 'before': 205, 'absolutely': 206, 'problem': 207, 'reason': 208, 'given': 209, 'nor': 210, 'does': 211, 'bother': 212, 'me': 213, 'ending': 214, 'exactly': 215, 'anyway': 216, 'wonder': 217, 'sets': 218, 'come': 219, 'shining': 220, 'brightly': 221, 'maybe': 222, 'crashing': 223, 'into': 224, 'who': 225, 'knows': 226, 'also': 227, 'comforting': 228, 'mankind': 229, 'planet': 230, 'gang': 231, 'sheer': 232, 'purpose': 233, 'pushing': 234, 'car': 235, 'bus': 236, 'shot': 237, 'mind': 238, 'stupid': 239, 'truly': 240, 'would': 241, 'out': 242, 'tipping': 243, 'cars': 244, 'available': 245, 'dvd': 246, 'universal': 247, 'video': 248, 'contains': 249, 'fullscreen': 250, 'format': 251, 'includes': 252, 'original': 253, 'theatrical': 254, 'trailer': 255, 'r': 256}\n"
     ]
    }
   ],
   "source": [
    "def get_popularity(dataset):\n",
    "    word_index_list = []\n",
    "    for text in dataset:\n",
    "        t = keras.preprocessing.text.Tokenizer()\n",
    "        t.fit_on_texts([text])\n",
    "        #print(sorted(t.word_counts.values()))\n",
    "        #print(t.word_index)\n",
    "        word_index_list.append(t.word_index)\n",
    "    return word_index_list\n",
    "    \n",
    "print(\"tokenizing train set...\")\n",
    "train_ranks_list = get_popularity(train_X)\n",
    "print(\"  sample output:\\n\", train_ranks_list[615])\n",
    "print(\"\\ntockenizing test set...\")\n",
    "test_ranks_list = get_popularity(test_X)\n",
    "print(\"  sample output:\\n\", test_ranks_list[13])\n",
    "#print(\"tokenizing train + test ...\")\n",
    "#train_ranks_list = get_popularity(train_X+test_X)\n",
    "#print(\"-- freq rank list:\", train_ranks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1726a5",
   "metadata": {},
   "source": [
    "#### Select a review length L:  70% and 90% of the reviews have a length below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3983b7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% L = 753\n",
      "90% L = 1018\n"
     ]
    }
   ],
   "source": [
    "def decide_l(len_list, q):\n",
    "    return np.percentile(len_list, q)\n",
    "    \n",
    "L_70 = int(decide_l(train_len_list,70))\n",
    "print(\"70% L =\", L_70)\n",
    "L_90 = int(decide_l(train_len_list,90))\n",
    "print(\"90% L =\", L_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3975546",
   "metadata": {},
   "source": [
    "#### Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c50bc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "shape of output: (2000, 753)\n",
      "-- 90% L --\n",
      "shape of output: (2000, 1018)\n",
      "\n",
      "  sample output:\n",
      " [ 5115     6     2  2515   476     4    46    54   601    47    30   489\n",
      "     5  5656     2    25   949  1283     2   259    89   232   117  8358\n",
      " 12944     6    60  2959     5    16   247  4168   801   145     5   121\n",
      " 18954    11     1  2976 11821  4949  5670   349    11  4643  4436     2\n",
      "  1006  6243 12306    13     2  8439   272    31     2  4158 19120   143\n",
      "    18  1521     1 11153     4    14  1889  5838   831 31854   375 11513\n",
      "     7     1  7545   516     4   161    18    54  1671     7    14  2253\n",
      "    26  8930  1827 31855    23     2 31856     3    65     4    38     2\n",
      "  2399   218     5   135    58    45     7   193  4643    36     5   141\n",
      "    31   503  2666   322     5    87   511   588    19    39   160    24\n",
      "     2   688    31     1   131     4    10  4209    18  2129    45    11\n",
      "     2   344  7491  2121     7     2 31857  4274   403    23     1  3508\n",
      "     8   668 31858  2150 13341    11     2   596    14  2929    21 14528\n",
      " 31859   700    14  7492  2832    18   584   227     7   747  3796     4\n",
      "     1   272  4746    10    39   160    24    52 31860   387   222     5\n",
      "   247  2024  2929  2316  4949  5670   196    16   182    31   395 20902\n",
      "   693   775   908  4160  3548     4  1512   338     1   333     6  1170\n",
      "    33     2   148  2359  1432  3492    39     8    29    71    10     8\n",
      "   180   123     1    15    36     9     8    25  1178  2436     3 20293\n",
      "    41     1   328     4    66  1464    12   237   485 12110   338    39\n",
      "   599   477    22    71   325   318    57     1    93     1   337   272\n",
      "  6372  1659     6   326  1041    17   568   169     1  4616    20  1838\n",
      " 21353  4892    55     1   337   272     6   162     5   199   146     5\n",
      "     2   594 12051  6412  9274     3     6    16     1    61   272   115\n",
      "  3361     5 12873  9356    16 12755     5   253     9   901  5115    90\n",
      "   489     5   811     2  4415   949    12  4643     8  4881   846 31861\n",
      "  1330  9937   617    18     6   448     5    24 31862    19     1    15\n",
      "   111    90   234    12    58   828    58     7     2 14767  6220   482\n",
      "     1    28    14  8204   120    12  4643   143    76  1062     2  1551\n",
      "     3  1628   566     3   101    39     8     1   130   607    48     6\n",
      "   257  9263  6590  1257  1516    40    16    25     7    16   310     1\n",
      "  3714     4  4643     8 31863     6 18335 10844  2029     2  1223  1172\n",
      "    27   418    22    34   234     5    76    12  4643   290    18  6848\n",
      "    14  2024  2929  3611     5   189     1   786     6   326  7888     3\n",
      "  1241    94     5     1    15    16     6     2    15    10  2061  1166\n",
      "   134   346    24    10     2    64    93    44   533    49   322  3471\n",
      "   820    49     2   550    72    49    79   234    69    34  2275  5115\n",
      "    73    92     1  1110    11     9     6    38     1  4215 10387  8761\n",
      "     7     1   137    54    22   266  4949  5670    73    16    25    92\n",
      "     1  1110     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "def get_sequences(dataset):\n",
    "    t = keras.preprocessing.text.Tokenizer()\n",
    "    t.fit_on_texts(dataset[:1400]) #only fit on train\n",
    "    return t.texts_to_sequences(dataset)\n",
    "\n",
    "def truncating_n_padding(dataset, l):\n",
    "    sequences = get_sequences(dataset)\n",
    "    return keras.preprocessing.sequence.pad_sequences(sequences, truncating='pre', padding='post', maxlen=l)\n",
    "\n",
    "#truncating = 'post'\n",
    "#padding = 'post'\n",
    "\n",
    "padded_70 = truncating_n_padding(train_X+test_X, L_70)\n",
    "padded_90 = truncating_n_padding(train_X+test_X, L_90)\n",
    "print(\"-- 70% L --\")\n",
    "print(\"shape of output:\", padded_70.shape)\n",
    "print(\"-- 90% L --\")\n",
    "print(\"shape of output:\", padded_90.shape)\n",
    "\n",
    "train_padded_70 = padded_70[:1400]\n",
    "#print(train_padded_70.shape)\n",
    "test_padded_70 = padded_70[1400:]\n",
    "#print(test_padded_70.shape)\n",
    "\n",
    "train_padded_90 = padded_90[:1400]\n",
    "test_padded_90 = padded_90[1400:]\n",
    "\n",
    "print(\"\\n  sample output:\\n\", padded_70[1212])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fb2728",
   "metadata": {},
   "source": [
    "### (b) Word Embeddings\n",
    "#### We are interested in the top 5,000 words and 7,000 words.\n",
    "- This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000/7,000 words in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bc082b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "shape of output: (2000, 753, 32)\n",
      "-- 90% L --\n",
      "shape of output: (2000, 1018, 32)\n",
      "\n",
      "  sample output:\n",
      " [[-0.00756687 -0.04414221  0.0088793  ...  0.00858375  0.03821745\n",
      "  -0.0171473 ]\n",
      " [-0.02984439  0.01097547  0.02475737 ...  0.03875841 -0.00260548\n",
      "  -0.03710032]\n",
      " [-0.03138181  0.04057566  0.04692687 ... -0.0238717  -0.01298435\n",
      "  -0.02215447]\n",
      " ...\n",
      " [ 0.01682469 -0.03046727 -0.01494098 ...  0.03729475  0.04902737\n",
      "  -0.03780967]\n",
      " [-0.00019054  0.00159942  0.0235624  ...  0.03436607 -0.01965669\n",
      "   0.03088603]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def embedding(padded_text, top_words):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(top_words, 32))\n",
    "    model.compile('rmsprop', 'mse')\n",
    "    output_array = model.predict(padded_text)\n",
    "    print(\"shape of output:\", output_array.shape)\n",
    "    return output_array\n",
    "\n",
    "print(\"-- 70% L --\")\n",
    "embedded_70 = embedding(padded_70, 5000)\n",
    "print(\"-- 90% L --\")\n",
    "embedded_90 = embedding(padded_90, 5000)\n",
    "\n",
    "print(\"\\n  sample output:\\n\", embedded_70[502])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199e095",
   "metadata": {},
   "source": [
    "#### Flatten the matrix of each document to a vector.\n",
    "- the whole implementation of (c)i & (c)ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ff5b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "shape of output: (2000, 24096)\n",
      "-- 90% L --\n",
      "shape of output: (2000, 32576)\n",
      "\n",
      "  sample output:\n",
      " [-0.00756687 -0.04414221  0.0088793  ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "def embedding_n_flattening(padded_text, top_words):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Embedding(top_words, 32))\n",
    "    model.add(layers.Flatten())\n",
    "    model.compile('rmsprop', 'mse')\n",
    "    output_array = model.predict(padded_text)\n",
    "    print(\"shape of output:\", output_array.shape)\n",
    "    return output_array\n",
    "\n",
    "print(\"-- 70% L --\")\n",
    "embedded_flatten_70 = embedding_n_flattening(padded_70, 5000)\n",
    "print(\"-- 90% L --\")\n",
    "embedded_flatten_90 = embedding_n_flattening(padded_90, 5000)\n",
    "\n",
    "print(\"\\n  sample output:\\n\", embedded_flatten_70[502])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b5b7a",
   "metadata": {},
   "source": [
    "### (c) Multi-Layer Perceptron\n",
    "#### Train a MLP with three (dense) hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Use a dropout rate of 20% for the first layer and 50% for the other layers. Use ADAM optimizer and binary cross entropy loss (which is equivalent to having a softmax in the output). To avoid overfitting, set the number of epochs as 2. Use a batch size of 10.\n",
    "- for both 70%L and 90%L, epoch = 2 yielded their best results with a accuracy of about 60%-70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe533ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start...\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 753, 32)           160000    \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 24096)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                1204850   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,370,001\n",
      "Trainable params: 1,370,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 3s 16ms/step - loss: 0.6938 - binary_accuracy: 0.5207\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 2s 14ms/step - loss: 0.5992 - binary_accuracy: 0.6486\n",
      "\n",
      "  -- train set accuracy --\n",
      "140/140 [==============================] - 0s 3ms/step - loss: 0.2610 - binary_accuracy: 0.9493\n",
      "  -- test set accuracy --\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_accuracy: 0.6533\n",
      "\n",
      "-- 90% L --\n",
      "training start...\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 1018, 32)          160000    \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 32576)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                1628850   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,794,001\n",
      "Trainable params: 1,794,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "140/140 [==============================] - 4s 23ms/step - loss: 0.7030 - binary_accuracy: 0.5043\n",
      "Epoch 2/2\n",
      "140/140 [==============================] - 3s 22ms/step - loss: 0.5630 - binary_accuracy: 0.7157\n",
      "\n",
      "  -- train set accuracy --\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.1718 - binary_accuracy: 0.9693\n",
      "  -- test set accuracy --\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6082 - binary_accuracy: 0.6483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6081604957580566, 0.6483333706855774]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mlp(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(5000, 32),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_mlp(train_X, train_y, l, epoch):\n",
    "    print(\"training start...\")\n",
    "    model = create_mlp(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    return model\n",
    "    \n",
    "print(\"-- 70% L --\")\n",
    "mlp_70 = fit_train_mlp(train_padded_70, train_y, L_70, 2)\n",
    "print(\"\\n  -- train set accuracy --\")\n",
    "mlp_70.evaluate(train_padded_70, train_y, batch_size=10)\n",
    "print(\"  -- test set accuracy --\")\n",
    "mlp_70.evaluate(test_padded_70, test_y, batch_size=10)\n",
    "print(\"\\n-- 90% L --\")\n",
    "mlp_90 = fit_train_mlp(train_padded_90, train_y, L_90, 2)\n",
    "print(\"\\n  -- train set accuracy --\")\n",
    "mlp_90.evaluate(train_padded_90, train_y, batch_size=10)\n",
    "print(\"  -- test set accuracy --\")\n",
    "mlp_90.evaluate(test_padded_90, test_y, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390a273",
   "metadata": {},
   "source": [
    "### (d) One-Dimensional Convolutional Neural Network\n",
    "#### Although CNNs are mainly used for image data, they can also be applied to text data, as text also has adjacency information. Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively.\n",
    "#### After the embedding layer, insert a Conv1D layer. This convolutional layer has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded word representations 3 vector elements of the word embedding at a time. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above.\n",
    "- epoch = 3 seemed to work better with this CNN setting. accuracies of 70-80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b9ffc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start...\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 753, 32)           160000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 751, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 368, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 11776)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 50)                588850    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 757,105\n",
      "Trainable params: 757,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "140/140 [==============================] - 3s 15ms/step - loss: 0.7004 - binary_accuracy: 0.4943\n",
      "Epoch 2/3\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 0.6846 - binary_accuracy: 0.5407\n",
      "Epoch 3/3\n",
      "140/140 [==============================] - 2s 13ms/step - loss: 0.5316 - binary_accuracy: 0.7393\n",
      "\n",
      "  -- train set accuracy --\n",
      "140/140 [==============================] - 1s 3ms/step - loss: 0.2149 - binary_accuracy: 0.9564\n",
      "  -- test set accuracy --\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5596 - binary_accuracy: 0.7083\n",
      "\n",
      "-- 90% L --\n",
      "training start...\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 1018, 32)          160000    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1016, 32)          3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 501, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 16032)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 50)                801650    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 969,905\n",
      "Trainable params: 969,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "140/140 [==============================] - 3s 18ms/step - loss: 0.6990 - binary_accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 0.6697 - binary_accuracy: 0.5971\n",
      "Epoch 3/3\n",
      "140/140 [==============================] - 2s 15ms/step - loss: 0.4358 - binary_accuracy: 0.8143\n",
      "\n",
      "  -- train set accuracy --\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.2136 - binary_accuracy: 0.9621\n",
      "  -- test set accuracy --\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.4784 - binary_accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4784056842327118, 0.7850000262260437]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_cnn(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(5000, 32),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=16, strides=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_cnn(train_X, train_y, l, epoch):\n",
    "    print(\"training start...\")\n",
    "    model = create_cnn(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    return model\n",
    "    \n",
    "print(\"-- 70% L --\")\n",
    "cnn_70 = fit_train_cnn(train_padded_70, train_y, L_70, 3)\n",
    "print(\"\\n  -- train set accuracy --\")\n",
    "cnn_70.evaluate(train_padded_70, train_y, batch_size=10)\n",
    "print(\"  -- test set accuracy --\")\n",
    "cnn_70.evaluate(test_padded_70, test_y, batch_size=10)\n",
    "print(\"\\n-- 90% L --\")\n",
    "cnn_90 = fit_train_cnn(train_padded_90, train_y, L_90, 3)\n",
    "print(\"\\n  -- train set accuracy --\")\n",
    "cnn_90.evaluate(train_padded_90, train_y, batch_size=10)\n",
    "print(\"  -- test set accuracy --\")\n",
    "cnn_90.evaluate(test_padded_90, test_y, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd59b2",
   "metadata": {},
   "source": [
    "### (e) Long Short-Term Memory Recurrent Neural Network\n",
    "####  Each word is represented to LSTM as a vector of 32 elements and the LSTM is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both LSTM and the dense layer. Train the model using 10-50 epochs and batch size of 10.\n",
    "\n",
    "Summary:\n",
    "- try 1: LSTM units = 256, best accuracy = 58% when epoch = 44 (epoch range 10-50)\n",
    "- try 2: LSTM units = 32, best accuracy = 61% when epoch = 23 (epoch range 10-50)\n",
    "- try 3: top_words = 20,000, accuracy = 55% (epoch = 10)\n",
    "- try 4: top_words = #unique_words, accuracy = 60% (epoch = 10)\n",
    "- try 5: remove stopwords, best accuracy = 57% when epoch = 15 (epoch set to 15 & 25)\n",
    "- try 6: slower learning rate = 0.0001, best accuracy = 76% when epoch = 8 (epoch set to 8 & 12)\n",
    "- try 7: BRNN , best accuracy = 78% when epoch = 12 (epoch set to 7 & 12-24)\n",
    "\n",
    "Adjustments that brought improvement:\n",
    "- Bigger Vocabulary \n",
    "- Stopwords Removal\n",
    "- Slower Learning Rate\n",
    "- BRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f559d48c",
   "metadata": {},
   "source": [
    "-- try 1: LSTM layer units set to 256 --\n",
    "- accuracy didn't increase between epochs, and test accu didn't hit 60% eventually (epoch range 10-50)\n",
    "- The model basically learned nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eecd716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(5000, 32),\n",
    "        layers.LSTM(256),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch, validation_split=0.2)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b28118ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start... epochs = 10\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 35s 224ms/step - loss: 0.6920 - binary_accuracy: 0.5384 - val_loss: 0.6926 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.6857 - binary_accuracy: 0.5688 - val_loss: 0.6905 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.6512 - binary_accuracy: 0.6250 - val_loss: 0.7152 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5816 - binary_accuracy: 0.6554 - val_loss: 0.8869 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 41s 368ms/step - loss: 0.5455 - binary_accuracy: 0.6562 - val_loss: 0.9146 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 78s 694ms/step - loss: 0.4974 - binary_accuracy: 0.6759 - val_loss: 0.9518 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 22s 197ms/step - loss: 0.4843 - binary_accuracy: 0.6777 - val_loss: 1.0517 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 22s 197ms/step - loss: 0.4816 - binary_accuracy: 0.6768 - val_loss: 1.0633 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 22s 198ms/step - loss: 0.4864 - binary_accuracy: 0.6777 - val_loss: 0.9392 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.4828 - binary_accuracy: 0.6777 - val_loss: 1.0594 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5958 - binary_accuracy: 0.6450\n",
      "60/60 [==============================] - 6s 103ms/step - loss: 1.1237 - binary_accuracy: 0.5250\n",
      "training start... epochs = 11\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_24 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/11\n",
      "112/112 [==============================] - 35s 223ms/step - loss: 0.6975 - binary_accuracy: 0.5312 - val_loss: 0.6893 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/11\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6825 - binary_accuracy: 0.5518 - val_loss: 0.6993 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/11\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.6857 - binary_accuracy: 0.5973 - val_loss: 0.7212 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/11\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.6084 - binary_accuracy: 0.6393 - val_loss: 0.7692 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.5736 - binary_accuracy: 0.6536 - val_loss: 0.8236 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.5400 - binary_accuracy: 0.6696 - val_loss: 0.8166 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.5013 - binary_accuracy: 0.6598 - val_loss: 1.0031 - val_binary_accuracy: 0.5286\n",
      "Epoch 8/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.4928 - binary_accuracy: 0.6750 - val_loss: 0.9794 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.4920 - binary_accuracy: 0.6750 - val_loss: 1.1038 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/11\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.4833 - binary_accuracy: 0.6732 - val_loss: 1.0868 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/11\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.4887 - binary_accuracy: 0.6768 - val_loss: 0.8910 - val_binary_accuracy: 0.5000\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5758 - binary_accuracy: 0.6400\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 0.8496 - binary_accuracy: 0.5483\n",
      "training start... epochs = 12\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "112/112 [==============================] - 35s 227ms/step - loss: 0.6933 - binary_accuracy: 0.5179 - val_loss: 0.6897 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/12\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.7661 - binary_accuracy: 0.5080 - val_loss: 0.7016 - val_binary_accuracy: 0.4893\n",
      "Epoch 3/12\n",
      "112/112 [==============================] - 23s 201ms/step - loss: 0.7135 - binary_accuracy: 0.4911 - val_loss: 0.6926 - val_binary_accuracy: 0.5429\n",
      "Epoch 4/12\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.7004 - binary_accuracy: 0.5143 - val_loss: 0.7062 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/12\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.6866 - binary_accuracy: 0.5295 - val_loss: 0.6902 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/12\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.6677 - binary_accuracy: 0.5723 - val_loss: 0.6952 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/12\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.6305 - binary_accuracy: 0.6214 - val_loss: 0.7172 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/12\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.6011 - binary_accuracy: 0.6179 - val_loss: 0.7265 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/12\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.5881 - binary_accuracy: 0.6054 - val_loss: 0.7523 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/12\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.5564 - binary_accuracy: 0.6518 - val_loss: 0.7655 - val_binary_accuracy: 0.5179\n",
      "Epoch 11/12\n",
      "112/112 [==============================] - 23s 201ms/step - loss: 0.5407 - binary_accuracy: 0.6598 - val_loss: 0.8295 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/12\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.5351 - binary_accuracy: 0.6420 - val_loss: 0.8198 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.5885 - binary_accuracy: 0.6407\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.8345 - binary_accuracy: 0.5517\n",
      "training start... epochs = 13\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/13\n",
      "112/112 [==============================] - 36s 231ms/step - loss: 0.7097 - binary_accuracy: 0.5304 - val_loss: 0.6899 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/13\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6765 - binary_accuracy: 0.5696 - val_loss: 0.6939 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/13\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.6130 - binary_accuracy: 0.6357 - val_loss: 0.7557 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/13\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.5409 - binary_accuracy: 0.6634 - val_loss: 0.8607 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/13\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5228 - binary_accuracy: 0.6366 - val_loss: 0.8058 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/13\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5020 - binary_accuracy: 0.6652 - val_loss: 0.8543 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/13\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.4857 - binary_accuracy: 0.6759 - val_loss: 1.0766 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/13\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.5099 - binary_accuracy: 0.6652 - val_loss: 0.9516 - val_binary_accuracy: 0.4929\n",
      "Epoch 9/13\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.4893 - binary_accuracy: 0.6812 - val_loss: 0.8961 - val_binary_accuracy: 0.5071\n",
      "Epoch 10/13\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.4850 - binary_accuracy: 0.6804 - val_loss: 1.1225 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/13\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.4813 - binary_accuracy: 0.6741 - val_loss: 1.1628 - val_binary_accuracy: 0.5071\n",
      "Epoch 12/13\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4817 - binary_accuracy: 0.6839 - val_loss: 0.9194 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/13\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.4877 - binary_accuracy: 0.6768 - val_loss: 1.2267 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6289 - binary_accuracy: 0.6479\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.2277 - binary_accuracy: 0.5133\n",
      "training start... epochs = 14\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_27 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/14\n",
      "112/112 [==============================] - 35s 228ms/step - loss: 0.7254 - binary_accuracy: 0.4875 - val_loss: 0.7333 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/14\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.7352 - binary_accuracy: 0.5089 - val_loss: 0.6930 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/14\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.7107 - binary_accuracy: 0.4911 - val_loss: 0.7071 - val_binary_accuracy: 0.4893\n",
      "Epoch 4/14\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.7015 - binary_accuracy: 0.5188 - val_loss: 0.6967 - val_binary_accuracy: 0.4893\n",
      "Epoch 5/14\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6967 - binary_accuracy: 0.5143 - val_loss: 0.6911 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/14\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6784 - binary_accuracy: 0.5527 - val_loss: 0.6982 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/14\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.6559 - binary_accuracy: 0.5821 - val_loss: 0.7102 - val_binary_accuracy: 0.5107\n",
      "Epoch 8/14\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.6351 - binary_accuracy: 0.6018 - val_loss: 0.7023 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/14\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.5974 - binary_accuracy: 0.5964 - val_loss: 0.7622 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/14\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.5945 - binary_accuracy: 0.6152 - val_loss: 0.7364 - val_binary_accuracy: 0.5250\n",
      "Epoch 11/14\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.5765 - binary_accuracy: 0.6473 - val_loss: 0.7599 - val_binary_accuracy: 0.5107\n",
      "Epoch 12/14\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5530 - binary_accuracy: 0.6705 - val_loss: 0.9453 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 23s 201ms/step - loss: 0.5225 - binary_accuracy: 0.6527 - val_loss: 0.9882 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/14\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.5359 - binary_accuracy: 0.6545 - val_loss: 0.6913 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6633 - binary_accuracy: 0.6000\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 0.6905 - binary_accuracy: 0.5233\n",
      "training start... epochs = 15\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "112/112 [==============================] - 35s 229ms/step - loss: 0.6926 - binary_accuracy: 0.5268 - val_loss: 0.6904 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/15\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6803 - binary_accuracy: 0.5589 - val_loss: 0.7005 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.6406 - binary_accuracy: 0.6330 - val_loss: 0.7023 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5578 - binary_accuracy: 0.6598 - val_loss: 0.7965 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5144 - binary_accuracy: 0.6670 - val_loss: 0.8226 - val_binary_accuracy: 0.5286\n",
      "Epoch 6/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5117 - binary_accuracy: 0.6723 - val_loss: 0.9339 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4957 - binary_accuracy: 0.6804 - val_loss: 0.9162 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/15\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4880 - binary_accuracy: 0.6562 - val_loss: 1.1148 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4890 - binary_accuracy: 0.6750 - val_loss: 1.0109 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/15\n",
      "112/112 [==============================] - 22s 199ms/step - loss: 0.4959 - binary_accuracy: 0.6679 - val_loss: 0.8760 - val_binary_accuracy: 0.5071\n",
      "Epoch 11/15\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.4813 - binary_accuracy: 0.6777 - val_loss: 1.1778 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/15\n",
      "112/112 [==============================] - 23s 201ms/step - loss: 0.5155 - binary_accuracy: 0.6884 - val_loss: 0.8994 - val_binary_accuracy: 0.5214\n",
      "Epoch 13/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4815 - binary_accuracy: 0.6786 - val_loss: 1.0026 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/15\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.5538 - binary_accuracy: 0.6830 - val_loss: 0.9083 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/15\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5252 - binary_accuracy: 0.6821 - val_loss: 1.2425 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 1.2119 - binary_accuracy: 0.5000\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.2610 - binary_accuracy: 0.5000\n",
      "training start... epochs = 16\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "112/112 [==============================] - 35s 227ms/step - loss: 0.6925 - binary_accuracy: 0.5277 - val_loss: 0.6892 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/16\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.6621 - binary_accuracy: 0.5821 - val_loss: 0.7088 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/16\n",
      "112/112 [==============================] - 23s 204ms/step - loss: 0.6028 - binary_accuracy: 0.6446 - val_loss: 0.7253 - val_binary_accuracy: 0.5179\n",
      "Epoch 4/16\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.5516 - binary_accuracy: 0.6589 - val_loss: 0.7730 - val_binary_accuracy: 0.5214\n",
      "Epoch 5/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5496 - binary_accuracy: 0.6545 - val_loss: 0.8401 - val_binary_accuracy: 0.4750\n",
      "Epoch 6/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5020 - binary_accuracy: 0.6616 - val_loss: 0.8467 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4877 - binary_accuracy: 0.6732 - val_loss: 1.0034 - val_binary_accuracy: 0.5107\n",
      "Epoch 8/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5624 - binary_accuracy: 0.6714 - val_loss: 0.8882 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.7381 - binary_accuracy: 0.6750 - val_loss: 0.8186 - val_binary_accuracy: 0.4607\n",
      "Epoch 10/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.7013 - binary_accuracy: 0.4946 - val_loss: 0.6935 - val_binary_accuracy: 0.4893\n",
      "Epoch 11/16\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6932 - binary_accuracy: 0.5018 - val_loss: 0.6934 - val_binary_accuracy: 0.4893\n",
      "Epoch 12/16\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6931 - binary_accuracy: 0.5143 - val_loss: 0.6935 - val_binary_accuracy: 0.4893\n",
      "Epoch 13/16\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6926 - binary_accuracy: 0.5304 - val_loss: 0.6931 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/16\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.6937 - binary_accuracy: 0.4973 - val_loss: 0.6936 - val_binary_accuracy: 0.4893\n",
      "Epoch 15/16\n",
      "112/112 [==============================] - 22s 200ms/step - loss: 0.6931 - binary_accuracy: 0.5063 - val_loss: 0.6935 - val_binary_accuracy: 0.4893\n",
      "Epoch 16/16\n",
      "112/112 [==============================] - 23s 201ms/step - loss: 0.6924 - binary_accuracy: 0.5223 - val_loss: 0.6929 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 111ms/step - loss: 0.6930 - binary_accuracy: 0.5000\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 0.6933 - binary_accuracy: 0.5000\n",
      "training start... epochs = 17\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_30 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/17\n",
      "112/112 [==============================] - 35s 226ms/step - loss: 0.6949 - binary_accuracy: 0.5205 - val_loss: 0.6916 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/17\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.6766 - binary_accuracy: 0.5679 - val_loss: 0.7172 - val_binary_accuracy: 0.5071\n",
      "Epoch 3/17\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.6275 - binary_accuracy: 0.6393 - val_loss: 0.7246 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/17\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.5643 - binary_accuracy: 0.6652 - val_loss: 0.9950 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/17\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.5108 - binary_accuracy: 0.6598 - val_loss: 0.9330 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/17\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4898 - binary_accuracy: 0.6759 - val_loss: 1.1469 - val_binary_accuracy: 0.5143\n",
      "Epoch 7/17\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4911 - binary_accuracy: 0.6759 - val_loss: 1.0414 - val_binary_accuracy: 0.5107\n",
      "Epoch 8/17\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4799 - binary_accuracy: 0.6777 - val_loss: 1.4780 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/17\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.5188 - binary_accuracy: 0.6687 - val_loss: 0.9391 - val_binary_accuracy: 0.5143\n",
      "Epoch 10/17\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.4824 - binary_accuracy: 0.6732 - val_loss: 1.1830 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/17\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4831 - binary_accuracy: 0.6723 - val_loss: 1.0405 - val_binary_accuracy: 0.5179\n",
      "Epoch 12/17\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4817 - binary_accuracy: 0.6795 - val_loss: 0.9779 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/17\n",
      "112/112 [==============================] - 23s 203ms/step - loss: 0.4798 - binary_accuracy: 0.6759 - val_loss: 1.4245 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/17\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.4757 - binary_accuracy: 0.6875 - val_loss: 1.3378 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/17\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4843 - binary_accuracy: 0.6777 - val_loss: 1.2462 - val_binary_accuracy: 0.4893\n",
      "Epoch 16/17\n",
      "112/112 [==============================] - 23s 202ms/step - loss: 0.4759 - binary_accuracy: 0.6946 - val_loss: 1.1836 - val_binary_accuracy: 0.4964\n",
      "Epoch 17/17\n",
      "112/112 [==============================] - 22s 201ms/step - loss: 0.5024 - binary_accuracy: 0.6643 - val_loss: 1.1643 - val_binary_accuracy: 0.5071\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6185 - binary_accuracy: 0.6436\n",
      "60/60 [==============================] - 7s 108ms/step - loss: 1.1663 - binary_accuracy: 0.5400\n",
      "training start... epochs = 18\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "112/112 [==============================] - 36s 234ms/step - loss: 0.6963 - binary_accuracy: 0.5330 - val_loss: 0.6913 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/18\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6719 - binary_accuracy: 0.5759 - val_loss: 0.7172 - val_binary_accuracy: 0.5107\n",
      "Epoch 3/18\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.6042 - binary_accuracy: 0.6384 - val_loss: 0.8000 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/18\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5934 - binary_accuracy: 0.6518 - val_loss: 0.7962 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/18\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.5244 - binary_accuracy: 0.6661 - val_loss: 0.7799 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/18\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.5006 - binary_accuracy: 0.6714 - val_loss: 0.9026 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/18\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4827 - binary_accuracy: 0.6741 - val_loss: 1.0476 - val_binary_accuracy: 0.5107\n",
      "Epoch 8/18\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4840 - binary_accuracy: 0.6830 - val_loss: 0.9661 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/18\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4806 - binary_accuracy: 0.6795 - val_loss: 1.3223 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/18\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4850 - binary_accuracy: 0.6732 - val_loss: 1.0323 - val_binary_accuracy: 0.5179\n",
      "Epoch 11/18\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4809 - binary_accuracy: 0.6795 - val_loss: 1.2183 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/18\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.4798 - binary_accuracy: 0.6777 - val_loss: 1.0005 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/18\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4839 - binary_accuracy: 0.6759 - val_loss: 0.9075 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/18\n",
      "112/112 [==============================] - 23s 210ms/step - loss: 0.4805 - binary_accuracy: 0.6732 - val_loss: 1.1290 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/18\n",
      "112/112 [==============================] - 23s 206ms/step - loss: 0.4773 - binary_accuracy: 0.6714 - val_loss: 0.9720 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/18\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.4803 - binary_accuracy: 0.6768 - val_loss: 1.0670 - val_binary_accuracy: 0.5143\n",
      "Epoch 17/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4760 - binary_accuracy: 0.6804 - val_loss: 1.1398 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/18\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.4847 - binary_accuracy: 0.6839 - val_loss: 1.0598 - val_binary_accuracy: 0.5214\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5900 - binary_accuracy: 0.6529\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 1.0929 - binary_accuracy: 0.5600\n",
      "training start... epochs = 19\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_32 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/19\n",
      "112/112 [==============================] - 37s 240ms/step - loss: 0.6932 - binary_accuracy: 0.5268 - val_loss: 0.6910 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/19\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.6801 - binary_accuracy: 0.5598 - val_loss: 0.6987 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/19\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6141 - binary_accuracy: 0.6339 - val_loss: 0.7642 - val_binary_accuracy: 0.5071\n",
      "Epoch 4/19\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.5524 - binary_accuracy: 0.6634 - val_loss: 0.7870 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/19\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5105 - binary_accuracy: 0.6732 - val_loss: 0.7694 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/19\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4990 - binary_accuracy: 0.6643 - val_loss: 1.3602 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/19\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.5425 - binary_accuracy: 0.6705 - val_loss: 0.9052 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/19\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4842 - binary_accuracy: 0.6804 - val_loss: 1.0111 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/19\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.4901 - binary_accuracy: 0.6830 - val_loss: 0.9726 - val_binary_accuracy: 0.5036\n",
      "Epoch 10/19\n",
      "112/112 [==============================] - 23s 205ms/step - loss: 0.4803 - binary_accuracy: 0.6804 - val_loss: 1.0556 - val_binary_accuracy: 0.4893\n",
      "Epoch 11/19\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4766 - binary_accuracy: 0.6777 - val_loss: 1.0256 - val_binary_accuracy: 0.4893\n",
      "Epoch 12/19\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4817 - binary_accuracy: 0.6786 - val_loss: 0.9860 - val_binary_accuracy: 0.4893\n",
      "Epoch 13/19\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4742 - binary_accuracy: 0.6848 - val_loss: 1.1040 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/19\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4895 - binary_accuracy: 0.6777 - val_loss: 0.9746 - val_binary_accuracy: 0.4964\n",
      "Epoch 15/19\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4707 - binary_accuracy: 0.6884 - val_loss: 1.1125 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/19\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4889 - binary_accuracy: 0.6759 - val_loss: 0.9671 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/19\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4822 - binary_accuracy: 0.6830 - val_loss: 0.9959 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/19\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4751 - binary_accuracy: 0.6893 - val_loss: 0.9684 - val_binary_accuracy: 0.5214\n",
      "Epoch 19/19\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4900 - binary_accuracy: 0.6821 - val_loss: 1.0891 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6733 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 7s 110ms/step - loss: 1.1027 - binary_accuracy: 0.5400\n",
      "training start... epochs = 20\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 37s 242ms/step - loss: 0.7184 - binary_accuracy: 0.5357 - val_loss: 0.7386 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.7187 - binary_accuracy: 0.4982 - val_loss: 0.7104 - val_binary_accuracy: 0.4893\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.7002 - binary_accuracy: 0.4982 - val_loss: 0.6954 - val_binary_accuracy: 0.5107\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6974 - binary_accuracy: 0.4911 - val_loss: 0.6934 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.6938 - binary_accuracy: 0.4946 - val_loss: 0.7025 - val_binary_accuracy: 0.4893\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.6915 - binary_accuracy: 0.5250 - val_loss: 0.6911 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.6685 - binary_accuracy: 0.5973 - val_loss: 0.6999 - val_binary_accuracy: 0.4964\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.6127 - binary_accuracy: 0.6170 - val_loss: 0.7297 - val_binary_accuracy: 0.5214\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.5779 - binary_accuracy: 0.6330 - val_loss: 0.7511 - val_binary_accuracy: 0.5393\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.5575 - binary_accuracy: 0.6438 - val_loss: 0.7978 - val_binary_accuracy: 0.5321\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5290 - binary_accuracy: 0.6482 - val_loss: 0.8797 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5040 - binary_accuracy: 0.6482 - val_loss: 0.9799 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.8539 - binary_accuracy: 0.5670 - val_loss: 0.6921 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.6030 - binary_accuracy: 0.6313 - val_loss: 0.7416 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5658 - binary_accuracy: 0.6402 - val_loss: 0.8020 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.5372 - binary_accuracy: 0.6554 - val_loss: 0.8096 - val_binary_accuracy: 0.5036\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.5177 - binary_accuracy: 0.6429 - val_loss: 0.8601 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5004 - binary_accuracy: 0.6580 - val_loss: 0.9376 - val_binary_accuracy: 0.5250\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5012 - binary_accuracy: 0.6634 - val_loss: 0.8794 - val_binary_accuracy: 0.5071\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5184 - binary_accuracy: 0.6464 - val_loss: 0.8504 - val_binary_accuracy: 0.5000\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6102 - binary_accuracy: 0.6336\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.8259 - binary_accuracy: 0.5483\n",
      "training start... epochs = 21\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "112/112 [==============================] - 38s 246ms/step - loss: 0.6939 - binary_accuracy: 0.5134 - val_loss: 0.6904 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/21\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.6756 - binary_accuracy: 0.5589 - val_loss: 0.7010 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/21\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.6058 - binary_accuracy: 0.6384 - val_loss: 0.9253 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/21\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5733 - binary_accuracy: 0.6411 - val_loss: 0.7755 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/21\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5072 - binary_accuracy: 0.6571 - val_loss: 0.9200 - val_binary_accuracy: 0.4964\n",
      "Epoch 6/21\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4879 - binary_accuracy: 0.6759 - val_loss: 0.9553 - val_binary_accuracy: 0.4964\n",
      "Epoch 7/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4883 - binary_accuracy: 0.6759 - val_loss: 0.9870 - val_binary_accuracy: 0.4929\n",
      "Epoch 8/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4865 - binary_accuracy: 0.6750 - val_loss: 0.9255 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4822 - binary_accuracy: 0.6705 - val_loss: 1.2610 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.6865 - binary_accuracy: 0.6250 - val_loss: 0.7633 - val_binary_accuracy: 0.5179\n",
      "Epoch 11/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5394 - binary_accuracy: 0.6554 - val_loss: 0.8554 - val_binary_accuracy: 0.5107\n",
      "Epoch 12/21\n",
      "112/112 [==============================] - 23s 210ms/step - loss: 0.5036 - binary_accuracy: 0.6652 - val_loss: 0.9224 - val_binary_accuracy: 0.4964\n",
      "Epoch 13/21\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4892 - binary_accuracy: 0.6786 - val_loss: 1.0025 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/21\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4853 - binary_accuracy: 0.6589 - val_loss: 1.0711 - val_binary_accuracy: 0.4929\n",
      "Epoch 15/21\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4817 - binary_accuracy: 0.6804 - val_loss: 1.1383 - val_binary_accuracy: 0.4929\n",
      "Epoch 16/21\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4787 - binary_accuracy: 0.6812 - val_loss: 1.1879 - val_binary_accuracy: 0.5036\n",
      "Epoch 17/21\n",
      "112/112 [==============================] - 23s 207ms/step - loss: 0.4756 - binary_accuracy: 0.6848 - val_loss: 1.0171 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/21\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4874 - binary_accuracy: 0.6714 - val_loss: 1.1923 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/21\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4826 - binary_accuracy: 0.6786 - val_loss: 1.2864 - val_binary_accuracy: 0.5214\n",
      "Epoch 20/21\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4812 - binary_accuracy: 0.6812 - val_loss: 1.2603 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/21\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4848 - binary_accuracy: 0.6804 - val_loss: 1.4627 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6899 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.3023 - binary_accuracy: 0.5483\n",
      "training start... epochs = 22\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_35 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/22\n",
      "112/112 [==============================] - 37s 240ms/step - loss: 0.6934 - binary_accuracy: 0.5152 - val_loss: 0.6895 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/22\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.7691 - binary_accuracy: 0.5464 - val_loss: 0.6921 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/22\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6411 - binary_accuracy: 0.6098 - val_loss: 0.7061 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/22\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5725 - binary_accuracy: 0.6518 - val_loss: 0.8331 - val_binary_accuracy: 0.5286\n",
      "Epoch 5/22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 23s 210ms/step - loss: 0.6874 - binary_accuracy: 0.6402 - val_loss: 0.7359 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/22\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5162 - binary_accuracy: 0.6750 - val_loss: 0.8167 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/22\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4921 - binary_accuracy: 0.6732 - val_loss: 0.9184 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/22\n",
      "112/112 [==============================] - 23s 210ms/step - loss: 0.4888 - binary_accuracy: 0.6759 - val_loss: 0.9060 - val_binary_accuracy: 0.5143\n",
      "Epoch 9/22\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4880 - binary_accuracy: 0.6732 - val_loss: 1.0421 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/22\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4908 - binary_accuracy: 0.6795 - val_loss: 1.0362 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/22\n",
      "112/112 [==============================] - 23s 210ms/step - loss: 0.4792 - binary_accuracy: 0.6839 - val_loss: 1.0005 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4804 - binary_accuracy: 0.6679 - val_loss: 1.0727 - val_binary_accuracy: 0.5071\n",
      "Epoch 13/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.6982 - binary_accuracy: 0.6107 - val_loss: 0.8650 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/22\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.6251 - binary_accuracy: 0.6125 - val_loss: 0.7183 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.5656 - binary_accuracy: 0.6446 - val_loss: 0.7658 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.5201 - binary_accuracy: 0.6598 - val_loss: 0.8680 - val_binary_accuracy: 0.5143\n",
      "Epoch 17/22\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.5033 - binary_accuracy: 0.6616 - val_loss: 0.9158 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4895 - binary_accuracy: 0.6759 - val_loss: 1.0601 - val_binary_accuracy: 0.5250\n",
      "Epoch 19/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4888 - binary_accuracy: 0.6795 - val_loss: 1.1745 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.5248 - binary_accuracy: 0.6696 - val_loss: 0.9097 - val_binary_accuracy: 0.5393\n",
      "Epoch 21/22\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4855 - binary_accuracy: 0.6795 - val_loss: 0.9298 - val_binary_accuracy: 0.5393\n",
      "Epoch 22/22\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4784 - binary_accuracy: 0.6839 - val_loss: 1.0504 - val_binary_accuracy: 0.5429\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5892 - binary_accuracy: 0.6571\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.0625 - binary_accuracy: 0.5583\n",
      "training start... epochs = 23\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_36 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_26 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "112/112 [==============================] - 38s 244ms/step - loss: 0.6922 - binary_accuracy: 0.5152 - val_loss: 0.6898 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/23\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.6709 - binary_accuracy: 0.5625 - val_loss: 0.7102 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/23\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.6051 - binary_accuracy: 0.6393 - val_loss: 0.7160 - val_binary_accuracy: 0.4821\n",
      "Epoch 4/23\n",
      "112/112 [==============================] - 23s 210ms/step - loss: 0.5583 - binary_accuracy: 0.6652 - val_loss: 0.8343 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/23\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.5022 - binary_accuracy: 0.6696 - val_loss: 0.9297 - val_binary_accuracy: 0.5071\n",
      "Epoch 6/23\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4900 - binary_accuracy: 0.6741 - val_loss: 0.9868 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/23\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4896 - binary_accuracy: 0.6723 - val_loss: 1.0308 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/23\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4874 - binary_accuracy: 0.6750 - val_loss: 0.9147 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/23\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5062 - binary_accuracy: 0.6687 - val_loss: 1.0196 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/23\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4840 - binary_accuracy: 0.6750 - val_loss: 1.0562 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/23\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4822 - binary_accuracy: 0.6732 - val_loss: 1.2220 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/23\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4833 - binary_accuracy: 0.6804 - val_loss: 1.1267 - val_binary_accuracy: 0.5143\n",
      "Epoch 13/23\n",
      "112/112 [==============================] - 24s 210ms/step - loss: 0.4871 - binary_accuracy: 0.6741 - val_loss: 1.1430 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/23\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4813 - binary_accuracy: 0.6768 - val_loss: 1.2769 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/23\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4797 - binary_accuracy: 0.6768 - val_loss: 1.3689 - val_binary_accuracy: 0.5036\n",
      "Epoch 16/23\n",
      "112/112 [==============================] - 23s 209ms/step - loss: 0.4894 - binary_accuracy: 0.6679 - val_loss: 1.2937 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/23\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4794 - binary_accuracy: 0.6839 - val_loss: 1.2822 - val_binary_accuracy: 0.4929\n",
      "Epoch 18/23\n",
      "112/112 [==============================] - 23s 208ms/step - loss: 0.4922 - binary_accuracy: 0.6723 - val_loss: 0.8498 - val_binary_accuracy: 0.4786\n",
      "Epoch 19/23\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4917 - binary_accuracy: 0.6723 - val_loss: 1.1542 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/23\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.4809 - binary_accuracy: 0.6821 - val_loss: 1.2544 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/23\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4699 - binary_accuracy: 0.6875 - val_loss: 1.5318 - val_binary_accuracy: 0.5179\n",
      "Epoch 22/23\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4709 - binary_accuracy: 0.6857 - val_loss: 1.3800 - val_binary_accuracy: 0.5143\n",
      "Epoch 23/23\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4755 - binary_accuracy: 0.6804 - val_loss: 1.3047 - val_binary_accuracy: 0.4964\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6403 - binary_accuracy: 0.6486\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 1.3526 - binary_accuracy: 0.5250\n",
      "training start... epochs = 24\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_37 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      "112/112 [==============================] - 38s 246ms/step - loss: 0.6957 - binary_accuracy: 0.4973 - val_loss: 0.6918 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/24\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.7467 - binary_accuracy: 0.5607 - val_loss: 0.6919 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/24\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.6622 - binary_accuracy: 0.6000 - val_loss: 0.7058 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/24\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.7200 - binary_accuracy: 0.6241 - val_loss: 0.6962 - val_binary_accuracy: 0.4893\n",
      "Epoch 5/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.7259 - binary_accuracy: 0.4866 - val_loss: 0.7222 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/24\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.6976 - binary_accuracy: 0.5250 - val_loss: 0.6978 - val_binary_accuracy: 0.4929\n",
      "Epoch 7/24\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.6833 - binary_accuracy: 0.5589 - val_loss: 0.6917 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/24\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.6535 - binary_accuracy: 0.5964 - val_loss: 0.6986 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/24\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.6166 - binary_accuracy: 0.6205 - val_loss: 0.7777 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6014 - binary_accuracy: 0.6384 - val_loss: 0.7098 - val_binary_accuracy: 0.5071\n",
      "Epoch 11/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.6166 - binary_accuracy: 0.5991 - val_loss: 0.7322 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/24\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5760 - binary_accuracy: 0.6259 - val_loss: 0.7643 - val_binary_accuracy: 0.5071\n",
      "Epoch 13/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5547 - binary_accuracy: 0.6500 - val_loss: 0.8541 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5569 - binary_accuracy: 0.6420 - val_loss: 0.7737 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.6296 - binary_accuracy: 0.5911 - val_loss: 0.7134 - val_binary_accuracy: 0.5250\n",
      "Epoch 16/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5906 - binary_accuracy: 0.6107 - val_loss: 0.7711 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5687 - binary_accuracy: 0.6196 - val_loss: 0.8115 - val_binary_accuracy: 0.5036\n",
      "Epoch 18/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5522 - binary_accuracy: 0.6571 - val_loss: 0.8066 - val_binary_accuracy: 0.5036\n",
      "Epoch 19/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5535 - binary_accuracy: 0.6393 - val_loss: 0.7802 - val_binary_accuracy: 0.5214\n",
      "Epoch 20/24\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5314 - binary_accuracy: 0.6491 - val_loss: 0.8299 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5581 - binary_accuracy: 0.6643 - val_loss: 0.7770 - val_binary_accuracy: 0.5071\n",
      "Epoch 22/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5317 - binary_accuracy: 0.6643 - val_loss: 0.8563 - val_binary_accuracy: 0.5107\n",
      "Epoch 23/24\n",
      "112/112 [==============================] - 24s 211ms/step - loss: 0.5278 - binary_accuracy: 0.6455 - val_loss: 0.8434 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/24\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.5161 - binary_accuracy: 0.6616 - val_loss: 0.9196 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5831 - binary_accuracy: 0.6529\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.8659 - binary_accuracy: 0.5633\n",
      "training start... epochs = 25\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_38 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_28 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "112/112 [==============================] - 38s 249ms/step - loss: 0.7325 - binary_accuracy: 0.5143 - val_loss: 0.6939 - val_binary_accuracy: 0.4893\n",
      "Epoch 2/25\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.6899 - binary_accuracy: 0.5277 - val_loss: 0.6927 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/25\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.6400 - binary_accuracy: 0.6170 - val_loss: 0.6928 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/25\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.5954 - binary_accuracy: 0.6402 - val_loss: 0.7383 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/25\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.5373 - binary_accuracy: 0.6670 - val_loss: 0.7927 - val_binary_accuracy: 0.5214\n",
      "Epoch 6/25\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.5013 - binary_accuracy: 0.6786 - val_loss: 0.7959 - val_binary_accuracy: 0.5143\n",
      "Epoch 7/25\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.5049 - binary_accuracy: 0.6652 - val_loss: 0.9768 - val_binary_accuracy: 0.5071\n",
      "Epoch 8/25\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4916 - binary_accuracy: 0.6759 - val_loss: 0.8613 - val_binary_accuracy: 0.5214\n",
      "Epoch 9/25\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4830 - binary_accuracy: 0.6768 - val_loss: 1.1993 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/25\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4938 - binary_accuracy: 0.6759 - val_loss: 0.9083 - val_binary_accuracy: 0.5321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4881 - binary_accuracy: 0.6759 - val_loss: 1.0915 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4838 - binary_accuracy: 0.6821 - val_loss: 0.8932 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/25\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4857 - binary_accuracy: 0.6768 - val_loss: 1.3502 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4903 - binary_accuracy: 0.6804 - val_loss: 0.8524 - val_binary_accuracy: 0.5321\n",
      "Epoch 15/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4884 - binary_accuracy: 0.6661 - val_loss: 1.0521 - val_binary_accuracy: 0.4893\n",
      "Epoch 16/25\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4834 - binary_accuracy: 0.6821 - val_loss: 1.3956 - val_binary_accuracy: 0.4964\n",
      "Epoch 17/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.5693 - binary_accuracy: 0.6696 - val_loss: 1.0110 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/25\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4918 - binary_accuracy: 0.6759 - val_loss: 0.8903 - val_binary_accuracy: 0.4893\n",
      "Epoch 19/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4854 - binary_accuracy: 0.6741 - val_loss: 1.0280 - val_binary_accuracy: 0.4964\n",
      "Epoch 20/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4794 - binary_accuracy: 0.6786 - val_loss: 1.2155 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/25\n",
      "112/112 [==============================] - 24s 212ms/step - loss: 0.4771 - binary_accuracy: 0.6839 - val_loss: 1.3446 - val_binary_accuracy: 0.4964\n",
      "Epoch 22/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4866 - binary_accuracy: 0.6830 - val_loss: 0.8955 - val_binary_accuracy: 0.5286\n",
      "Epoch 23/25\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4937 - binary_accuracy: 0.6741 - val_loss: 0.9838 - val_binary_accuracy: 0.5286\n",
      "Epoch 24/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4845 - binary_accuracy: 0.6768 - val_loss: 1.2605 - val_binary_accuracy: 0.5036\n",
      "Epoch 25/25\n",
      "112/112 [==============================] - 24s 213ms/step - loss: 0.4803 - binary_accuracy: 0.6812 - val_loss: 1.0749 - val_binary_accuracy: 0.5286\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5990 - binary_accuracy: 0.6493\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1336 - binary_accuracy: 0.5333\n",
      "training start... epochs = 26\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_39 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/26\n",
      "112/112 [==============================] - 39s 262ms/step - loss: 0.6925 - binary_accuracy: 0.5286 - val_loss: 0.6927 - val_binary_accuracy: 0.5214\n",
      "Epoch 2/26\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.6771 - binary_accuracy: 0.5446 - val_loss: 0.7020 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/26\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.7178 - binary_accuracy: 0.6036 - val_loss: 0.6878 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/26\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.6203 - binary_accuracy: 0.6241 - val_loss: 0.7257 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/26\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5835 - binary_accuracy: 0.6464 - val_loss: 0.7624 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/26\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.5515 - binary_accuracy: 0.6687 - val_loss: 0.8354 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/26\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5209 - binary_accuracy: 0.6670 - val_loss: 0.9127 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/26\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4963 - binary_accuracy: 0.6723 - val_loss: 0.9576 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/26\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4830 - binary_accuracy: 0.6786 - val_loss: 1.0147 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4735 - binary_accuracy: 0.6929 - val_loss: 1.0577 - val_binary_accuracy: 0.5286\n",
      "Epoch 11/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4821 - binary_accuracy: 0.6795 - val_loss: 1.0021 - val_binary_accuracy: 0.5464\n",
      "Epoch 12/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4776 - binary_accuracy: 0.6821 - val_loss: 1.1039 - val_binary_accuracy: 0.5429\n",
      "Epoch 13/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4909 - binary_accuracy: 0.6768 - val_loss: 1.1340 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4848 - binary_accuracy: 0.6768 - val_loss: 1.1378 - val_binary_accuracy: 0.5107\n",
      "Epoch 15/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4799 - binary_accuracy: 0.6955 - val_loss: 1.2896 - val_binary_accuracy: 0.5036\n",
      "Epoch 16/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4757 - binary_accuracy: 0.6670 - val_loss: 1.2732 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/26\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4782 - binary_accuracy: 0.6830 - val_loss: 1.2764 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4792 - binary_accuracy: 0.6625 - val_loss: 1.1258 - val_binary_accuracy: 0.4964\n",
      "Epoch 19/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4815 - binary_accuracy: 0.6857 - val_loss: 1.3214 - val_binary_accuracy: 0.5036\n",
      "Epoch 20/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4745 - binary_accuracy: 0.6884 - val_loss: 1.2779 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4997 - binary_accuracy: 0.6786 - val_loss: 1.1408 - val_binary_accuracy: 0.5321\n",
      "Epoch 22/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.5025 - binary_accuracy: 0.6661 - val_loss: 1.4730 - val_binary_accuracy: 0.5321\n",
      "Epoch 23/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4950 - binary_accuracy: 0.6661 - val_loss: 1.5181 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/26\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4894 - binary_accuracy: 0.6670 - val_loss: 1.4812 - val_binary_accuracy: 0.5214\n",
      "Epoch 25/26\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4861 - binary_accuracy: 0.6759 - val_loss: 1.5902 - val_binary_accuracy: 0.5321\n",
      "Epoch 26/26\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4873 - binary_accuracy: 0.6750 - val_loss: 1.3417 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6577 - binary_accuracy: 0.6436\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.2124 - binary_accuracy: 0.5483\n",
      "training start... epochs = 27\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_78 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_79 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/27\n",
      "112/112 [==============================] - 39s 258ms/step - loss: 0.6940 - binary_accuracy: 0.5161 - val_loss: 0.6916 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/27\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.7132 - binary_accuracy: 0.5679 - val_loss: 0.6921 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/27\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.8435 - binary_accuracy: 0.5491 - val_loss: 0.7283 - val_binary_accuracy: 0.4893\n",
      "Epoch 4/27\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.7346 - binary_accuracy: 0.5188 - val_loss: 0.6981 - val_binary_accuracy: 0.4893\n",
      "Epoch 5/27\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.7013 - binary_accuracy: 0.5152 - val_loss: 0.6919 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/27\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.7057 - binary_accuracy: 0.5143 - val_loss: 0.6999 - val_binary_accuracy: 0.5179\n",
      "Epoch 7/27\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.7015 - binary_accuracy: 0.4973 - val_loss: 0.6937 - val_binary_accuracy: 0.4964\n",
      "Epoch 8/27\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.6927 - binary_accuracy: 0.5250 - val_loss: 0.6938 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/27\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.6821 - binary_accuracy: 0.5688 - val_loss: 0.6960 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/27\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.6560 - binary_accuracy: 0.5821 - val_loss: 0.7357 - val_binary_accuracy: 0.5107\n",
      "Epoch 11/27\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.6227 - binary_accuracy: 0.6036 - val_loss: 0.7159 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.6075 - binary_accuracy: 0.6268 - val_loss: 0.7238 - val_binary_accuracy: 0.5107\n",
      "Epoch 13/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5840 - binary_accuracy: 0.6187 - val_loss: 0.7742 - val_binary_accuracy: 0.5179\n",
      "Epoch 14/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5882 - binary_accuracy: 0.6187 - val_loss: 0.7058 - val_binary_accuracy: 0.5036\n",
      "Epoch 15/27\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.5944 - binary_accuracy: 0.6045 - val_loss: 0.7459 - val_binary_accuracy: 0.5107\n",
      "Epoch 16/27\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.5806 - binary_accuracy: 0.6045 - val_loss: 0.7878 - val_binary_accuracy: 0.5071\n",
      "Epoch 17/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5598 - binary_accuracy: 0.6634 - val_loss: 0.7894 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5574 - binary_accuracy: 0.6473 - val_loss: 0.7464 - val_binary_accuracy: 0.5107\n",
      "Epoch 19/27\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.5357 - binary_accuracy: 0.6500 - val_loss: 0.8268 - val_binary_accuracy: 0.4964\n",
      "Epoch 20/27\n",
      "112/112 [==============================] - 25s 219ms/step - loss: 0.5314 - binary_accuracy: 0.6714 - val_loss: 0.8118 - val_binary_accuracy: 0.5143\n",
      "Epoch 21/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5108 - binary_accuracy: 0.6705 - val_loss: 0.8585 - val_binary_accuracy: 0.5143\n",
      "Epoch 22/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5166 - binary_accuracy: 0.6571 - val_loss: 0.9027 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5100 - binary_accuracy: 0.6545 - val_loss: 0.8516 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5049 - binary_accuracy: 0.6580 - val_loss: 0.8340 - val_binary_accuracy: 0.4929\n",
      "Epoch 25/27\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.4992 - binary_accuracy: 0.6589 - val_loss: 0.8880 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/27\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4922 - binary_accuracy: 0.6741 - val_loss: 1.0059 - val_binary_accuracy: 0.5071\n",
      "Epoch 27/27\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4856 - binary_accuracy: 0.6812 - val_loss: 0.9393 - val_binary_accuracy: 0.4857\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5745 - binary_accuracy: 0.6064\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.8760 - binary_accuracy: 0.5200\n",
      "training start... epochs = 28\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_41 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_80 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_81 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "112/112 [==============================] - 39s 254ms/step - loss: 0.6933 - binary_accuracy: 0.5045 - val_loss: 0.7008 - val_binary_accuracy: 0.5250\n",
      "Epoch 2/28\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.7308 - binary_accuracy: 0.5518 - val_loss: 0.6903 - val_binary_accuracy: 0.5321\n",
      "Epoch 3/28\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.6426 - binary_accuracy: 0.6152 - val_loss: 0.7292 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/28\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5676 - binary_accuracy: 0.6589 - val_loss: 0.8254 - val_binary_accuracy: 0.5214\n",
      "Epoch 5/28\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4962 - binary_accuracy: 0.6804 - val_loss: 0.9647 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4898 - binary_accuracy: 0.6786 - val_loss: 1.1571 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/28\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4770 - binary_accuracy: 0.6759 - val_loss: 1.1408 - val_binary_accuracy: 0.5071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4909 - binary_accuracy: 0.6723 - val_loss: 0.8722 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4916 - binary_accuracy: 0.6732 - val_loss: 0.9152 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/28\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4870 - binary_accuracy: 0.6759 - val_loss: 1.0013 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/28\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4844 - binary_accuracy: 0.6768 - val_loss: 1.1143 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4843 - binary_accuracy: 0.6848 - val_loss: 1.0260 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.5103 - binary_accuracy: 0.6723 - val_loss: 1.0264 - val_binary_accuracy: 0.5107\n",
      "Epoch 14/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4846 - binary_accuracy: 0.6759 - val_loss: 1.0255 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/28\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4819 - binary_accuracy: 0.6795 - val_loss: 1.1265 - val_binary_accuracy: 0.5250\n",
      "Epoch 16/28\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4944 - binary_accuracy: 0.6750 - val_loss: 0.8969 - val_binary_accuracy: 0.5214\n",
      "Epoch 17/28\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4918 - binary_accuracy: 0.6696 - val_loss: 1.0658 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/28\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4830 - binary_accuracy: 0.6777 - val_loss: 1.1471 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/28\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.4782 - binary_accuracy: 0.6812 - val_loss: 1.1394 - val_binary_accuracy: 0.5250\n",
      "Epoch 20/28\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5060 - binary_accuracy: 0.6741 - val_loss: 0.9227 - val_binary_accuracy: 0.5179\n",
      "Epoch 21/28\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4977 - binary_accuracy: 0.6732 - val_loss: 0.9690 - val_binary_accuracy: 0.5250\n",
      "Epoch 22/28\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4892 - binary_accuracy: 0.6777 - val_loss: 1.0346 - val_binary_accuracy: 0.5214\n",
      "Epoch 23/28\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4849 - binary_accuracy: 0.6777 - val_loss: 1.1647 - val_binary_accuracy: 0.5250\n",
      "Epoch 24/28\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4883 - binary_accuracy: 0.6759 - val_loss: 0.9702 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/28\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4846 - binary_accuracy: 0.6777 - val_loss: 1.0736 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/28\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4850 - binary_accuracy: 0.6777 - val_loss: 1.0767 - val_binary_accuracy: 0.5321\n",
      "Epoch 27/28\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.5210 - binary_accuracy: 0.6804 - val_loss: 1.2651 - val_binary_accuracy: 0.5357\n",
      "Epoch 28/28\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4870 - binary_accuracy: 0.6830 - val_loss: 0.9280 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5748 - binary_accuracy: 0.6457\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.9115 - binary_accuracy: 0.5500\n",
      "training start... epochs = 29\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_42 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_82 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_83 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/29\n",
      "112/112 [==============================] - 40s 265ms/step - loss: 0.6938 - binary_accuracy: 0.5429 - val_loss: 0.6921 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/29\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 0.6722 - binary_accuracy: 0.5786 - val_loss: 0.6988 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/29\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.7001 - binary_accuracy: 0.6339 - val_loss: 0.7136 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/29\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.5442 - binary_accuracy: 0.6580 - val_loss: 0.8169 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/29\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.5347 - binary_accuracy: 0.6661 - val_loss: 0.8349 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4897 - binary_accuracy: 0.6723 - val_loss: 0.8652 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/29\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4874 - binary_accuracy: 0.6759 - val_loss: 1.0057 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/29\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.5023 - binary_accuracy: 0.6804 - val_loss: 0.9367 - val_binary_accuracy: 0.4964\n",
      "Epoch 9/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4840 - binary_accuracy: 0.6786 - val_loss: 1.0803 - val_binary_accuracy: 0.5036\n",
      "Epoch 10/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4857 - binary_accuracy: 0.6750 - val_loss: 0.9237 - val_binary_accuracy: 0.4964\n",
      "Epoch 11/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4854 - binary_accuracy: 0.6786 - val_loss: 0.9236 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4875 - binary_accuracy: 0.6777 - val_loss: 1.0052 - val_binary_accuracy: 0.5143\n",
      "Epoch 13/29\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4794 - binary_accuracy: 0.6795 - val_loss: 0.9228 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4905 - binary_accuracy: 0.6777 - val_loss: 1.0182 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4837 - binary_accuracy: 0.6750 - val_loss: 1.0164 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4836 - binary_accuracy: 0.6786 - val_loss: 1.1864 - val_binary_accuracy: 0.5250\n",
      "Epoch 17/29\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4840 - binary_accuracy: 0.6804 - val_loss: 1.0721 - val_binary_accuracy: 0.4964\n",
      "Epoch 18/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4831 - binary_accuracy: 0.6670 - val_loss: 1.0681 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/29\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4844 - binary_accuracy: 0.6804 - val_loss: 1.1026 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/29\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4781 - binary_accuracy: 0.6768 - val_loss: 1.7748 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4976 - binary_accuracy: 0.6687 - val_loss: 1.0538 - val_binary_accuracy: 0.5143\n",
      "Epoch 22/29\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4847 - binary_accuracy: 0.6732 - val_loss: 1.1689 - val_binary_accuracy: 0.5143\n",
      "Epoch 23/29\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.7905 - binary_accuracy: 0.5902 - val_loss: 0.7539 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.7325 - binary_accuracy: 0.4750 - val_loss: 0.7139 - val_binary_accuracy: 0.5071\n",
      "Epoch 25/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.7012 - binary_accuracy: 0.5152 - val_loss: 0.6996 - val_binary_accuracy: 0.4750\n",
      "Epoch 26/29\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.6982 - binary_accuracy: 0.5107 - val_loss: 0.6993 - val_binary_accuracy: 0.5179\n",
      "Epoch 27/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.6954 - binary_accuracy: 0.5027 - val_loss: 0.6931 - val_binary_accuracy: 0.5179\n",
      "Epoch 28/29\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.6964 - binary_accuracy: 0.5018 - val_loss: 0.6933 - val_binary_accuracy: 0.4893\n",
      "Epoch 29/29\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.6943 - binary_accuracy: 0.5321 - val_loss: 0.6933 - val_binary_accuracy: 0.4821\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6902 - binary_accuracy: 0.5264\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.6930 - binary_accuracy: 0.5017\n",
      "training start... epochs = 30\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_43 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_84 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_85 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 40s 262ms/step - loss: 0.6941 - binary_accuracy: 0.5312 - val_loss: 0.6914 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 0.7514 - binary_accuracy: 0.5589 - val_loss: 0.6999 - val_binary_accuracy: 0.5107\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 26s 229ms/step - loss: 0.6178 - binary_accuracy: 0.6330 - val_loss: 0.7285 - val_binary_accuracy: 0.4929\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.5779 - binary_accuracy: 0.6384 - val_loss: 0.7510 - val_binary_accuracy: 0.4714\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 25s 228ms/step - loss: 0.5127 - binary_accuracy: 0.6687 - val_loss: 0.7736 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.5022 - binary_accuracy: 0.6714 - val_loss: 0.8726 - val_binary_accuracy: 0.5036\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.4865 - binary_accuracy: 0.6786 - val_loss: 1.0072 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4831 - binary_accuracy: 0.6812 - val_loss: 0.9275 - val_binary_accuracy: 0.4929\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 0.4856 - binary_accuracy: 0.6786 - val_loss: 1.1896 - val_binary_accuracy: 0.5071\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.4974 - binary_accuracy: 0.6723 - val_loss: 0.9199 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.4871 - binary_accuracy: 0.6741 - val_loss: 1.0442 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 0.4893 - binary_accuracy: 0.6812 - val_loss: 0.9684 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4901 - binary_accuracy: 0.6732 - val_loss: 0.9773 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4773 - binary_accuracy: 0.6884 - val_loss: 1.2012 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4911 - binary_accuracy: 0.6759 - val_loss: 0.9803 - val_binary_accuracy: 0.5250\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.4887 - binary_accuracy: 0.6795 - val_loss: 0.9599 - val_binary_accuracy: 0.5179\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4802 - binary_accuracy: 0.6875 - val_loss: 1.3814 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4955 - binary_accuracy: 0.6804 - val_loss: 0.9681 - val_binary_accuracy: 0.5214\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4819 - binary_accuracy: 0.6804 - val_loss: 0.9385 - val_binary_accuracy: 0.5036\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4887 - binary_accuracy: 0.6759 - val_loss: 0.9675 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4794 - binary_accuracy: 0.6839 - val_loss: 1.2425 - val_binary_accuracy: 0.5214\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.5765 - binary_accuracy: 0.6741 - val_loss: 0.7824 - val_binary_accuracy: 0.5107\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4944 - binary_accuracy: 0.6759 - val_loss: 0.9109 - val_binary_accuracy: 0.5071\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4864 - binary_accuracy: 0.6768 - val_loss: 0.9759 - val_binary_accuracy: 0.4964\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4833 - binary_accuracy: 0.6768 - val_loss: 1.0154 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4823 - binary_accuracy: 0.6848 - val_loss: 1.0582 - val_binary_accuracy: 0.4964\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4828 - binary_accuracy: 0.6750 - val_loss: 1.0989 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4826 - binary_accuracy: 0.6804 - val_loss: 1.1481 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4813 - binary_accuracy: 0.6812 - val_loss: 1.1918 - val_binary_accuracy: 0.4964\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.4770 - binary_accuracy: 0.6866 - val_loss: 1.3764 - val_binary_accuracy: 0.4893\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6531 - binary_accuracy: 0.6486\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.3977 - binary_accuracy: 0.5517\n",
      "training start... epochs = 31\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_44 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_86 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_87 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/31\n",
      "112/112 [==============================] - 39s 255ms/step - loss: 0.7151 - binary_accuracy: 0.5250 - val_loss: 0.6921 - val_binary_accuracy: 0.5214\n",
      "Epoch 2/31\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.6758 - binary_accuracy: 0.5670 - val_loss: 0.6957 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/31\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.6771 - binary_accuracy: 0.6357 - val_loss: 0.6999 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/31\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.5787 - binary_accuracy: 0.6429 - val_loss: 0.7761 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/31\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.5317 - binary_accuracy: 0.6652 - val_loss: 0.7922 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4951 - binary_accuracy: 0.6687 - val_loss: 1.0654 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/31\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5357 - binary_accuracy: 0.6732 - val_loss: 0.8751 - val_binary_accuracy: 0.5250\n",
      "Epoch 8/31\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4952 - binary_accuracy: 0.6777 - val_loss: 0.9346 - val_binary_accuracy: 0.5214\n",
      "Epoch 9/31\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.4896 - binary_accuracy: 0.6750 - val_loss: 0.9653 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/31\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4843 - binary_accuracy: 0.6768 - val_loss: 1.0476 - val_binary_accuracy: 0.5250\n",
      "Epoch 11/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4835 - binary_accuracy: 0.6705 - val_loss: 1.0563 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/31\n",
      "112/112 [==============================] - 24s 214ms/step - loss: 0.4886 - binary_accuracy: 0.6750 - val_loss: 1.0908 - val_binary_accuracy: 0.5143\n",
      "Epoch 13/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4912 - binary_accuracy: 0.6625 - val_loss: 1.0824 - val_binary_accuracy: 0.5179\n",
      "Epoch 14/31\n",
      "112/112 [==============================] - 24s 219ms/step - loss: 0.4822 - binary_accuracy: 0.6777 - val_loss: 1.2418 - val_binary_accuracy: 0.5179\n",
      "Epoch 15/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4801 - binary_accuracy: 0.6812 - val_loss: 1.1216 - val_binary_accuracy: 0.5107\n",
      "Epoch 16/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4800 - binary_accuracy: 0.6830 - val_loss: 1.0424 - val_binary_accuracy: 0.5286\n",
      "Epoch 17/31\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4882 - binary_accuracy: 0.6768 - val_loss: 1.1285 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4938 - binary_accuracy: 0.6768 - val_loss: 1.0384 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4828 - binary_accuracy: 0.6848 - val_loss: 1.1467 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4784 - binary_accuracy: 0.6839 - val_loss: 1.1719 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4767 - binary_accuracy: 0.6848 - val_loss: 1.1589 - val_binary_accuracy: 0.5393\n",
      "Epoch 22/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4843 - binary_accuracy: 0.6812 - val_loss: 1.1121 - val_binary_accuracy: 0.5107\n",
      "Epoch 23/31\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4799 - binary_accuracy: 0.6839 - val_loss: 1.2760 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4777 - binary_accuracy: 0.6848 - val_loss: 1.2919 - val_binary_accuracy: 0.5214\n",
      "Epoch 25/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4778 - binary_accuracy: 0.6848 - val_loss: 1.2763 - val_binary_accuracy: 0.5393\n",
      "Epoch 26/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4759 - binary_accuracy: 0.6857 - val_loss: 1.3294 - val_binary_accuracy: 0.5286\n",
      "Epoch 27/31\n",
      "112/112 [==============================] - 24s 215ms/step - loss: 0.4748 - binary_accuracy: 0.6857 - val_loss: 1.3332 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/31\n",
      "112/112 [==============================] - 24s 217ms/step - loss: 0.4742 - binary_accuracy: 0.6848 - val_loss: 1.3728 - val_binary_accuracy: 0.5143\n",
      "Epoch 29/31\n",
      "112/112 [==============================] - 24s 216ms/step - loss: 0.4766 - binary_accuracy: 0.6741 - val_loss: 1.2790 - val_binary_accuracy: 0.5179\n",
      "Epoch 30/31\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4742 - binary_accuracy: 0.6857 - val_loss: 1.2486 - val_binary_accuracy: 0.5214\n",
      "Epoch 31/31\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.4744 - binary_accuracy: 0.6857 - val_loss: 1.4090 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6603 - binary_accuracy: 0.6521\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.4297 - binary_accuracy: 0.5433\n",
      "training start... epochs = 32\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_45 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_88 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "112/112 [==============================] - 40s 259ms/step - loss: 0.6916 - binary_accuracy: 0.5098 - val_loss: 0.6915 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/32\n",
      "112/112 [==============================] - 26s 228ms/step - loss: 0.6769 - binary_accuracy: 0.5696 - val_loss: 0.7052 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.5965 - binary_accuracy: 0.6482 - val_loss: 0.7589 - val_binary_accuracy: 0.5071\n",
      "Epoch 4/32\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.5148 - binary_accuracy: 0.6509 - val_loss: 1.1001 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/32\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4874 - binary_accuracy: 0.6580 - val_loss: 1.1493 - val_binary_accuracy: 0.4929\n",
      "Epoch 6/32\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4948 - binary_accuracy: 0.6732 - val_loss: 1.0640 - val_binary_accuracy: 0.5143\n",
      "Epoch 7/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4892 - binary_accuracy: 0.6670 - val_loss: 1.1054 - val_binary_accuracy: 0.4893\n",
      "Epoch 8/32\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.4872 - binary_accuracy: 0.6795 - val_loss: 1.1529 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4879 - binary_accuracy: 0.6723 - val_loss: 1.1989 - val_binary_accuracy: 0.5071\n",
      "Epoch 10/32\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4893 - binary_accuracy: 0.6750 - val_loss: 1.0998 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/32\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4856 - binary_accuracy: 0.6777 - val_loss: 1.1983 - val_binary_accuracy: 0.4964\n",
      "Epoch 12/32\n",
      "112/112 [==============================] - 25s 219ms/step - loss: 0.4816 - binary_accuracy: 0.6804 - val_loss: 1.2829 - val_binary_accuracy: 0.5036\n",
      "Epoch 13/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4776 - binary_accuracy: 0.6821 - val_loss: 1.4016 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4937 - binary_accuracy: 0.6696 - val_loss: 1.0837 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/32\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4833 - binary_accuracy: 0.6786 - val_loss: 1.0974 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.5199 - binary_accuracy: 0.6705 - val_loss: 1.1764 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4864 - binary_accuracy: 0.6777 - val_loss: 1.3229 - val_binary_accuracy: 0.5107\n",
      "Epoch 18/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4784 - binary_accuracy: 0.6795 - val_loss: 1.5075 - val_binary_accuracy: 0.5107\n",
      "Epoch 19/32\n",
      "112/112 [==============================] - 25s 219ms/step - loss: 0.4822 - binary_accuracy: 0.6804 - val_loss: 1.4145 - val_binary_accuracy: 0.5071\n",
      "Epoch 20/32\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4887 - binary_accuracy: 0.6795 - val_loss: 1.2900 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.5658 - binary_accuracy: 0.6777 - val_loss: 0.9092 - val_binary_accuracy: 0.4964\n",
      "Epoch 22/32\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4933 - binary_accuracy: 0.6777 - val_loss: 1.3901 - val_binary_accuracy: 0.5071\n",
      "Epoch 23/32\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4806 - binary_accuracy: 0.6812 - val_loss: 2.0043 - val_binary_accuracy: 0.4893\n",
      "Epoch 24/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4862 - binary_accuracy: 0.6723 - val_loss: 1.2062 - val_binary_accuracy: 0.5036\n",
      "Epoch 25/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4833 - binary_accuracy: 0.6812 - val_loss: 1.4714 - val_binary_accuracy: 0.5036\n",
      "Epoch 26/32\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4872 - binary_accuracy: 0.6795 - val_loss: 1.1393 - val_binary_accuracy: 0.5071\n",
      "Epoch 27/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4807 - binary_accuracy: 0.6759 - val_loss: 1.4461 - val_binary_accuracy: 0.4929\n",
      "Epoch 28/32\n",
      "112/112 [==============================] - 25s 220ms/step - loss: 0.4746 - binary_accuracy: 0.6866 - val_loss: 1.6033 - val_binary_accuracy: 0.4893\n",
      "Epoch 29/32\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4699 - binary_accuracy: 0.6866 - val_loss: 2.2244 - val_binary_accuracy: 0.4929\n",
      "Epoch 30/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 1.7253 - binary_accuracy: 0.5054 - val_loss: 0.6929 - val_binary_accuracy: 0.5107\n",
      "Epoch 31/32\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.6947 - binary_accuracy: 0.4768 - val_loss: 0.6938 - val_binary_accuracy: 0.4893\n",
      "Epoch 32/32\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.6938 - binary_accuracy: 0.5027 - val_loss: 0.6941 - val_binary_accuracy: 0.4893\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6935 - binary_accuracy: 0.5000\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.6935 - binary_accuracy: 0.5000\n",
      "training start... epochs = 33\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_46 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_36 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_90 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_91 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/33\n",
      "112/112 [==============================] - 40s 267ms/step - loss: 0.6949 - binary_accuracy: 0.5063 - val_loss: 0.6926 - val_binary_accuracy: 0.5286\n",
      "Epoch 2/33\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.7526 - binary_accuracy: 0.5714 - val_loss: 0.7408 - val_binary_accuracy: 0.5393\n",
      "Epoch 3/33\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 0.6239 - binary_accuracy: 0.6196 - val_loss: 0.7254 - val_binary_accuracy: 0.5036\n",
      "Epoch 4/33\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 0.5751 - binary_accuracy: 0.6643 - val_loss: 0.7746 - val_binary_accuracy: 0.5143\n",
      "Epoch 5/33\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.7323 - binary_accuracy: 0.6027 - val_loss: 0.6898 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/33\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.7045 - binary_accuracy: 0.5518 - val_loss: 0.7139 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.6476 - binary_accuracy: 0.5884 - val_loss: 0.7471 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/33\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.6065 - binary_accuracy: 0.6223 - val_loss: 0.7634 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/33\n",
      "112/112 [==============================] - 24s 218ms/step - loss: 0.5884 - binary_accuracy: 0.6607 - val_loss: 0.7314 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/33\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.5753 - binary_accuracy: 0.6455 - val_loss: 0.7686 - val_binary_accuracy: 0.5107\n",
      "Epoch 11/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5598 - binary_accuracy: 0.6571 - val_loss: 0.8040 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.5567 - binary_accuracy: 0.6527 - val_loss: 0.7704 - val_binary_accuracy: 0.5036\n",
      "Epoch 13/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5453 - binary_accuracy: 0.6652 - val_loss: 0.9937 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5388 - binary_accuracy: 0.6518 - val_loss: 0.9487 - val_binary_accuracy: 0.5107\n",
      "Epoch 15/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5125 - binary_accuracy: 0.6616 - val_loss: 1.0161 - val_binary_accuracy: 0.5036\n",
      "Epoch 16/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.5078 - binary_accuracy: 0.6411 - val_loss: 0.8093 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 25s 223ms/step - loss: 0.5024 - binary_accuracy: 0.6795 - val_loss: 0.7479 - val_binary_accuracy: 0.5036\n",
      "Epoch 18/33\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.5146 - binary_accuracy: 0.6473 - val_loss: 1.0112 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/33\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4923 - binary_accuracy: 0.6679 - val_loss: 1.0138 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4823 - binary_accuracy: 0.6732 - val_loss: 1.3529 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/33\n",
      "112/112 [==============================] - 25s 227ms/step - loss: 0.4826 - binary_accuracy: 0.6821 - val_loss: 1.3314 - val_binary_accuracy: 0.4964\n",
      "Epoch 22/33\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4750 - binary_accuracy: 0.6821 - val_loss: 1.2556 - val_binary_accuracy: 0.4821\n",
      "Epoch 23/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4914 - binary_accuracy: 0.6687 - val_loss: 0.9737 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/33\n",
      "112/112 [==============================] - 25s 221ms/step - loss: 0.4815 - binary_accuracy: 0.6705 - val_loss: 1.2900 - val_binary_accuracy: 0.4929\n",
      "Epoch 25/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4773 - binary_accuracy: 0.6634 - val_loss: 1.3756 - val_binary_accuracy: 0.4679\n",
      "Epoch 26/33\n",
      "112/112 [==============================] - 25s 222ms/step - loss: 0.4779 - binary_accuracy: 0.6741 - val_loss: 1.2644 - val_binary_accuracy: 0.4786\n",
      "Epoch 27/33\n",
      "112/112 [==============================] - 25s 223ms/step - loss: 0.4750 - binary_accuracy: 0.6634 - val_loss: 1.5207 - val_binary_accuracy: 0.5321\n",
      "Epoch 28/33\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4934 - binary_accuracy: 0.6723 - val_loss: 0.8744 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4750 - binary_accuracy: 0.6911 - val_loss: 1.3499 - val_binary_accuracy: 0.4679\n",
      "Epoch 30/33\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4836 - binary_accuracy: 0.6625 - val_loss: 1.1457 - val_binary_accuracy: 0.5107\n",
      "Epoch 31/33\n",
      "112/112 [==============================] - 25s 225ms/step - loss: 0.4719 - binary_accuracy: 0.6804 - val_loss: 1.3446 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/33\n",
      "112/112 [==============================] - 25s 226ms/step - loss: 0.4700 - binary_accuracy: 0.6696 - val_loss: 1.4660 - val_binary_accuracy: 0.5036\n",
      "Epoch 33/33\n",
      "112/112 [==============================] - 25s 224ms/step - loss: 0.4929 - binary_accuracy: 0.6777 - val_loss: 1.0362 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6046 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.0500 - binary_accuracy: 0.5283\n",
      "training start... epochs = 34\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_47 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/34\n",
      "112/112 [==============================] - 41s 270ms/step - loss: 0.6941 - binary_accuracy: 0.5098 - val_loss: 0.6901 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/34\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.6957 - binary_accuracy: 0.5500 - val_loss: 0.6925 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/34\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.6488 - binary_accuracy: 0.6268 - val_loss: 0.7892 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/34\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.5674 - binary_accuracy: 0.6491 - val_loss: 0.8497 - val_binary_accuracy: 0.4929\n",
      "Epoch 5/34\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.5079 - binary_accuracy: 0.6598 - val_loss: 0.8588 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4927 - binary_accuracy: 0.6750 - val_loss: 1.0075 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/34\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.5007 - binary_accuracy: 0.6634 - val_loss: 0.9482 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/34\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.5024 - binary_accuracy: 0.6670 - val_loss: 0.9440 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/34\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4894 - binary_accuracy: 0.6732 - val_loss: 0.9282 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/34\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4848 - binary_accuracy: 0.6795 - val_loss: 1.1491 - val_binary_accuracy: 0.5321\n",
      "Epoch 11/34\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4859 - binary_accuracy: 0.6812 - val_loss: 0.9438 - val_binary_accuracy: 0.5429\n",
      "Epoch 12/34\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4879 - binary_accuracy: 0.6750 - val_loss: 1.0516 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4829 - binary_accuracy: 0.6687 - val_loss: 1.3267 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/34\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4964 - binary_accuracy: 0.6830 - val_loss: 1.0034 - val_binary_accuracy: 0.5500\n",
      "Epoch 15/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4874 - binary_accuracy: 0.6804 - val_loss: 0.9797 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/34\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4842 - binary_accuracy: 0.6768 - val_loss: 1.1093 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/34\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 0.4859 - binary_accuracy: 0.6786 - val_loss: 1.0179 - val_binary_accuracy: 0.5250\n",
      "Epoch 18/34\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 0.4799 - binary_accuracy: 0.6804 - val_loss: 1.3238 - val_binary_accuracy: 0.5321\n",
      "Epoch 19/34\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.6204 - binary_accuracy: 0.6464 - val_loss: 1.1249 - val_binary_accuracy: 0.5321\n",
      "Epoch 20/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4887 - binary_accuracy: 0.6893 - val_loss: 1.0404 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/34\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 0.4816 - binary_accuracy: 0.6839 - val_loss: 1.4284 - val_binary_accuracy: 0.5214\n",
      "Epoch 22/34\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 0.4914 - binary_accuracy: 0.6759 - val_loss: 1.0319 - val_binary_accuracy: 0.5286\n",
      "Epoch 23/34\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 0.4793 - binary_accuracy: 0.6821 - val_loss: 1.2807 - val_binary_accuracy: 0.5214\n",
      "Epoch 24/34\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4847 - binary_accuracy: 0.6866 - val_loss: 1.0744 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4814 - binary_accuracy: 0.6857 - val_loss: 1.0343 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/34\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4726 - binary_accuracy: 0.6884 - val_loss: 1.4230 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/34\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4820 - binary_accuracy: 0.6884 - val_loss: 1.3743 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/34\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4920 - binary_accuracy: 0.6804 - val_loss: 1.0289 - val_binary_accuracy: 0.5179\n",
      "Epoch 29/34\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 0.4924 - binary_accuracy: 0.6821 - val_loss: 1.0392 - val_binary_accuracy: 0.5179\n",
      "Epoch 30/34\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4798 - binary_accuracy: 0.6804 - val_loss: 1.1357 - val_binary_accuracy: 0.5250\n",
      "Epoch 31/34\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4806 - binary_accuracy: 0.6804 - val_loss: 1.0554 - val_binary_accuracy: 0.4929\n",
      "Epoch 32/34\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4976 - binary_accuracy: 0.6866 - val_loss: 1.0666 - val_binary_accuracy: 0.5214\n",
      "Epoch 33/34\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4854 - binary_accuracy: 0.6812 - val_loss: 1.0886 - val_binary_accuracy: 0.5286\n",
      "Epoch 34/34\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4725 - binary_accuracy: 0.6866 - val_loss: 1.2175 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6185 - binary_accuracy: 0.6514\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1775 - binary_accuracy: 0.5650\n",
      "training start... epochs = 35\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_48 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_95 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "112/112 [==============================] - 45s 302ms/step - loss: 0.6929 - binary_accuracy: 0.5188 - val_loss: 0.6922 - val_binary_accuracy: 0.5429\n",
      "Epoch 2/35\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.6745 - binary_accuracy: 0.5705 - val_loss: 0.7004 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/35\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.6798 - binary_accuracy: 0.6464 - val_loss: 0.7209 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/35\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5673 - binary_accuracy: 0.6616 - val_loss: 0.8084 - val_binary_accuracy: 0.4750\n",
      "Epoch 5/35\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5224 - binary_accuracy: 0.6670 - val_loss: 0.9574 - val_binary_accuracy: 0.4821\n",
      "Epoch 6/35\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4913 - binary_accuracy: 0.6759 - val_loss: 0.9969 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/35\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4895 - binary_accuracy: 0.6741 - val_loss: 1.0857 - val_binary_accuracy: 0.4964\n",
      "Epoch 8/35\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4839 - binary_accuracy: 0.6768 - val_loss: 1.0898 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/35\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4872 - binary_accuracy: 0.6759 - val_loss: 0.9633 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/35\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4835 - binary_accuracy: 0.6777 - val_loss: 1.1620 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/35\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4779 - binary_accuracy: 0.6768 - val_loss: 1.2546 - val_binary_accuracy: 0.5107\n",
      "Epoch 12/35\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4765 - binary_accuracy: 0.6804 - val_loss: 1.2642 - val_binary_accuracy: 0.4964\n",
      "Epoch 13/35\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4835 - binary_accuracy: 0.6786 - val_loss: 0.9519 - val_binary_accuracy: 0.5321\n",
      "Epoch 14/35\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4791 - binary_accuracy: 0.6795 - val_loss: 1.0880 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/35\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4717 - binary_accuracy: 0.6893 - val_loss: 1.1621 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/35\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4667 - binary_accuracy: 0.6830 - val_loss: 1.1720 - val_binary_accuracy: 0.5036\n",
      "Epoch 17/35\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4696 - binary_accuracy: 0.6839 - val_loss: 1.4955 - val_binary_accuracy: 0.4929\n",
      "Epoch 18/35\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4928 - binary_accuracy: 0.6741 - val_loss: 1.1600 - val_binary_accuracy: 0.5036\n",
      "Epoch 19/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4739 - binary_accuracy: 0.6830 - val_loss: 0.9967 - val_binary_accuracy: 0.5036\n",
      "Epoch 20/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4862 - binary_accuracy: 0.6786 - val_loss: 1.3202 - val_binary_accuracy: 0.5214\n",
      "Epoch 21/35\n",
      "112/112 [==============================] - 26s 230ms/step - loss: 0.4724 - binary_accuracy: 0.6652 - val_loss: 1.8267 - val_binary_accuracy: 0.5143\n",
      "Epoch 22/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4722 - binary_accuracy: 0.6902 - val_loss: 1.4268 - val_binary_accuracy: 0.5143\n",
      "Epoch 23/35\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4662 - binary_accuracy: 0.6911 - val_loss: 1.8121 - val_binary_accuracy: 0.4857\n",
      "Epoch 24/35\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 0.4709 - binary_accuracy: 0.6848 - val_loss: 1.2474 - val_binary_accuracy: 0.5107\n",
      "Epoch 25/35\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4680 - binary_accuracy: 0.6768 - val_loss: 1.4152 - val_binary_accuracy: 0.5107\n",
      "Epoch 26/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4625 - binary_accuracy: 0.6875 - val_loss: 1.8136 - val_binary_accuracy: 0.5214\n",
      "Epoch 27/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4748 - binary_accuracy: 0.6804 - val_loss: 1.1896 - val_binary_accuracy: 0.5036\n",
      "Epoch 28/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4729 - binary_accuracy: 0.6812 - val_loss: 1.6695 - val_binary_accuracy: 0.5214\n",
      "Epoch 29/35\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4675 - binary_accuracy: 0.6804 - val_loss: 1.4394 - val_binary_accuracy: 0.5143\n",
      "Epoch 30/35\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4790 - binary_accuracy: 0.6786 - val_loss: 1.1294 - val_binary_accuracy: 0.5071\n",
      "Epoch 31/35\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 0.4802 - binary_accuracy: 0.6732 - val_loss: 1.2246 - val_binary_accuracy: 0.5143\n",
      "Epoch 32/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4685 - binary_accuracy: 0.6857 - val_loss: 1.2867 - val_binary_accuracy: 0.5179\n",
      "Epoch 33/35\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4685 - binary_accuracy: 0.6848 - val_loss: 1.4178 - val_binary_accuracy: 0.5107\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 26s 236ms/step - loss: 0.5836 - binary_accuracy: 0.6554 - val_loss: 0.6934 - val_binary_accuracy: 0.5107\n",
      "Epoch 35/35\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.6954 - binary_accuracy: 0.5071 - val_loss: 0.6968 - val_binary_accuracy: 0.4893\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6952 - binary_accuracy: 0.5000\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.6953 - binary_accuracy: 0.5000\n",
      "training start... epochs = 36\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_49 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_96 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_97 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/36\n",
      "112/112 [==============================] - 44s 294ms/step - loss: 0.6934 - binary_accuracy: 0.5214 - val_loss: 0.6916 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/36\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.7259 - binary_accuracy: 0.5589 - val_loss: 0.6954 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/36\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.6214 - binary_accuracy: 0.6259 - val_loss: 0.7141 - val_binary_accuracy: 0.5071\n",
      "Epoch 4/36\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.5636 - binary_accuracy: 0.6562 - val_loss: 0.7218 - val_binary_accuracy: 0.4786\n",
      "Epoch 5/36\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5076 - binary_accuracy: 0.6616 - val_loss: 0.9445 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/36\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4939 - binary_accuracy: 0.6714 - val_loss: 0.8772 - val_binary_accuracy: 0.4964\n",
      "Epoch 7/36\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4917 - binary_accuracy: 0.6723 - val_loss: 1.0890 - val_binary_accuracy: 0.5107\n",
      "Epoch 8/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4914 - binary_accuracy: 0.6759 - val_loss: 0.9775 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/36\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4863 - binary_accuracy: 0.6723 - val_loss: 1.3780 - val_binary_accuracy: 0.5179\n",
      "Epoch 10/36\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.5059 - binary_accuracy: 0.6705 - val_loss: 1.0514 - val_binary_accuracy: 0.5286\n",
      "Epoch 11/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4847 - binary_accuracy: 0.6768 - val_loss: 1.1011 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/36\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4833 - binary_accuracy: 0.6741 - val_loss: 1.0198 - val_binary_accuracy: 0.5214\n",
      "Epoch 13/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4997 - binary_accuracy: 0.6714 - val_loss: 0.9452 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/36\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4907 - binary_accuracy: 0.6750 - val_loss: 0.8171 - val_binary_accuracy: 0.5107\n",
      "Epoch 15/36\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4899 - binary_accuracy: 0.6679 - val_loss: 1.0446 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/36\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4888 - binary_accuracy: 0.6786 - val_loss: 0.9485 - val_binary_accuracy: 0.5214\n",
      "Epoch 17/36\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4858 - binary_accuracy: 0.6786 - val_loss: 1.0303 - val_binary_accuracy: 0.5250\n",
      "Epoch 18/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4843 - binary_accuracy: 0.6786 - val_loss: 1.1695 - val_binary_accuracy: 0.5321\n",
      "Epoch 19/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4804 - binary_accuracy: 0.6786 - val_loss: 1.3607 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/36\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.5142 - binary_accuracy: 0.6714 - val_loss: 1.2722 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/36\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.5021 - binary_accuracy: 0.6679 - val_loss: 1.0544 - val_binary_accuracy: 0.5071\n",
      "Epoch 22/36\n",
      "112/112 [==============================] - 26s 231ms/step - loss: 0.4872 - binary_accuracy: 0.6768 - val_loss: 1.0324 - val_binary_accuracy: 0.4893\n",
      "Epoch 23/36\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4863 - binary_accuracy: 0.6759 - val_loss: 1.1265 - val_binary_accuracy: 0.5143\n",
      "Epoch 24/36\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4834 - binary_accuracy: 0.6777 - val_loss: 1.1806 - val_binary_accuracy: 0.5107\n",
      "Epoch 25/36\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4824 - binary_accuracy: 0.6777 - val_loss: 1.2739 - val_binary_accuracy: 0.5179\n",
      "Epoch 26/36\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4828 - binary_accuracy: 0.6777 - val_loss: 1.4022 - val_binary_accuracy: 0.5107\n",
      "Epoch 27/36\n",
      "112/112 [==============================] - 26s 233ms/step - loss: 0.4807 - binary_accuracy: 0.6786 - val_loss: 1.5438 - val_binary_accuracy: 0.5214\n",
      "Epoch 28/36\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4774 - binary_accuracy: 0.6795 - val_loss: 1.5537 - val_binary_accuracy: 0.5143\n",
      "Epoch 29/36\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4776 - binary_accuracy: 0.6795 - val_loss: 1.5934 - val_binary_accuracy: 0.5143\n",
      "Epoch 30/36\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4768 - binary_accuracy: 0.6795 - val_loss: 1.6245 - val_binary_accuracy: 0.5143\n",
      "Epoch 31/36\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4781 - binary_accuracy: 0.6795 - val_loss: 1.6403 - val_binary_accuracy: 0.5143\n",
      "Epoch 32/36\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4775 - binary_accuracy: 0.6795 - val_loss: 1.6548 - val_binary_accuracy: 0.5143\n",
      "Epoch 33/36\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4777 - binary_accuracy: 0.6795 - val_loss: 1.6678 - val_binary_accuracy: 0.5143\n",
      "Epoch 34/36\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4773 - binary_accuracy: 0.6795 - val_loss: 1.6658 - val_binary_accuracy: 0.5143\n",
      "Epoch 35/36\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4772 - binary_accuracy: 0.6795 - val_loss: 1.6842 - val_binary_accuracy: 0.5143\n",
      "Epoch 36/36\n",
      "112/112 [==============================] - 26s 232ms/step - loss: 0.4773 - binary_accuracy: 0.6795 - val_loss: 1.6973 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.7212 - binary_accuracy: 0.6471\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.8143 - binary_accuracy: 0.5267\n",
      "training start... epochs = 37\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_50 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_40 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_98 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_99 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/37\n",
      "112/112 [==============================] - 44s 295ms/step - loss: 0.6929 - binary_accuracy: 0.5143 - val_loss: 0.6893 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/37\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.6744 - binary_accuracy: 0.5643 - val_loss: 0.6917 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/37\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.6098 - binary_accuracy: 0.6348 - val_loss: 0.8681 - val_binary_accuracy: 0.5179\n",
      "Epoch 4/37\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.5961 - binary_accuracy: 0.6527 - val_loss: 0.8938 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/37\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.5259 - binary_accuracy: 0.6616 - val_loss: 0.8190 - val_binary_accuracy: 0.4929\n",
      "Epoch 6/37\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4918 - binary_accuracy: 0.6643 - val_loss: 0.9318 - val_binary_accuracy: 0.5179\n",
      "Epoch 7/37\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4873 - binary_accuracy: 0.6759 - val_loss: 1.0599 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/37\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4854 - binary_accuracy: 0.6830 - val_loss: 0.9201 - val_binary_accuracy: 0.5143\n",
      "Epoch 9/37\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4830 - binary_accuracy: 0.6848 - val_loss: 1.1478 - val_binary_accuracy: 0.4893\n",
      "Epoch 10/37\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4771 - binary_accuracy: 0.6857 - val_loss: 0.9667 - val_binary_accuracy: 0.4964\n",
      "Epoch 11/37\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4867 - binary_accuracy: 0.6732 - val_loss: 1.1643 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/37\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4792 - binary_accuracy: 0.6902 - val_loss: 1.1866 - val_binary_accuracy: 0.4964\n",
      "Epoch 13/37\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4792 - binary_accuracy: 0.6875 - val_loss: 0.9716 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/37\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4813 - binary_accuracy: 0.6786 - val_loss: 1.1800 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4695 - binary_accuracy: 0.6875 - val_loss: 1.8595 - val_binary_accuracy: 0.4964\n",
      "Epoch 16/37\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4919 - binary_accuracy: 0.6750 - val_loss: 1.0139 - val_binary_accuracy: 0.5036\n",
      "Epoch 17/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.7023 - binary_accuracy: 0.6509 - val_loss: 0.7935 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.5311 - binary_accuracy: 0.6420 - val_loss: 0.8703 - val_binary_accuracy: 0.5107\n",
      "Epoch 19/37\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4964 - binary_accuracy: 0.6750 - val_loss: 0.9676 - val_binary_accuracy: 0.5179\n",
      "Epoch 20/37\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4890 - binary_accuracy: 0.6723 - val_loss: 1.0071 - val_binary_accuracy: 0.5179\n",
      "Epoch 21/37\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4830 - binary_accuracy: 0.6804 - val_loss: 1.0595 - val_binary_accuracy: 0.5143\n",
      "Epoch 22/37\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.5144 - binary_accuracy: 0.6580 - val_loss: 1.1873 - val_binary_accuracy: 0.5071\n",
      "Epoch 23/37\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.5163 - binary_accuracy: 0.6491 - val_loss: 1.2977 - val_binary_accuracy: 0.4893\n",
      "Epoch 24/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.5134 - binary_accuracy: 0.6375 - val_loss: 1.2681 - val_binary_accuracy: 0.5107\n",
      "Epoch 25/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.5106 - binary_accuracy: 0.6464 - val_loss: 1.2834 - val_binary_accuracy: 0.5143\n",
      "Epoch 26/37\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.5079 - binary_accuracy: 0.6527 - val_loss: 1.3052 - val_binary_accuracy: 0.5107\n",
      "Epoch 27/37\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.5069 - binary_accuracy: 0.6527 - val_loss: 1.3244 - val_binary_accuracy: 0.5071\n",
      "Epoch 28/37\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.5053 - binary_accuracy: 0.6527 - val_loss: 1.3425 - val_binary_accuracy: 0.5143\n",
      "Epoch 29/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.5037 - binary_accuracy: 0.6562 - val_loss: 1.2205 - val_binary_accuracy: 0.5071\n",
      "Epoch 30/37\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.5954 - binary_accuracy: 0.5973 - val_loss: 1.0309 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/37\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.5587 - binary_accuracy: 0.6277 - val_loss: 1.2953 - val_binary_accuracy: 0.5214\n",
      "Epoch 32/37\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4947 - binary_accuracy: 0.6545 - val_loss: 1.3636 - val_binary_accuracy: 0.5214\n",
      "Epoch 33/37\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4910 - binary_accuracy: 0.6723 - val_loss: 1.3173 - val_binary_accuracy: 0.5071\n",
      "Epoch 34/37\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4928 - binary_accuracy: 0.6616 - val_loss: 1.2972 - val_binary_accuracy: 0.4964\n",
      "Epoch 35/37\n",
      "112/112 [==============================] - 26s 235ms/step - loss: 0.4842 - binary_accuracy: 0.6759 - val_loss: 1.3572 - val_binary_accuracy: 0.5143\n",
      "Epoch 36/37\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4862 - binary_accuracy: 0.6723 - val_loss: 1.3847 - val_binary_accuracy: 0.5179\n",
      "Epoch 37/37\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4841 - binary_accuracy: 0.6750 - val_loss: 1.4566 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6778 - binary_accuracy: 0.6421\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.4812 - binary_accuracy: 0.5500\n",
      "training start... epochs = 38\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/38\n",
      "112/112 [==============================] - 45s 300ms/step - loss: 0.7077 - binary_accuracy: 0.5205 - val_loss: 0.6921 - val_binary_accuracy: 0.5286\n",
      "Epoch 2/38\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.6908 - binary_accuracy: 0.5643 - val_loss: 0.6897 - val_binary_accuracy: 0.5393\n",
      "Epoch 3/38\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.6525 - binary_accuracy: 0.6071 - val_loss: 0.7207 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/38\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5827 - binary_accuracy: 0.6402 - val_loss: 0.7784 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/38\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5220 - binary_accuracy: 0.6616 - val_loss: 0.9264 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/38\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4938 - binary_accuracy: 0.6759 - val_loss: 1.0424 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/38\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4892 - binary_accuracy: 0.6741 - val_loss: 1.0992 - val_binary_accuracy: 0.4964\n",
      "Epoch 8/38\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4830 - binary_accuracy: 0.6795 - val_loss: 1.3529 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/38\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4965 - binary_accuracy: 0.6741 - val_loss: 0.9746 - val_binary_accuracy: 0.5143\n",
      "Epoch 10/38\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4852 - binary_accuracy: 0.6696 - val_loss: 1.1223 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/38\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4827 - binary_accuracy: 0.6786 - val_loss: 1.3325 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/38\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4853 - binary_accuracy: 0.6696 - val_loss: 1.0663 - val_binary_accuracy: 0.5179\n",
      "Epoch 13/38\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4927 - binary_accuracy: 0.6777 - val_loss: 1.0579 - val_binary_accuracy: 0.5321\n",
      "Epoch 14/38\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.5068 - binary_accuracy: 0.6741 - val_loss: 0.9531 - val_binary_accuracy: 0.5179\n",
      "Epoch 15/38\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4902 - binary_accuracy: 0.6804 - val_loss: 0.8854 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4814 - binary_accuracy: 0.6812 - val_loss: 0.8614 - val_binary_accuracy: 0.5286\n",
      "Epoch 17/38\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.4898 - binary_accuracy: 0.6804 - val_loss: 0.9178 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/38\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4808 - binary_accuracy: 0.6848 - val_loss: 1.0222 - val_binary_accuracy: 0.5107\n",
      "Epoch 19/38\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4805 - binary_accuracy: 0.6839 - val_loss: 1.2931 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/38\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4966 - binary_accuracy: 0.6830 - val_loss: 1.3426 - val_binary_accuracy: 0.5321\n",
      "Epoch 21/38\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.4982 - binary_accuracy: 0.6777 - val_loss: 1.5971 - val_binary_accuracy: 0.5179\n",
      "Epoch 22/38\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.5575 - binary_accuracy: 0.6768 - val_loss: 0.8502 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4823 - binary_accuracy: 0.6839 - val_loss: 1.0448 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/38\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4801 - binary_accuracy: 0.6875 - val_loss: 1.0808 - val_binary_accuracy: 0.5429\n",
      "Epoch 25/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4744 - binary_accuracy: 0.6884 - val_loss: 1.1688 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/38\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.7769 - binary_accuracy: 0.6054 - val_loss: 0.8242 - val_binary_accuracy: 0.4893\n",
      "Epoch 27/38\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.7062 - binary_accuracy: 0.5000 - val_loss: 0.6961 - val_binary_accuracy: 0.4893\n",
      "Epoch 28/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.6964 - binary_accuracy: 0.4982 - val_loss: 0.6997 - val_binary_accuracy: 0.4893\n",
      "Epoch 29/38\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.6965 - binary_accuracy: 0.4884 - val_loss: 0.6946 - val_binary_accuracy: 0.4893\n",
      "Epoch 30/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.6927 - binary_accuracy: 0.5080 - val_loss: 0.6927 - val_binary_accuracy: 0.5107\n",
      "Epoch 31/38\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.6935 - binary_accuracy: 0.4964 - val_loss: 0.6943 - val_binary_accuracy: 0.4893\n",
      "Epoch 32/38\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.6926 - binary_accuracy: 0.5054 - val_loss: 0.6948 - val_binary_accuracy: 0.4893\n",
      "Epoch 33/38\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.6928 - binary_accuracy: 0.5107 - val_loss: 0.6943 - val_binary_accuracy: 0.4893\n",
      "Epoch 34/38\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.6925 - binary_accuracy: 0.5188 - val_loss: 0.6937 - val_binary_accuracy: 0.4893\n",
      "Epoch 35/38\n",
      "112/112 [==============================] - 26s 236ms/step - loss: 0.6914 - binary_accuracy: 0.5179 - val_loss: 0.6925 - val_binary_accuracy: 0.5107\n",
      "Epoch 36/38\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.6907 - binary_accuracy: 0.5214 - val_loss: 0.6946 - val_binary_accuracy: 0.4893\n",
      "Epoch 37/38\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.6925 - binary_accuracy: 0.5152 - val_loss: 0.6938 - val_binary_accuracy: 0.4929\n",
      "Epoch 38/38\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.6871 - binary_accuracy: 0.5482 - val_loss: 0.6920 - val_binary_accuracy: 0.5071\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6844 - binary_accuracy: 0.5929\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.6913 - binary_accuracy: 0.5183\n",
      "training start... epochs = 39\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_52 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_42 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/39\n",
      "112/112 [==============================] - 45s 302ms/step - loss: 0.6928 - binary_accuracy: 0.5188 - val_loss: 0.6892 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/39\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.7878 - binary_accuracy: 0.5545 - val_loss: 0.6872 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/39\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.6394 - binary_accuracy: 0.6250 - val_loss: 0.7392 - val_binary_accuracy: 0.5179\n",
      "Epoch 4/39\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.5811 - binary_accuracy: 0.6625 - val_loss: 0.8229 - val_binary_accuracy: 0.5429\n",
      "Epoch 5/39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5184 - binary_accuracy: 0.6509 - val_loss: 0.8432 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/39\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4966 - binary_accuracy: 0.6634 - val_loss: 0.8587 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/39\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4998 - binary_accuracy: 0.6616 - val_loss: 0.8939 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/39\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4882 - binary_accuracy: 0.6812 - val_loss: 0.9584 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/39\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4888 - binary_accuracy: 0.6795 - val_loss: 0.9132 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/39\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4823 - binary_accuracy: 0.6759 - val_loss: 0.9497 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/39\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4855 - binary_accuracy: 0.6830 - val_loss: 0.9982 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/39\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4773 - binary_accuracy: 0.6786 - val_loss: 1.3353 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/39\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4866 - binary_accuracy: 0.6830 - val_loss: 0.8926 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/39\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4854 - binary_accuracy: 0.6562 - val_loss: 1.0094 - val_binary_accuracy: 0.5321\n",
      "Epoch 15/39\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4814 - binary_accuracy: 0.6786 - val_loss: 1.3867 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4853 - binary_accuracy: 0.6741 - val_loss: 1.0295 - val_binary_accuracy: 0.5250\n",
      "Epoch 17/39\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4737 - binary_accuracy: 0.6795 - val_loss: 1.0899 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/39\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4895 - binary_accuracy: 0.6768 - val_loss: 1.1505 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4784 - binary_accuracy: 0.6777 - val_loss: 0.9264 - val_binary_accuracy: 0.5143\n",
      "Epoch 20/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4775 - binary_accuracy: 0.6786 - val_loss: 1.1730 - val_binary_accuracy: 0.5286\n",
      "Epoch 21/39\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4712 - binary_accuracy: 0.6830 - val_loss: 1.2065 - val_binary_accuracy: 0.5357\n",
      "Epoch 22/39\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4733 - binary_accuracy: 0.6812 - val_loss: 1.2798 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/39\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4741 - binary_accuracy: 0.6821 - val_loss: 1.0582 - val_binary_accuracy: 0.5214\n",
      "Epoch 24/39\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4745 - binary_accuracy: 0.6777 - val_loss: 1.0823 - val_binary_accuracy: 0.5214\n",
      "Epoch 25/39\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4834 - binary_accuracy: 0.6759 - val_loss: 1.0953 - val_binary_accuracy: 0.5214\n",
      "Epoch 26/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4885 - binary_accuracy: 0.6759 - val_loss: 1.2242 - val_binary_accuracy: 0.5143\n",
      "Epoch 27/39\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4754 - binary_accuracy: 0.6714 - val_loss: 1.4256 - val_binary_accuracy: 0.5071\n",
      "Epoch 28/39\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4722 - binary_accuracy: 0.6777 - val_loss: 1.4915 - val_binary_accuracy: 0.5107\n",
      "Epoch 29/39\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4710 - binary_accuracy: 0.6795 - val_loss: 1.6861 - val_binary_accuracy: 0.5107\n",
      "Epoch 30/39\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4713 - binary_accuracy: 0.6795 - val_loss: 1.5553 - val_binary_accuracy: 0.4964\n",
      "Epoch 31/39\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4864 - binary_accuracy: 0.6741 - val_loss: 1.3596 - val_binary_accuracy: 0.5036\n",
      "Epoch 32/39\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4731 - binary_accuracy: 0.6795 - val_loss: 1.4157 - val_binary_accuracy: 0.5036\n",
      "Epoch 33/39\n",
      "112/112 [==============================] - 26s 234ms/step - loss: 0.4703 - binary_accuracy: 0.6795 - val_loss: 1.4353 - val_binary_accuracy: 0.5107\n",
      "Epoch 34/39\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4702 - binary_accuracy: 0.6795 - val_loss: 1.4504 - val_binary_accuracy: 0.5107\n",
      "Epoch 35/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4699 - binary_accuracy: 0.6795 - val_loss: 1.4659 - val_binary_accuracy: 0.5107\n",
      "Epoch 36/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4704 - binary_accuracy: 0.6795 - val_loss: 1.4785 - val_binary_accuracy: 0.5107\n",
      "Epoch 37/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4702 - binary_accuracy: 0.6795 - val_loss: 1.4900 - val_binary_accuracy: 0.5143\n",
      "Epoch 38/39\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4700 - binary_accuracy: 0.6795 - val_loss: 1.5024 - val_binary_accuracy: 0.5143\n",
      "Epoch 39/39\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4701 - binary_accuracy: 0.6795 - val_loss: 1.5129 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6785 - binary_accuracy: 0.6464\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.5132 - binary_accuracy: 0.5367\n",
      "training start... epochs = 40\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_53 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "112/112 [==============================] - 44s 304ms/step - loss: 0.6932 - binary_accuracy: 0.5152 - val_loss: 0.6913 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/40\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.6709 - binary_accuracy: 0.5768 - val_loss: 0.6971 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/40\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.6214 - binary_accuracy: 0.6339 - val_loss: 0.7142 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/40\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5789 - binary_accuracy: 0.6661 - val_loss: 0.7405 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/40\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.5246 - binary_accuracy: 0.6607 - val_loss: 0.8242 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/40\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4984 - binary_accuracy: 0.6705 - val_loss: 0.8956 - val_binary_accuracy: 0.4929\n",
      "Epoch 7/40\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5005 - binary_accuracy: 0.6723 - val_loss: 0.8926 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/40\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4855 - binary_accuracy: 0.6786 - val_loss: 1.0381 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/40\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4834 - binary_accuracy: 0.6777 - val_loss: 1.0613 - val_binary_accuracy: 0.5179\n",
      "Epoch 10/40\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.5144 - binary_accuracy: 0.6714 - val_loss: 0.8985 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/40\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4850 - binary_accuracy: 0.6661 - val_loss: 1.0078 - val_binary_accuracy: 0.5179\n",
      "Epoch 12/40\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4805 - binary_accuracy: 0.6786 - val_loss: 0.9897 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/40\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4894 - binary_accuracy: 0.6679 - val_loss: 0.9349 - val_binary_accuracy: 0.5036\n",
      "Epoch 14/40\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4845 - binary_accuracy: 0.6723 - val_loss: 1.1207 - val_binary_accuracy: 0.5107\n",
      "Epoch 15/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4958 - binary_accuracy: 0.6652 - val_loss: 0.9487 - val_binary_accuracy: 0.5143\n",
      "Epoch 16/40\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4877 - binary_accuracy: 0.6777 - val_loss: 1.0141 - val_binary_accuracy: 0.4964\n",
      "Epoch 17/40\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4855 - binary_accuracy: 0.6777 - val_loss: 1.0910 - val_binary_accuracy: 0.5071\n",
      "Epoch 18/40\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4852 - binary_accuracy: 0.6786 - val_loss: 1.1896 - val_binary_accuracy: 0.5036\n",
      "Epoch 19/40\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4857 - binary_accuracy: 0.6884 - val_loss: 0.9808 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4827 - binary_accuracy: 0.6786 - val_loss: 1.0206 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/40\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4849 - binary_accuracy: 0.6741 - val_loss: 1.0879 - val_binary_accuracy: 0.5071\n",
      "Epoch 22/40\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4817 - binary_accuracy: 0.6795 - val_loss: 1.1534 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/40\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4931 - binary_accuracy: 0.6759 - val_loss: 1.0135 - val_binary_accuracy: 0.5179\n",
      "Epoch 24/40\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4846 - binary_accuracy: 0.6786 - val_loss: 1.1411 - val_binary_accuracy: 0.5107\n",
      "Epoch 25/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4889 - binary_accuracy: 0.6741 - val_loss: 1.1960 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4820 - binary_accuracy: 0.6786 - val_loss: 1.2644 - val_binary_accuracy: 0.5250\n",
      "Epoch 27/40\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4891 - binary_accuracy: 0.6786 - val_loss: 0.9611 - val_binary_accuracy: 0.5143\n",
      "Epoch 28/40\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4884 - binary_accuracy: 0.6768 - val_loss: 1.0440 - val_binary_accuracy: 0.5179\n",
      "Epoch 29/40\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4840 - binary_accuracy: 0.6777 - val_loss: 1.1216 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4821 - binary_accuracy: 0.6795 - val_loss: 1.1957 - val_binary_accuracy: 0.5214\n",
      "Epoch 31/40\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4809 - binary_accuracy: 0.6759 - val_loss: 1.3033 - val_binary_accuracy: 0.5143\n",
      "Epoch 32/40\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4803 - binary_accuracy: 0.6786 - val_loss: 1.2548 - val_binary_accuracy: 0.5071\n",
      "Epoch 33/40\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4791 - binary_accuracy: 0.6795 - val_loss: 1.4031 - val_binary_accuracy: 0.5143\n",
      "Epoch 34/40\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.5092 - binary_accuracy: 0.6821 - val_loss: 1.1651 - val_binary_accuracy: 0.5036\n",
      "Epoch 35/40\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4774 - binary_accuracy: 0.6741 - val_loss: 1.3220 - val_binary_accuracy: 0.5071\n",
      "Epoch 36/40\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4875 - binary_accuracy: 0.6857 - val_loss: 1.0326 - val_binary_accuracy: 0.5143\n",
      "Epoch 37/40\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4840 - binary_accuracy: 0.6768 - val_loss: 1.1174 - val_binary_accuracy: 0.5071\n",
      "Epoch 38/40\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4811 - binary_accuracy: 0.6812 - val_loss: 1.2077 - val_binary_accuracy: 0.5143\n",
      "Epoch 39/40\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4790 - binary_accuracy: 0.6821 - val_loss: 1.3114 - val_binary_accuracy: 0.5214\n",
      "Epoch 40/40\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4787 - binary_accuracy: 0.6839 - val_loss: 1.2747 - val_binary_accuracy: 0.5107\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6455 - binary_accuracy: 0.6493\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.3709 - binary_accuracy: 0.5500\n",
      "training start... epochs = 41\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_54 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/41\n",
      "112/112 [==============================] - 46s 305ms/step - loss: 0.6943 - binary_accuracy: 0.5179 - val_loss: 0.6897 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/41\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.8052 - binary_accuracy: 0.5607 - val_loss: 0.7218 - val_binary_accuracy: 0.5107\n",
      "Epoch 3/41\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.6168 - binary_accuracy: 0.6348 - val_loss: 0.7261 - val_binary_accuracy: 0.4857\n",
      "Epoch 4/41\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5747 - binary_accuracy: 0.6571 - val_loss: 0.7518 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5239 - binary_accuracy: 0.6705 - val_loss: 0.8909 - val_binary_accuracy: 0.5071\n",
      "Epoch 6/41\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4893 - binary_accuracy: 0.6670 - val_loss: 1.0265 - val_binary_accuracy: 0.5143\n",
      "Epoch 7/41\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4789 - binary_accuracy: 0.6795 - val_loss: 1.2556 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/41\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4956 - binary_accuracy: 0.6821 - val_loss: 1.0025 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4787 - binary_accuracy: 0.6839 - val_loss: 1.1398 - val_binary_accuracy: 0.4929\n",
      "Epoch 10/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4761 - binary_accuracy: 0.6804 - val_loss: 1.2212 - val_binary_accuracy: 0.4964\n",
      "Epoch 11/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5286 - binary_accuracy: 0.6768 - val_loss: 0.8279 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5064 - binary_accuracy: 0.6732 - val_loss: 0.8599 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4882 - binary_accuracy: 0.6732 - val_loss: 1.0039 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4776 - binary_accuracy: 0.6812 - val_loss: 1.1481 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/41\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.5535 - binary_accuracy: 0.6598 - val_loss: 0.9440 - val_binary_accuracy: 0.5107\n",
      "Epoch 16/41\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4824 - binary_accuracy: 0.6777 - val_loss: 1.0543 - val_binary_accuracy: 0.5179\n",
      "Epoch 17/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4806 - binary_accuracy: 0.6598 - val_loss: 1.1182 - val_binary_accuracy: 0.5250\n",
      "Epoch 18/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4778 - binary_accuracy: 0.6795 - val_loss: 1.2283 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4756 - binary_accuracy: 0.6839 - val_loss: 1.3428 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4759 - binary_accuracy: 0.6893 - val_loss: 1.0852 - val_binary_accuracy: 0.5179\n",
      "Epoch 21/41\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4907 - binary_accuracy: 0.6786 - val_loss: 1.1305 - val_binary_accuracy: 0.4964\n",
      "Epoch 22/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4749 - binary_accuracy: 0.6830 - val_loss: 1.3092 - val_binary_accuracy: 0.5214\n",
      "Epoch 23/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4672 - binary_accuracy: 0.6902 - val_loss: 1.3620 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4658 - binary_accuracy: 0.6920 - val_loss: 1.4777 - val_binary_accuracy: 0.4893\n",
      "Epoch 25/41\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4702 - binary_accuracy: 0.6848 - val_loss: 1.4947 - val_binary_accuracy: 0.5143\n",
      "Epoch 26/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4709 - binary_accuracy: 0.6938 - val_loss: 1.5875 - val_binary_accuracy: 0.5536\n",
      "Epoch 27/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.5168 - binary_accuracy: 0.6679 - val_loss: 1.0118 - val_binary_accuracy: 0.5143\n",
      "Epoch 28/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4863 - binary_accuracy: 0.6732 - val_loss: 1.0881 - val_binary_accuracy: 0.5071\n",
      "Epoch 29/41\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.5327 - binary_accuracy: 0.6580 - val_loss: 0.8296 - val_binary_accuracy: 0.5321\n",
      "Epoch 30/41\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.5000 - binary_accuracy: 0.6750 - val_loss: 0.9232 - val_binary_accuracy: 0.5143\n",
      "Epoch 31/41\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4869 - binary_accuracy: 0.6741 - val_loss: 0.9806 - val_binary_accuracy: 0.5071\n",
      "Epoch 32/41\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4870 - binary_accuracy: 0.6759 - val_loss: 1.0225 - val_binary_accuracy: 0.5071\n",
      "Epoch 33/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4857 - binary_accuracy: 0.6777 - val_loss: 1.0576 - val_binary_accuracy: 0.5107\n",
      "Epoch 34/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4858 - binary_accuracy: 0.6777 - val_loss: 1.0914 - val_binary_accuracy: 0.5071\n",
      "Epoch 35/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4841 - binary_accuracy: 0.6786 - val_loss: 1.1375 - val_binary_accuracy: 0.5143\n",
      "Epoch 36/41\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4817 - binary_accuracy: 0.6804 - val_loss: 1.1987 - val_binary_accuracy: 0.5107\n",
      "Epoch 37/41\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4803 - binary_accuracy: 0.6821 - val_loss: 1.2739 - val_binary_accuracy: 0.5179\n",
      "Epoch 38/41\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4930 - binary_accuracy: 0.6795 - val_loss: 0.9606 - val_binary_accuracy: 0.5179\n",
      "Epoch 39/41\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.4908 - binary_accuracy: 0.6768 - val_loss: 1.0217 - val_binary_accuracy: 0.5214\n",
      "Epoch 40/41\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4845 - binary_accuracy: 0.6786 - val_loss: 1.0736 - val_binary_accuracy: 0.5214\n",
      "Epoch 41/41\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.4840 - binary_accuracy: 0.6777 - val_loss: 1.1131 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6088 - binary_accuracy: 0.6471\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1544 - binary_accuracy: 0.5350\n",
      "training start... epochs = 42\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_55 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/42\n",
      "112/112 [==============================] - 45s 298ms/step - loss: 0.6934 - binary_accuracy: 0.5116 - val_loss: 0.6908 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/42\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.6775 - binary_accuracy: 0.5625 - val_loss: 0.7624 - val_binary_accuracy: 0.5321\n",
      "Epoch 3/42\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.6262 - binary_accuracy: 0.6357 - val_loss: 0.7428 - val_binary_accuracy: 0.4964\n",
      "Epoch 4/42\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5698 - binary_accuracy: 0.6518 - val_loss: 0.8368 - val_binary_accuracy: 0.5143\n",
      "Epoch 5/42\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5268 - binary_accuracy: 0.6554 - val_loss: 0.8888 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/42\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4986 - binary_accuracy: 0.6571 - val_loss: 0.9907 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/42\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4904 - binary_accuracy: 0.6714 - val_loss: 0.9300 - val_binary_accuracy: 0.5143\n",
      "Epoch 8/42\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4905 - binary_accuracy: 0.6705 - val_loss: 0.9667 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/42\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4848 - binary_accuracy: 0.6795 - val_loss: 1.0490 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/42\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4816 - binary_accuracy: 0.6812 - val_loss: 1.2696 - val_binary_accuracy: 0.5071\n",
      "Epoch 11/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4843 - binary_accuracy: 0.6786 - val_loss: 1.0378 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/42\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4975 - binary_accuracy: 0.6768 - val_loss: 0.9670 - val_binary_accuracy: 0.5214\n",
      "Epoch 13/42\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4880 - binary_accuracy: 0.6777 - val_loss: 0.8973 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/42\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4873 - binary_accuracy: 0.6777 - val_loss: 1.0384 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/42\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4871 - binary_accuracy: 0.6768 - val_loss: 0.9460 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/42\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4847 - binary_accuracy: 0.6786 - val_loss: 1.1126 - val_binary_accuracy: 0.5143\n",
      "Epoch 17/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4829 - binary_accuracy: 0.6804 - val_loss: 1.1731 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/42\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4960 - binary_accuracy: 0.6786 - val_loss: 0.8604 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4881 - binary_accuracy: 0.6759 - val_loss: 1.0475 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4847 - binary_accuracy: 0.6786 - val_loss: 1.1463 - val_binary_accuracy: 0.5143\n",
      "Epoch 21/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4817 - binary_accuracy: 0.6812 - val_loss: 1.2095 - val_binary_accuracy: 0.5214\n",
      "Epoch 22/42\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4847 - binary_accuracy: 0.6839 - val_loss: 1.0744 - val_binary_accuracy: 0.5179\n",
      "Epoch 23/42\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4940 - binary_accuracy: 0.6750 - val_loss: 0.9998 - val_binary_accuracy: 0.5179\n",
      "Epoch 24/42\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4812 - binary_accuracy: 0.6848 - val_loss: 1.2984 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/42\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.5039 - binary_accuracy: 0.6723 - val_loss: 1.0947 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/42\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4851 - binary_accuracy: 0.6786 - val_loss: 1.2160 - val_binary_accuracy: 0.5071\n",
      "Epoch 27/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4835 - binary_accuracy: 0.6786 - val_loss: 1.4260 - val_binary_accuracy: 0.4929\n",
      "Epoch 28/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4868 - binary_accuracy: 0.6768 - val_loss: 1.1295 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/42\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4821 - binary_accuracy: 0.6634 - val_loss: 1.3221 - val_binary_accuracy: 0.5107\n",
      "Epoch 30/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4909 - binary_accuracy: 0.6786 - val_loss: 1.1378 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4856 - binary_accuracy: 0.6777 - val_loss: 1.2042 - val_binary_accuracy: 0.5036\n",
      "Epoch 32/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4831 - binary_accuracy: 0.6795 - val_loss: 1.2770 - val_binary_accuracy: 0.5071\n",
      "Epoch 33/42\n",
      "112/112 [==============================] - 27s 238ms/step - loss: 0.4821 - binary_accuracy: 0.6812 - val_loss: 1.2246 - val_binary_accuracy: 0.5036\n",
      "Epoch 34/42\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4800 - binary_accuracy: 0.6839 - val_loss: 1.1537 - val_binary_accuracy: 0.5107\n",
      "Epoch 35/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4902 - binary_accuracy: 0.6839 - val_loss: 0.9883 - val_binary_accuracy: 0.5286\n",
      "Epoch 36/42\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4921 - binary_accuracy: 0.6643 - val_loss: 1.1956 - val_binary_accuracy: 0.4964\n",
      "Epoch 37/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4848 - binary_accuracy: 0.6786 - val_loss: 1.2974 - val_binary_accuracy: 0.4964\n",
      "Epoch 38/42\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4833 - binary_accuracy: 0.6786 - val_loss: 1.3653 - val_binary_accuracy: 0.4964\n",
      "Epoch 39/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4824 - binary_accuracy: 0.6804 - val_loss: 1.4490 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/42\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4830 - binary_accuracy: 0.6804 - val_loss: 1.0437 - val_binary_accuracy: 0.5071\n",
      "Epoch 41/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4852 - binary_accuracy: 0.6804 - val_loss: 1.2212 - val_binary_accuracy: 0.5107\n",
      "Epoch 42/42\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4850 - binary_accuracy: 0.6795 - val_loss: 1.2308 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6324 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1244 - binary_accuracy: 0.5450\n",
      "training start... epochs = 43\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_56 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_46 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/43\n",
      "112/112 [==============================] - 45s 304ms/step - loss: 0.6932 - binary_accuracy: 0.5080 - val_loss: 0.6893 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/43\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.7065 - binary_accuracy: 0.5589 - val_loss: 0.6861 - val_binary_accuracy: 0.5464\n",
      "Epoch 3/43\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.6166 - binary_accuracy: 0.6241 - val_loss: 0.7372 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/43\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5741 - binary_accuracy: 0.6518 - val_loss: 0.7862 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/43\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5249 - binary_accuracy: 0.6607 - val_loss: 1.0572 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/43\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5079 - binary_accuracy: 0.6714 - val_loss: 0.9240 - val_binary_accuracy: 0.5179\n",
      "Epoch 7/43\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4890 - binary_accuracy: 0.6777 - val_loss: 0.9766 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/43\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4955 - binary_accuracy: 0.6723 - val_loss: 0.9397 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4874 - binary_accuracy: 0.6812 - val_loss: 1.0120 - val_binary_accuracy: 0.5179\n",
      "Epoch 10/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4845 - binary_accuracy: 0.6812 - val_loss: 1.1319 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4742 - binary_accuracy: 0.6857 - val_loss: 1.6271 - val_binary_accuracy: 0.5107\n",
      "Epoch 12/43\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4881 - binary_accuracy: 0.6759 - val_loss: 1.0579 - val_binary_accuracy: 0.5107\n",
      "Epoch 13/43\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4953 - binary_accuracy: 0.6768 - val_loss: 1.0595 - val_binary_accuracy: 0.5071\n",
      "Epoch 14/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4770 - binary_accuracy: 0.6848 - val_loss: 1.3294 - val_binary_accuracy: 0.5071\n",
      "Epoch 15/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4982 - binary_accuracy: 0.6625 - val_loss: 1.0233 - val_binary_accuracy: 0.5250\n",
      "Epoch 16/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4838 - binary_accuracy: 0.6777 - val_loss: 1.4818 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/43\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4921 - binary_accuracy: 0.6723 - val_loss: 1.0107 - val_binary_accuracy: 0.5357\n",
      "Epoch 18/43\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4841 - binary_accuracy: 0.6768 - val_loss: 1.1126 - val_binary_accuracy: 0.5286\n",
      "Epoch 19/43\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4812 - binary_accuracy: 0.6768 - val_loss: 1.2062 - val_binary_accuracy: 0.5250\n",
      "Epoch 20/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 1.1524 - binary_accuracy: 0.5973 - val_loss: 0.6963 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/43\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.6986 - binary_accuracy: 0.4875 - val_loss: 0.6966 - val_binary_accuracy: 0.4893\n",
      "Epoch 22/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.6946 - binary_accuracy: 0.5161 - val_loss: 0.6977 - val_binary_accuracy: 0.4964\n",
      "Epoch 23/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.6887 - binary_accuracy: 0.5241 - val_loss: 0.7003 - val_binary_accuracy: 0.4964\n",
      "Epoch 24/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.6862 - binary_accuracy: 0.5366 - val_loss: 0.6942 - val_binary_accuracy: 0.5071\n",
      "Epoch 25/43\n",
      "112/112 [==============================] - 26s 237ms/step - loss: 0.6811 - binary_accuracy: 0.5545 - val_loss: 0.6955 - val_binary_accuracy: 0.4857\n",
      "Epoch 26/43\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.6718 - binary_accuracy: 0.5491 - val_loss: 0.7082 - val_binary_accuracy: 0.4964\n",
      "Epoch 27/43\n",
      "112/112 [==============================] - 27s 237ms/step - loss: 0.6552 - binary_accuracy: 0.6027 - val_loss: 0.7002 - val_binary_accuracy: 0.4714\n",
      "Epoch 28/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.6368 - binary_accuracy: 0.5929 - val_loss: 0.7105 - val_binary_accuracy: 0.4786\n",
      "Epoch 29/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.6250 - binary_accuracy: 0.5821 - val_loss: 0.7147 - val_binary_accuracy: 0.4929\n",
      "Epoch 30/43\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.6047 - binary_accuracy: 0.5777 - val_loss: 0.7284 - val_binary_accuracy: 0.4964\n",
      "Epoch 31/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.5977 - binary_accuracy: 0.6071 - val_loss: 0.8339 - val_binary_accuracy: 0.4964\n",
      "Epoch 32/43\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.5669 - binary_accuracy: 0.6321 - val_loss: 0.7789 - val_binary_accuracy: 0.5036\n",
      "Epoch 33/43\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.5598 - binary_accuracy: 0.6509 - val_loss: 0.7565 - val_binary_accuracy: 0.5179\n",
      "Epoch 34/43\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.5558 - binary_accuracy: 0.6438 - val_loss: 0.7434 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/43\n",
      "112/112 [==============================] - 27s 239ms/step - loss: 0.5338 - binary_accuracy: 0.6643 - val_loss: 0.8178 - val_binary_accuracy: 0.4750\n",
      "Epoch 36/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.5152 - binary_accuracy: 0.6348 - val_loss: 0.8430 - val_binary_accuracy: 0.5071\n",
      "Epoch 37/43\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.5075 - binary_accuracy: 0.6455 - val_loss: 0.8030 - val_binary_accuracy: 0.5036\n",
      "Epoch 38/43\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4967 - binary_accuracy: 0.6518 - val_loss: 0.8373 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/43\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.5014 - binary_accuracy: 0.6554 - val_loss: 0.8888 - val_binary_accuracy: 0.5214\n",
      "Epoch 40/43\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5023 - binary_accuracy: 0.6705 - val_loss: 0.9189 - val_binary_accuracy: 0.5179\n",
      "Epoch 41/43\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.5104 - binary_accuracy: 0.6643 - val_loss: 0.8211 - val_binary_accuracy: 0.5107\n",
      "Epoch 42/43\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4974 - binary_accuracy: 0.6545 - val_loss: 0.8492 - val_binary_accuracy: 0.5143\n",
      "Epoch 43/43\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4982 - binary_accuracy: 0.6571 - val_loss: 0.9151 - val_binary_accuracy: 0.5071\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.5710 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.8838 - binary_accuracy: 0.5683\n",
      "training start... epochs = 44\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_47 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/44\n",
      "112/112 [==============================] - 46s 305ms/step - loss: 0.6944 - binary_accuracy: 0.5071 - val_loss: 0.6905 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/44\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.7124 - binary_accuracy: 0.5580 - val_loss: 0.6906 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/44\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.6392 - binary_accuracy: 0.6098 - val_loss: 0.7620 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/44\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.5621 - binary_accuracy: 0.6420 - val_loss: 0.7922 - val_binary_accuracy: 0.5071\n",
      "Epoch 5/44\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5000 - binary_accuracy: 0.6705 - val_loss: 0.9121 - val_binary_accuracy: 0.5036\n",
      "Epoch 6/44\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4863 - binary_accuracy: 0.6759 - val_loss: 1.0777 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.8726 - binary_accuracy: 0.5902 - val_loss: 0.7461 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/44\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.6006 - binary_accuracy: 0.6384 - val_loss: 0.7467 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5631 - binary_accuracy: 0.6384 - val_loss: 0.7789 - val_binary_accuracy: 0.5143\n",
      "Epoch 10/44\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5365 - binary_accuracy: 0.6429 - val_loss: 0.7966 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/44\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5246 - binary_accuracy: 0.6464 - val_loss: 0.8216 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/44\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5138 - binary_accuracy: 0.6670 - val_loss: 0.8388 - val_binary_accuracy: 0.5071\n",
      "Epoch 13/44\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5106 - binary_accuracy: 0.6562 - val_loss: 0.8420 - val_binary_accuracy: 0.5107\n",
      "Epoch 14/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4904 - binary_accuracy: 0.6750 - val_loss: 0.9411 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4821 - binary_accuracy: 0.6821 - val_loss: 0.9924 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/44\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4776 - binary_accuracy: 0.6795 - val_loss: 1.0138 - val_binary_accuracy: 0.5071\n",
      "Epoch 17/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4694 - binary_accuracy: 0.6875 - val_loss: 1.1434 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/44\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.5783 - binary_accuracy: 0.6812 - val_loss: 1.0706 - val_binary_accuracy: 0.5143\n",
      "Epoch 19/44\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.6033 - binary_accuracy: 0.6179 - val_loss: 0.8127 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5559 - binary_accuracy: 0.6232 - val_loss: 0.8654 - val_binary_accuracy: 0.4857\n",
      "Epoch 21/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5411 - binary_accuracy: 0.6473 - val_loss: 0.8933 - val_binary_accuracy: 0.4821\n",
      "Epoch 22/44\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.5274 - binary_accuracy: 0.6536 - val_loss: 0.8664 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5202 - binary_accuracy: 0.6589 - val_loss: 0.8663 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5155 - binary_accuracy: 0.6634 - val_loss: 0.8700 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5057 - binary_accuracy: 0.6741 - val_loss: 0.9493 - val_binary_accuracy: 0.4857\n",
      "Epoch 26/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5224 - binary_accuracy: 0.6545 - val_loss: 0.8567 - val_binary_accuracy: 0.4857\n",
      "Epoch 27/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5200 - binary_accuracy: 0.6527 - val_loss: 0.9175 - val_binary_accuracy: 0.4821\n",
      "Epoch 28/44\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5094 - binary_accuracy: 0.6420 - val_loss: 0.9940 - val_binary_accuracy: 0.5036\n",
      "Epoch 29/44\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5049 - binary_accuracy: 0.6607 - val_loss: 0.9243 - val_binary_accuracy: 0.5036\n",
      "Epoch 30/44\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5026 - binary_accuracy: 0.6625 - val_loss: 0.9880 - val_binary_accuracy: 0.4964\n",
      "Epoch 31/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5018 - binary_accuracy: 0.6625 - val_loss: 0.9569 - val_binary_accuracy: 0.4964\n",
      "Epoch 32/44\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4995 - binary_accuracy: 0.6545 - val_loss: 1.0482 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5046 - binary_accuracy: 0.6598 - val_loss: 1.0554 - val_binary_accuracy: 0.4821\n",
      "Epoch 34/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4953 - binary_accuracy: 0.6545 - val_loss: 1.0348 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4950 - binary_accuracy: 0.6527 - val_loss: 1.0167 - val_binary_accuracy: 0.5071\n",
      "Epoch 36/44\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4998 - binary_accuracy: 0.6473 - val_loss: 1.0007 - val_binary_accuracy: 0.4964\n",
      "Epoch 37/44\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4922 - binary_accuracy: 0.6768 - val_loss: 1.1553 - val_binary_accuracy: 0.5286\n",
      "Epoch 38/44\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.4972 - binary_accuracy: 0.6518 - val_loss: 1.0280 - val_binary_accuracy: 0.4929\n",
      "Epoch 39/44\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4878 - binary_accuracy: 0.6473 - val_loss: 1.1808 - val_binary_accuracy: 0.5214\n",
      "Epoch 40/44\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4860 - binary_accuracy: 0.6732 - val_loss: 1.1049 - val_binary_accuracy: 0.4964\n",
      "Epoch 41/44\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4919 - binary_accuracy: 0.6625 - val_loss: 1.2039 - val_binary_accuracy: 0.5036\n",
      "Epoch 42/44\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4887 - binary_accuracy: 0.6545 - val_loss: 1.1943 - val_binary_accuracy: 0.5143\n",
      "Epoch 43/44\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4907 - binary_accuracy: 0.6705 - val_loss: 1.1401 - val_binary_accuracy: 0.5071\n",
      "Epoch 44/44\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4854 - binary_accuracy: 0.6509 - val_loss: 1.4116 - val_binary_accuracy: 0.5286\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6611 - binary_accuracy: 0.6579\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.1577 - binary_accuracy: 0.5817\n",
      "training start... epochs = 45\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/45\n",
      "112/112 [==============================] - 47s 317ms/step - loss: 0.6924 - binary_accuracy: 0.5304 - val_loss: 0.6917 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/45\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.6680 - binary_accuracy: 0.5679 - val_loss: 0.6939 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/45\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.5966 - binary_accuracy: 0.6482 - val_loss: 0.7160 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/45\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.5393 - binary_accuracy: 0.6679 - val_loss: 0.7781 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/45\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5214 - binary_accuracy: 0.6759 - val_loss: 0.8978 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/45\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.9270 - binary_accuracy: 0.5795 - val_loss: 0.7122 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/45\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.6792 - binary_accuracy: 0.5580 - val_loss: 0.6897 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 28s 252ms/step - loss: 0.6602 - binary_accuracy: 0.5705 - val_loss: 0.6890 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/45\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5123 - binary_accuracy: 0.6687 - val_loss: 0.8970 - val_binary_accuracy: 0.5321\n",
      "Epoch 10/45\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4898 - binary_accuracy: 0.6786 - val_loss: 0.9404 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4864 - binary_accuracy: 0.6786 - val_loss: 0.9902 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4816 - binary_accuracy: 0.6830 - val_loss: 1.1157 - val_binary_accuracy: 0.5036\n",
      "Epoch 13/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4874 - binary_accuracy: 0.6786 - val_loss: 0.9902 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5121 - binary_accuracy: 0.6714 - val_loss: 0.9130 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/45\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4861 - binary_accuracy: 0.6687 - val_loss: 0.9952 - val_binary_accuracy: 0.5321\n",
      "Epoch 16/45\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4806 - binary_accuracy: 0.6821 - val_loss: 1.2536 - val_binary_accuracy: 0.5429\n",
      "Epoch 17/45\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4876 - binary_accuracy: 0.6768 - val_loss: 1.1625 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4796 - binary_accuracy: 0.6857 - val_loss: 0.9892 - val_binary_accuracy: 0.5250\n",
      "Epoch 19/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4991 - binary_accuracy: 0.6812 - val_loss: 0.9164 - val_binary_accuracy: 0.4964\n",
      "Epoch 20/45\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4899 - binary_accuracy: 0.6786 - val_loss: 0.9460 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4839 - binary_accuracy: 0.6812 - val_loss: 1.0293 - val_binary_accuracy: 0.5036\n",
      "Epoch 22/45\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4843 - binary_accuracy: 0.6821 - val_loss: 1.0390 - val_binary_accuracy: 0.5179\n",
      "Epoch 23/45\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4835 - binary_accuracy: 0.6830 - val_loss: 1.0591 - val_binary_accuracy: 0.5393\n",
      "Epoch 24/45\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4776 - binary_accuracy: 0.6857 - val_loss: 1.1949 - val_binary_accuracy: 0.5321\n",
      "Epoch 25/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4753 - binary_accuracy: 0.6866 - val_loss: 1.3061 - val_binary_accuracy: 0.5179\n",
      "Epoch 26/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4739 - binary_accuracy: 0.6884 - val_loss: 1.2964 - val_binary_accuracy: 0.5214\n",
      "Epoch 27/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4754 - binary_accuracy: 0.6875 - val_loss: 1.2106 - val_binary_accuracy: 0.5179\n",
      "Epoch 28/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4703 - binary_accuracy: 0.6884 - val_loss: 1.3495 - val_binary_accuracy: 0.5357\n",
      "Epoch 29/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.8047 - binary_accuracy: 0.5786 - val_loss: 0.7737 - val_binary_accuracy: 0.4857\n",
      "Epoch 30/45\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.6546 - binary_accuracy: 0.5518 - val_loss: 0.7045 - val_binary_accuracy: 0.4786\n",
      "Epoch 31/45\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.6235 - binary_accuracy: 0.5804 - val_loss: 0.7438 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5932 - binary_accuracy: 0.6143 - val_loss: 0.7426 - val_binary_accuracy: 0.5357\n",
      "Epoch 33/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5594 - binary_accuracy: 0.6339 - val_loss: 0.8403 - val_binary_accuracy: 0.4857\n",
      "Epoch 34/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5476 - binary_accuracy: 0.6366 - val_loss: 0.9848 - val_binary_accuracy: 0.4964\n",
      "Epoch 35/45\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5773 - binary_accuracy: 0.6214 - val_loss: 0.7722 - val_binary_accuracy: 0.5214\n",
      "Epoch 36/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5787 - binary_accuracy: 0.6223 - val_loss: 0.8560 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/45\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5626 - binary_accuracy: 0.6304 - val_loss: 0.9533 - val_binary_accuracy: 0.5179\n",
      "Epoch 38/45\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5609 - binary_accuracy: 0.6080 - val_loss: 0.9356 - val_binary_accuracy: 0.5036\n",
      "Epoch 39/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5608 - binary_accuracy: 0.5946 - val_loss: 0.9286 - val_binary_accuracy: 0.5143\n",
      "Epoch 40/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5536 - binary_accuracy: 0.6304 - val_loss: 0.9865 - val_binary_accuracy: 0.5071\n",
      "Epoch 41/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5722 - binary_accuracy: 0.6143 - val_loss: 1.1071 - val_binary_accuracy: 0.5107\n",
      "Epoch 42/45\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.5683 - binary_accuracy: 0.6170 - val_loss: 1.1759 - val_binary_accuracy: 0.5143\n",
      "Epoch 43/45\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5624 - binary_accuracy: 0.6179 - val_loss: 1.2380 - val_binary_accuracy: 0.5286\n",
      "Epoch 44/45\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5882 - binary_accuracy: 0.6196 - val_loss: 0.7647 - val_binary_accuracy: 0.5107\n",
      "Epoch 45/45\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5649 - binary_accuracy: 0.6295 - val_loss: 1.0360 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.6467 - binary_accuracy: 0.6143\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.9420 - binary_accuracy: 0.5533\n",
      "training start... epochs = 46\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/46\n",
      "112/112 [==============================] - 47s 318ms/step - loss: 0.6947 - binary_accuracy: 0.5375 - val_loss: 0.6906 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/46\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.6711 - binary_accuracy: 0.5759 - val_loss: 0.7060 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/46\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.6792 - binary_accuracy: 0.6411 - val_loss: 0.7099 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/46\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.5454 - binary_accuracy: 0.6482 - val_loss: 0.8181 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/46\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.5037 - binary_accuracy: 0.6607 - val_loss: 0.8520 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/46\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4948 - binary_accuracy: 0.6777 - val_loss: 0.8960 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/46\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4897 - binary_accuracy: 0.6768 - val_loss: 1.0677 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/46\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5221 - binary_accuracy: 0.6661 - val_loss: 0.8697 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/46\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.4881 - binary_accuracy: 0.6759 - val_loss: 1.1288 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/46\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4791 - binary_accuracy: 0.6857 - val_loss: 1.2423 - val_binary_accuracy: 0.5107\n",
      "Epoch 11/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4846 - binary_accuracy: 0.6804 - val_loss: 0.9426 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/46\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4822 - binary_accuracy: 0.6795 - val_loss: 0.9297 - val_binary_accuracy: 0.5107\n",
      "Epoch 13/46\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.4953 - binary_accuracy: 0.6768 - val_loss: 0.9997 - val_binary_accuracy: 0.5179\n",
      "Epoch 14/46\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4868 - binary_accuracy: 0.6786 - val_loss: 1.1097 - val_binary_accuracy: 0.5179\n",
      "Epoch 15/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4768 - binary_accuracy: 0.6821 - val_loss: 1.3169 - val_binary_accuracy: 0.5143\n",
      "Epoch 16/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4903 - binary_accuracy: 0.6714 - val_loss: 1.0930 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4875 - binary_accuracy: 0.6786 - val_loss: 1.0841 - val_binary_accuracy: 0.5107\n",
      "Epoch 18/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4774 - binary_accuracy: 0.6875 - val_loss: 1.2179 - val_binary_accuracy: 0.5214\n",
      "Epoch 19/46\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.7410 - binary_accuracy: 0.6723 - val_loss: 0.9606 - val_binary_accuracy: 0.5036\n",
      "Epoch 20/46\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4847 - binary_accuracy: 0.6786 - val_loss: 1.0932 - val_binary_accuracy: 0.5036\n",
      "Epoch 21/46\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4795 - binary_accuracy: 0.6786 - val_loss: 1.3109 - val_binary_accuracy: 0.4750\n",
      "Epoch 22/46\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.4812 - binary_accuracy: 0.6714 - val_loss: 1.1359 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4773 - binary_accuracy: 0.6848 - val_loss: 1.6491 - val_binary_accuracy: 0.4964\n",
      "Epoch 24/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4919 - binary_accuracy: 0.6777 - val_loss: 1.0282 - val_binary_accuracy: 0.5107\n",
      "Epoch 25/46\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4906 - binary_accuracy: 0.6750 - val_loss: 0.8696 - val_binary_accuracy: 0.4964\n",
      "Epoch 26/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4850 - binary_accuracy: 0.6795 - val_loss: 0.9954 - val_binary_accuracy: 0.5179\n",
      "Epoch 27/46\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4779 - binary_accuracy: 0.6830 - val_loss: 1.1282 - val_binary_accuracy: 0.5143\n",
      "Epoch 28/46\n",
      "112/112 [==============================] - 27s 240ms/step - loss: 0.4728 - binary_accuracy: 0.6866 - val_loss: 1.1156 - val_binary_accuracy: 0.5250\n",
      "Epoch 29/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4797 - binary_accuracy: 0.6839 - val_loss: 1.1855 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4748 - binary_accuracy: 0.6875 - val_loss: 1.2088 - val_binary_accuracy: 0.5250\n",
      "Epoch 31/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4737 - binary_accuracy: 0.6893 - val_loss: 1.3226 - val_binary_accuracy: 0.5143\n",
      "Epoch 32/46\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4724 - binary_accuracy: 0.6875 - val_loss: 0.8169 - val_binary_accuracy: 0.5321\n",
      "Epoch 33/46\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.5022 - binary_accuracy: 0.6786 - val_loss: 0.9239 - val_binary_accuracy: 0.5250\n",
      "Epoch 34/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4854 - binary_accuracy: 0.6768 - val_loss: 1.0427 - val_binary_accuracy: 0.5393\n",
      "Epoch 35/46\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4846 - binary_accuracy: 0.6777 - val_loss: 1.0690 - val_binary_accuracy: 0.5321\n",
      "Epoch 36/46\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4843 - binary_accuracy: 0.6848 - val_loss: 1.0878 - val_binary_accuracy: 0.5357\n",
      "Epoch 37/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4842 - binary_accuracy: 0.6616 - val_loss: 1.1535 - val_binary_accuracy: 0.5321\n",
      "Epoch 38/46\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4819 - binary_accuracy: 0.6795 - val_loss: 1.1406 - val_binary_accuracy: 0.5321\n",
      "Epoch 39/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4809 - binary_accuracy: 0.6795 - val_loss: 1.2065 - val_binary_accuracy: 0.5321\n",
      "Epoch 40/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4807 - binary_accuracy: 0.6795 - val_loss: 1.2545 - val_binary_accuracy: 0.5250\n",
      "Epoch 41/46\n",
      "112/112 [==============================] - 27s 243ms/step - loss: 0.4815 - binary_accuracy: 0.6786 - val_loss: 1.1675 - val_binary_accuracy: 0.5250\n",
      "Epoch 42/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4802 - binary_accuracy: 0.6741 - val_loss: 1.1635 - val_binary_accuracy: 0.5107\n",
      "Epoch 43/46\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4748 - binary_accuracy: 0.6857 - val_loss: 1.4284 - val_binary_accuracy: 0.5143\n",
      "Epoch 44/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.5182 - binary_accuracy: 0.6661 - val_loss: 0.9416 - val_binary_accuracy: 0.5071\n",
      "Epoch 45/46\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4879 - binary_accuracy: 0.6732 - val_loss: 1.0568 - val_binary_accuracy: 0.5071\n",
      "Epoch 46/46\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4833 - binary_accuracy: 0.6750 - val_loss: 1.1046 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6053 - binary_accuracy: 0.6443\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 0.9971 - binary_accuracy: 0.5617\n",
      "training start... epochs = 47\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_60 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_50 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 47s 316ms/step - loss: 0.6976 - binary_accuracy: 0.5170 - val_loss: 0.6906 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/47\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.6720 - binary_accuracy: 0.5723 - val_loss: 0.7175 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/47\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.6101 - binary_accuracy: 0.6348 - val_loss: 0.7657 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/47\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.5520 - binary_accuracy: 0.6696 - val_loss: 0.7555 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/47\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.5093 - binary_accuracy: 0.6679 - val_loss: 0.8126 - val_binary_accuracy: 0.5393\n",
      "Epoch 6/47\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.5186 - binary_accuracy: 0.6607 - val_loss: 0.9981 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/47\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5076 - binary_accuracy: 0.6598 - val_loss: 0.8697 - val_binary_accuracy: 0.5071\n",
      "Epoch 8/47\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4921 - binary_accuracy: 0.6696 - val_loss: 0.9739 - val_binary_accuracy: 0.5179\n",
      "Epoch 9/47\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4834 - binary_accuracy: 0.6777 - val_loss: 1.1629 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/47\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4829 - binary_accuracy: 0.6768 - val_loss: 1.2073 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/47\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4819 - binary_accuracy: 0.6750 - val_loss: 1.2263 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/47\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4800 - binary_accuracy: 0.6795 - val_loss: 1.1284 - val_binary_accuracy: 0.5071\n",
      "Epoch 13/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4767 - binary_accuracy: 0.6839 - val_loss: 1.2160 - val_binary_accuracy: 0.5107\n",
      "Epoch 14/47\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4871 - binary_accuracy: 0.6768 - val_loss: 1.1100 - val_binary_accuracy: 0.4964\n",
      "Epoch 15/47\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4779 - binary_accuracy: 0.6857 - val_loss: 1.0987 - val_binary_accuracy: 0.5179\n",
      "Epoch 16/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4859 - binary_accuracy: 0.6768 - val_loss: 1.1580 - val_binary_accuracy: 0.5179\n",
      "Epoch 17/47\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4817 - binary_accuracy: 0.6795 - val_loss: 1.1125 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/47\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4815 - binary_accuracy: 0.6786 - val_loss: 1.3500 - val_binary_accuracy: 0.5071\n",
      "Epoch 19/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4734 - binary_accuracy: 0.6759 - val_loss: 1.1904 - val_binary_accuracy: 0.5179\n",
      "Epoch 20/47\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4835 - binary_accuracy: 0.6786 - val_loss: 1.1546 - val_binary_accuracy: 0.5143\n",
      "Epoch 21/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4774 - binary_accuracy: 0.6848 - val_loss: 0.9696 - val_binary_accuracy: 0.5179\n",
      "Epoch 22/47\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4938 - binary_accuracy: 0.6741 - val_loss: 1.0772 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4872 - binary_accuracy: 0.6786 - val_loss: 1.2275 - val_binary_accuracy: 0.5286\n",
      "Epoch 24/47\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4858 - binary_accuracy: 0.6768 - val_loss: 1.2183 - val_binary_accuracy: 0.5071\n",
      "Epoch 25/47\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4795 - binary_accuracy: 0.6777 - val_loss: 1.3381 - val_binary_accuracy: 0.5071\n",
      "Epoch 26/47\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4765 - binary_accuracy: 0.6812 - val_loss: 1.5295 - val_binary_accuracy: 0.5179\n",
      "Epoch 27/47\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4815 - binary_accuracy: 0.6804 - val_loss: 1.5473 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/47\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4779 - binary_accuracy: 0.6795 - val_loss: 1.2343 - val_binary_accuracy: 0.5107\n",
      "Epoch 29/47\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4729 - binary_accuracy: 0.6857 - val_loss: 1.4675 - val_binary_accuracy: 0.5071\n",
      "Epoch 30/47\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.4727 - binary_accuracy: 0.6866 - val_loss: 1.5262 - val_binary_accuracy: 0.5036\n",
      "Epoch 31/47\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4905 - binary_accuracy: 0.6786 - val_loss: 1.2519 - val_binary_accuracy: 0.5179\n",
      "Epoch 32/47\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4735 - binary_accuracy: 0.6795 - val_loss: 1.5434 - val_binary_accuracy: 0.5036\n",
      "Epoch 33/47\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4887 - binary_accuracy: 0.6705 - val_loss: 1.0704 - val_binary_accuracy: 0.5321\n",
      "Epoch 34/47\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4913 - binary_accuracy: 0.6795 - val_loss: 1.4659 - val_binary_accuracy: 0.5036\n",
      "Epoch 35/47\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.5158 - binary_accuracy: 0.6705 - val_loss: 1.0483 - val_binary_accuracy: 0.5214\n",
      "Epoch 36/47\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4860 - binary_accuracy: 0.6768 - val_loss: 1.1321 - val_binary_accuracy: 0.5179\n",
      "Epoch 37/47\n",
      "112/112 [==============================] - 27s 245ms/step - loss: 0.4855 - binary_accuracy: 0.6768 - val_loss: 1.0842 - val_binary_accuracy: 0.5214\n",
      "Epoch 38/47\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4823 - binary_accuracy: 0.6777 - val_loss: 1.1294 - val_binary_accuracy: 0.5214\n",
      "Epoch 39/47\n",
      "112/112 [==============================] - 27s 241ms/step - loss: 0.4853 - binary_accuracy: 0.6875 - val_loss: 1.1403 - val_binary_accuracy: 0.5286\n",
      "Epoch 40/47\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4861 - binary_accuracy: 0.6759 - val_loss: 1.0287 - val_binary_accuracy: 0.5286\n",
      "Epoch 41/47\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4828 - binary_accuracy: 0.6768 - val_loss: 1.1253 - val_binary_accuracy: 0.5321\n",
      "Epoch 42/47\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4795 - binary_accuracy: 0.6786 - val_loss: 1.2467 - val_binary_accuracy: 0.5250\n",
      "Epoch 43/47\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4796 - binary_accuracy: 0.6741 - val_loss: 1.2725 - val_binary_accuracy: 0.5214\n",
      "Epoch 44/47\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4763 - binary_accuracy: 0.6821 - val_loss: 1.4409 - val_binary_accuracy: 0.5464\n",
      "Epoch 45/47\n",
      "112/112 [==============================] - 27s 246ms/step - loss: 0.5011 - binary_accuracy: 0.6696 - val_loss: 1.0031 - val_binary_accuracy: 0.5250\n",
      "Epoch 46/47\n",
      "112/112 [==============================] - 27s 244ms/step - loss: 0.4883 - binary_accuracy: 0.6438 - val_loss: 1.0801 - val_binary_accuracy: 0.5286\n",
      "Epoch 47/47\n",
      "112/112 [==============================] - 27s 242ms/step - loss: 0.4807 - binary_accuracy: 0.6830 - val_loss: 1.1658 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6160 - binary_accuracy: 0.6564\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 1.2901 - binary_accuracy: 0.5400\n",
      "training start... epochs = 48\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_61 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_120 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/48\n",
      "112/112 [==============================] - 47s 315ms/step - loss: 0.6922 - binary_accuracy: 0.5188 - val_loss: 0.6962 - val_binary_accuracy: 0.5286\n",
      "Epoch 2/48\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.7042 - binary_accuracy: 0.5705 - val_loss: 0.6898 - val_binary_accuracy: 0.5321\n",
      "Epoch 3/48\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.6317 - binary_accuracy: 0.6098 - val_loss: 0.7114 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/48\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.6185 - binary_accuracy: 0.6500 - val_loss: 0.7374 - val_binary_accuracy: 0.4786\n",
      "Epoch 5/48\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.5877 - binary_accuracy: 0.6500 - val_loss: 0.7379 - val_binary_accuracy: 0.4500\n",
      "Epoch 6/48\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.5312 - binary_accuracy: 0.6571 - val_loss: 0.7946 - val_binary_accuracy: 0.4929\n",
      "Epoch 7/48\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.5031 - binary_accuracy: 0.6687 - val_loss: 0.8505 - val_binary_accuracy: 0.5179\n",
      "Epoch 8/48\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4909 - binary_accuracy: 0.6714 - val_loss: 1.0432 - val_binary_accuracy: 0.5036\n",
      "Epoch 9/48\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.4866 - binary_accuracy: 0.6750 - val_loss: 1.0941 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4842 - binary_accuracy: 0.6768 - val_loss: 1.2192 - val_binary_accuracy: 0.5179\n",
      "Epoch 11/48\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4858 - binary_accuracy: 0.6777 - val_loss: 1.1218 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/48\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4893 - binary_accuracy: 0.6768 - val_loss: 0.9614 - val_binary_accuracy: 0.5036\n",
      "Epoch 13/48\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.4842 - binary_accuracy: 0.6812 - val_loss: 1.0604 - val_binary_accuracy: 0.4964\n",
      "Epoch 14/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4832 - binary_accuracy: 0.6750 - val_loss: 1.0601 - val_binary_accuracy: 0.4786\n",
      "Epoch 15/48\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4792 - binary_accuracy: 0.6804 - val_loss: 1.1831 - val_binary_accuracy: 0.4929\n",
      "Epoch 16/48\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4845 - binary_accuracy: 0.6759 - val_loss: 1.0271 - val_binary_accuracy: 0.5036\n",
      "Epoch 17/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4827 - binary_accuracy: 0.6786 - val_loss: 1.2373 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/48\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4781 - binary_accuracy: 0.6839 - val_loss: 1.4792 - val_binary_accuracy: 0.4821\n",
      "Epoch 19/48\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4847 - binary_accuracy: 0.6786 - val_loss: 1.0700 - val_binary_accuracy: 0.5036\n",
      "Epoch 20/48\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4806 - binary_accuracy: 0.6777 - val_loss: 1.2251 - val_binary_accuracy: 0.5071\n",
      "Epoch 21/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4777 - binary_accuracy: 0.6857 - val_loss: 1.3558 - val_binary_accuracy: 0.4893\n",
      "Epoch 22/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4764 - binary_accuracy: 0.6857 - val_loss: 1.1194 - val_binary_accuracy: 0.4929\n",
      "Epoch 23/48\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4820 - binary_accuracy: 0.6920 - val_loss: 1.1829 - val_binary_accuracy: 0.4893\n",
      "Epoch 24/48\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5129 - binary_accuracy: 0.6670 - val_loss: 1.1623 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/48\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4833 - binary_accuracy: 0.6768 - val_loss: 1.0010 - val_binary_accuracy: 0.5071\n",
      "Epoch 26/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4784 - binary_accuracy: 0.6857 - val_loss: 1.0087 - val_binary_accuracy: 0.5036\n",
      "Epoch 27/48\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4863 - binary_accuracy: 0.6830 - val_loss: 1.0544 - val_binary_accuracy: 0.4964\n",
      "Epoch 28/48\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4835 - binary_accuracy: 0.6777 - val_loss: 1.1885 - val_binary_accuracy: 0.4929\n",
      "Epoch 29/48\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4838 - binary_accuracy: 0.6714 - val_loss: 1.2005 - val_binary_accuracy: 0.5036\n",
      "Epoch 30/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4773 - binary_accuracy: 0.6777 - val_loss: 1.4425 - val_binary_accuracy: 0.5036\n",
      "Epoch 31/48\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4782 - binary_accuracy: 0.6821 - val_loss: 1.1663 - val_binary_accuracy: 0.4964\n",
      "Epoch 32/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4764 - binary_accuracy: 0.6866 - val_loss: 1.5783 - val_binary_accuracy: 0.4929\n",
      "Epoch 33/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4868 - binary_accuracy: 0.6821 - val_loss: 1.2239 - val_binary_accuracy: 0.5071\n",
      "Epoch 34/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4729 - binary_accuracy: 0.6875 - val_loss: 1.3632 - val_binary_accuracy: 0.5250\n",
      "Epoch 35/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4948 - binary_accuracy: 0.6750 - val_loss: 1.0468 - val_binary_accuracy: 0.5036\n",
      "Epoch 36/48\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4864 - binary_accuracy: 0.6786 - val_loss: 1.0550 - val_binary_accuracy: 0.5036\n",
      "Epoch 37/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4854 - binary_accuracy: 0.6750 - val_loss: 1.1311 - val_binary_accuracy: 0.4857\n",
      "Epoch 38/48\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4800 - binary_accuracy: 0.6839 - val_loss: 1.2811 - val_binary_accuracy: 0.4964\n",
      "Epoch 39/48\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4904 - binary_accuracy: 0.6687 - val_loss: 0.9771 - val_binary_accuracy: 0.5071\n",
      "Epoch 40/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4826 - binary_accuracy: 0.6812 - val_loss: 1.0842 - val_binary_accuracy: 0.4821\n",
      "Epoch 41/48\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4736 - binary_accuracy: 0.6875 - val_loss: 1.2028 - val_binary_accuracy: 0.4821\n",
      "Epoch 42/48\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4709 - binary_accuracy: 0.6857 - val_loss: 1.1964 - val_binary_accuracy: 0.4786\n",
      "Epoch 43/48\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4724 - binary_accuracy: 0.6777 - val_loss: 1.1971 - val_binary_accuracy: 0.5071\n",
      "Epoch 44/48\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4712 - binary_accuracy: 0.6911 - val_loss: 1.3542 - val_binary_accuracy: 0.4786\n",
      "Epoch 45/48\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4731 - binary_accuracy: 0.6866 - val_loss: 1.4356 - val_binary_accuracy: 0.4786\n",
      "Epoch 46/48\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4807 - binary_accuracy: 0.6759 - val_loss: 1.1502 - val_binary_accuracy: 0.5036\n",
      "Epoch 47/48\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4769 - binary_accuracy: 0.6848 - val_loss: 1.3227 - val_binary_accuracy: 0.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/48\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4747 - binary_accuracy: 0.6857 - val_loss: 1.2033 - val_binary_accuracy: 0.4964\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.6231 - binary_accuracy: 0.6471\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1173 - binary_accuracy: 0.5583\n",
      "training start... epochs = 49\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_62 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_128 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/49\n",
      "112/112 [==============================] - 48s 323ms/step - loss: 0.6909 - binary_accuracy: 0.5339 - val_loss: 0.6954 - val_binary_accuracy: 0.5214\n",
      "Epoch 2/49\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.6703 - binary_accuracy: 0.5830 - val_loss: 0.7010 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/49\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.6406 - binary_accuracy: 0.6187 - val_loss: 0.7057 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/49\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.5792 - binary_accuracy: 0.6536 - val_loss: 0.7350 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/49\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.5229 - binary_accuracy: 0.6741 - val_loss: 0.8580 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/49\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.5119 - binary_accuracy: 0.6670 - val_loss: 0.8524 - val_binary_accuracy: 0.5321\n",
      "Epoch 7/49\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4925 - binary_accuracy: 0.6732 - val_loss: 1.0198 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4854 - binary_accuracy: 0.6768 - val_loss: 1.0421 - val_binary_accuracy: 0.5143\n",
      "Epoch 9/49\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4849 - binary_accuracy: 0.6741 - val_loss: 1.1473 - val_binary_accuracy: 0.5179\n",
      "Epoch 10/49\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.5099 - binary_accuracy: 0.6589 - val_loss: 0.9798 - val_binary_accuracy: 0.5107\n",
      "Epoch 11/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4863 - binary_accuracy: 0.6786 - val_loss: 1.0459 - val_binary_accuracy: 0.5036\n",
      "Epoch 12/49\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4860 - binary_accuracy: 0.6804 - val_loss: 1.0276 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4846 - binary_accuracy: 0.6777 - val_loss: 1.1813 - val_binary_accuracy: 0.5107\n",
      "Epoch 14/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4823 - binary_accuracy: 0.6777 - val_loss: 1.1591 - val_binary_accuracy: 0.5143\n",
      "Epoch 15/49\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.4889 - binary_accuracy: 0.6759 - val_loss: 1.2293 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/49\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4819 - binary_accuracy: 0.6777 - val_loss: 1.2715 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/49\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5015 - binary_accuracy: 0.6821 - val_loss: 0.8816 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/49\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4889 - binary_accuracy: 0.6750 - val_loss: 1.1379 - val_binary_accuracy: 0.5143\n",
      "Epoch 19/49\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4904 - binary_accuracy: 0.6804 - val_loss: 1.0336 - val_binary_accuracy: 0.5107\n",
      "Epoch 20/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4838 - binary_accuracy: 0.6777 - val_loss: 1.2239 - val_binary_accuracy: 0.5107\n",
      "Epoch 21/49\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4830 - binary_accuracy: 0.6795 - val_loss: 1.2210 - val_binary_accuracy: 0.5143\n",
      "Epoch 22/49\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4815 - binary_accuracy: 0.6804 - val_loss: 1.4571 - val_binary_accuracy: 0.5143\n",
      "Epoch 23/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.6408 - binary_accuracy: 0.6625 - val_loss: 0.9231 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/49\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.4871 - binary_accuracy: 0.6714 - val_loss: 1.1045 - val_binary_accuracy: 0.5143\n",
      "Epoch 25/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4865 - binary_accuracy: 0.6830 - val_loss: 0.9213 - val_binary_accuracy: 0.5286\n",
      "Epoch 26/49\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.7375 - binary_accuracy: 0.5330 - val_loss: 0.6941 - val_binary_accuracy: 0.4893\n",
      "Epoch 27/49\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.6933 - binary_accuracy: 0.5027 - val_loss: 0.6928 - val_binary_accuracy: 0.5036\n",
      "Epoch 28/49\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.6905 - binary_accuracy: 0.5295 - val_loss: 0.6961 - val_binary_accuracy: 0.4929\n",
      "Epoch 29/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.6898 - binary_accuracy: 0.5232 - val_loss: 0.6889 - val_binary_accuracy: 0.5500\n",
      "Epoch 30/49\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.6780 - binary_accuracy: 0.5830 - val_loss: 0.6933 - val_binary_accuracy: 0.5107\n",
      "Epoch 31/49\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.6519 - binary_accuracy: 0.6054 - val_loss: 0.6918 - val_binary_accuracy: 0.5179\n",
      "Epoch 32/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.6269 - binary_accuracy: 0.6196 - val_loss: 0.7054 - val_binary_accuracy: 0.5179\n",
      "Epoch 33/49\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5967 - binary_accuracy: 0.6223 - val_loss: 0.7351 - val_binary_accuracy: 0.5214\n",
      "Epoch 34/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5717 - binary_accuracy: 0.6429 - val_loss: 0.7462 - val_binary_accuracy: 0.5357\n",
      "Epoch 35/49\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.5530 - binary_accuracy: 0.6643 - val_loss: 0.7134 - val_binary_accuracy: 0.5429\n",
      "Epoch 36/49\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.5522 - binary_accuracy: 0.6562 - val_loss: 0.8831 - val_binary_accuracy: 0.5036\n",
      "Epoch 37/49\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5308 - binary_accuracy: 0.6607 - val_loss: 0.8101 - val_binary_accuracy: 0.5464\n",
      "Epoch 38/49\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5274 - binary_accuracy: 0.6625 - val_loss: 0.8620 - val_binary_accuracy: 0.5286\n",
      "Epoch 39/49\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5938 - binary_accuracy: 0.6259 - val_loss: 0.7846 - val_binary_accuracy: 0.5214\n",
      "Epoch 40/49\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5555 - binary_accuracy: 0.6571 - val_loss: 0.8125 - val_binary_accuracy: 0.5214\n",
      "Epoch 41/49\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.5413 - binary_accuracy: 0.6607 - val_loss: 0.9362 - val_binary_accuracy: 0.5107\n",
      "Epoch 42/49\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5106 - binary_accuracy: 0.6589 - val_loss: 0.8915 - val_binary_accuracy: 0.5250\n",
      "Epoch 43/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4877 - binary_accuracy: 0.6768 - val_loss: 0.9764 - val_binary_accuracy: 0.5179\n",
      "Epoch 44/49\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4888 - binary_accuracy: 0.6589 - val_loss: 0.9472 - val_binary_accuracy: 0.5143\n",
      "Epoch 45/49\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4831 - binary_accuracy: 0.6652 - val_loss: 1.1325 - val_binary_accuracy: 0.5214\n",
      "Epoch 46/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4827 - binary_accuracy: 0.6661 - val_loss: 1.0680 - val_binary_accuracy: 0.5321\n",
      "Epoch 47/49\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4995 - binary_accuracy: 0.6616 - val_loss: 0.8299 - val_binary_accuracy: 0.5179\n",
      "Epoch 48/49\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4897 - binary_accuracy: 0.6625 - val_loss: 1.0291 - val_binary_accuracy: 0.5286\n",
      "Epoch 49/49\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.4815 - binary_accuracy: 0.6723 - val_loss: 1.0412 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.5955 - binary_accuracy: 0.6464\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.0314 - binary_accuracy: 0.5650\n",
      "training start... epochs = 50\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_63 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 256)               295936    \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 521,985\n",
      "Trainable params: 521,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 48s 317ms/step - loss: 0.6949 - binary_accuracy: 0.5214 - val_loss: 0.6941 - val_binary_accuracy: 0.4857\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.6739 - binary_accuracy: 0.5804 - val_loss: 0.6975 - val_binary_accuracy: 0.5071\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.6630 - binary_accuracy: 0.6295 - val_loss: 0.7156 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.5717 - binary_accuracy: 0.6509 - val_loss: 0.8257 - val_binary_accuracy: 0.5214\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.5267 - binary_accuracy: 0.6670 - val_loss: 0.7933 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4952 - binary_accuracy: 0.6687 - val_loss: 0.8647 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4906 - binary_accuracy: 0.6759 - val_loss: 0.9930 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.4846 - binary_accuracy: 0.6786 - val_loss: 1.0144 - val_binary_accuracy: 0.4929\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4980 - binary_accuracy: 0.6705 - val_loss: 0.9304 - val_binary_accuracy: 0.5071\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4828 - binary_accuracy: 0.6830 - val_loss: 1.0620 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4949 - binary_accuracy: 0.6768 - val_loss: 0.9602 - val_binary_accuracy: 0.5143\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4863 - binary_accuracy: 0.6804 - val_loss: 1.0761 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4879 - binary_accuracy: 0.6759 - val_loss: 1.0179 - val_binary_accuracy: 0.5107\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4835 - binary_accuracy: 0.6777 - val_loss: 1.0964 - val_binary_accuracy: 0.5107\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4835 - binary_accuracy: 0.6821 - val_loss: 1.0039 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4794 - binary_accuracy: 0.6786 - val_loss: 1.0184 - val_binary_accuracy: 0.5107\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.4825 - binary_accuracy: 0.6696 - val_loss: 1.0685 - val_binary_accuracy: 0.5036\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4820 - binary_accuracy: 0.6777 - val_loss: 1.3238 - val_binary_accuracy: 0.5143\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4944 - binary_accuracy: 0.6804 - val_loss: 1.1082 - val_binary_accuracy: 0.5393\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4850 - binary_accuracy: 0.6732 - val_loss: 0.9641 - val_binary_accuracy: 0.5071\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4814 - binary_accuracy: 0.6723 - val_loss: 1.1917 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.8992 - binary_accuracy: 0.5893 - val_loss: 0.6907 - val_binary_accuracy: 0.5143\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.6659 - binary_accuracy: 0.5705 - val_loss: 0.7227 - val_binary_accuracy: 0.5107\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.6357 - binary_accuracy: 0.6062 - val_loss: 0.6936 - val_binary_accuracy: 0.5214\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5904 - binary_accuracy: 0.6250 - val_loss: 0.7606 - val_binary_accuracy: 0.5107\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.5380 - binary_accuracy: 0.6438 - val_loss: 0.8245 - val_binary_accuracy: 0.5143\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5003 - binary_accuracy: 0.6696 - val_loss: 1.0563 - val_binary_accuracy: 0.5143\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4963 - binary_accuracy: 0.6670 - val_loss: 1.2417 - val_binary_accuracy: 0.4893\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.5016 - binary_accuracy: 0.6571 - val_loss: 0.8707 - val_binary_accuracy: 0.5179\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4908 - binary_accuracy: 0.6759 - val_loss: 0.9973 - val_binary_accuracy: 0.5071\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4816 - binary_accuracy: 0.6786 - val_loss: 1.2056 - val_binary_accuracy: 0.4964\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4913 - binary_accuracy: 0.6714 - val_loss: 0.9604 - val_binary_accuracy: 0.5321\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4976 - binary_accuracy: 0.6652 - val_loss: 0.8267 - val_binary_accuracy: 0.5071\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5132 - binary_accuracy: 0.6750 - val_loss: 1.0925 - val_binary_accuracy: 0.5071\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4760 - binary_accuracy: 0.6786 - val_loss: 1.2358 - val_binary_accuracy: 0.4929\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4745 - binary_accuracy: 0.6714 - val_loss: 1.1630 - val_binary_accuracy: 0.5071\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4783 - binary_accuracy: 0.6777 - val_loss: 1.2160 - val_binary_accuracy: 0.5071\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4723 - binary_accuracy: 0.6804 - val_loss: 1.1169 - val_binary_accuracy: 0.5179\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4714 - binary_accuracy: 0.6857 - val_loss: 1.2143 - val_binary_accuracy: 0.4893\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4756 - binary_accuracy: 0.6875 - val_loss: 1.4698 - val_binary_accuracy: 0.4964\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4726 - binary_accuracy: 0.6875 - val_loss: 1.1044 - val_binary_accuracy: 0.5036\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4857 - binary_accuracy: 0.6848 - val_loss: 1.1979 - val_binary_accuracy: 0.5107\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4675 - binary_accuracy: 0.6946 - val_loss: 1.2871 - val_binary_accuracy: 0.5143\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.5289 - binary_accuracy: 0.6625 - val_loss: 1.2784 - val_binary_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4807 - binary_accuracy: 0.6696 - val_loss: 1.4881 - val_binary_accuracy: 0.5143\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4739 - binary_accuracy: 0.6938 - val_loss: 0.8370 - val_binary_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.4780 - binary_accuracy: 0.6812 - val_loss: 1.3004 - val_binary_accuracy: 0.5143\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4674 - binary_accuracy: 0.6839 - val_loss: 1.5647 - val_binary_accuracy: 0.4821\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4733 - binary_accuracy: 0.6821 - val_loss: 1.3138 - val_binary_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4679 - binary_accuracy: 0.6857 - val_loss: 1.5327 - val_binary_accuracy: 0.5000\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6795 - binary_accuracy: 0.6514\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.3780 - binary_accuracy: 0.5600\n"
     ]
    }
   ],
   "source": [
    "print(\"-- 70% L --\")\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for epoch in range(10, 51):\n",
    "    res_lstm_70 = fit_train_lstm(train_padded_70, train_y, test_padded_70, test_y, L_70, epoch)\n",
    "    train_acc.append(res_lstm_70[0])\n",
    "    test_acc.append(res_lstm_70[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75b0f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LSTM report --\n",
      "epoch = 10 train accuracy = 0.6449999809265137 test accuracy = 0.5250000357627869\n",
      "epoch = 11 train accuracy = 0.6399999856948853 test accuracy = 0.5483333468437195\n",
      "epoch = 12 train accuracy = 0.6407142877578735 test accuracy = 0.5516666769981384\n",
      "epoch = 13 train accuracy = 0.647857129573822 test accuracy = 0.5133333206176758\n",
      "epoch = 14 train accuracy = 0.5999999642372131 test accuracy = 0.5233333706855774\n",
      "epoch = 15 train accuracy = 0.5 test accuracy = 0.5\n",
      "epoch = 16 train accuracy = 0.5 test accuracy = 0.5\n",
      "epoch = 17 train accuracy = 0.6435714364051819 test accuracy = 0.5400000214576721\n",
      "epoch = 18 train accuracy = 0.6528571248054504 test accuracy = 0.5600000023841858\n",
      "epoch = 19 train accuracy = 0.6442856788635254 test accuracy = 0.5400000214576721\n",
      "epoch = 20 train accuracy = 0.633571445941925 test accuracy = 0.5483333468437195\n",
      "epoch = 21 train accuracy = 0.6442856788635254 test accuracy = 0.5483333468437195\n",
      "epoch = 22 train accuracy = 0.6571428775787354 test accuracy = 0.5583333373069763\n",
      "epoch = 23 train accuracy = 0.6485714316368103 test accuracy = 0.5250000357627869\n",
      "epoch = 24 train accuracy = 0.6528571248054504 test accuracy = 0.5633333325386047\n",
      "epoch = 25 train accuracy = 0.6492857336997986 test accuracy = 0.5333333611488342\n",
      "epoch = 26 train accuracy = 0.6435714364051819 test accuracy = 0.5483333468437195\n",
      "epoch = 27 train accuracy = 0.6064285635948181 test accuracy = 0.5200000405311584\n",
      "epoch = 28 train accuracy = 0.645714282989502 test accuracy = 0.550000011920929\n",
      "epoch = 29 train accuracy = 0.5264285802841187 test accuracy = 0.5016666650772095\n",
      "epoch = 30 train accuracy = 0.6485714316368103 test accuracy = 0.5516666769981384\n",
      "epoch = 31 train accuracy = 0.6521428227424622 test accuracy = 0.5433333516120911\n",
      "epoch = 32 train accuracy = 0.5 test accuracy = 0.5\n",
      "epoch = 33 train accuracy = 0.6442856788635254 test accuracy = 0.5283333659172058\n",
      "epoch = 34 train accuracy = 0.6514285802841187 test accuracy = 0.5649999976158142\n",
      "epoch = 35 train accuracy = 0.5 test accuracy = 0.5\n",
      "epoch = 36 train accuracy = 0.6471428275108337 test accuracy = 0.5266667008399963\n",
      "epoch = 37 train accuracy = 0.6421428322792053 test accuracy = 0.550000011920929\n",
      "epoch = 38 train accuracy = 0.5928571224212646 test accuracy = 0.518333375453949\n",
      "epoch = 39 train accuracy = 0.6464285850524902 test accuracy = 0.5366666913032532\n",
      "epoch = 40 train accuracy = 0.6492857336997986 test accuracy = 0.550000011920929\n",
      "epoch = 41 train accuracy = 0.6471428275108337 test accuracy = 0.5350000262260437\n",
      "epoch = 42 train accuracy = 0.6442856788635254 test accuracy = 0.5450000166893005\n",
      "epoch = 43 train accuracy = 0.6442856788635254 test accuracy = 0.5683333277702332\n",
      "epoch = 44 train accuracy = 0.6578571200370789 test accuracy = 0.5816667079925537\n",
      "epoch = 45 train accuracy = 0.6142857074737549 test accuracy = 0.5533333420753479\n",
      "epoch = 46 train accuracy = 0.6442856788635254 test accuracy = 0.5616666674613953\n",
      "epoch = 47 train accuracy = 0.6564285755157471 test accuracy = 0.5400000214576721\n",
      "epoch = 48 train accuracy = 0.6471428275108337 test accuracy = 0.5583333373069763\n",
      "epoch = 49 train accuracy = 0.6464285850524902 test accuracy = 0.5649999976158142\n",
      "epoch = 50 train accuracy = 0.6514285802841187 test accuracy = 0.5600000023841858\n"
     ]
    }
   ],
   "source": [
    "print(\"-- LSTM report --\")\n",
    "for i in range(41):\n",
    "    print(\"epoch =\", i+10, \"train accuracy =\", train_acc[i], \"test accuracy =\", test_acc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a7dcc",
   "metadata": {},
   "source": [
    "-- try 2: LSTM layer units set to 32 --\n",
    "- slightly better but still not satisfying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a603d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start... epochs = 10\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_64 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_54 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "112/112 [==============================] - 47s 311ms/step - loss: 0.6920 - binary_accuracy: 0.5348 - val_loss: 0.6903 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.6672 - binary_accuracy: 0.5705 - val_loss: 0.6995 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 29s 255ms/step - loss: 0.6126 - binary_accuracy: 0.6500 - val_loss: 0.6993 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.5663 - binary_accuracy: 0.6679 - val_loss: 0.8268 - val_binary_accuracy: 0.5214\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.5302 - binary_accuracy: 0.6750 - val_loss: 0.7864 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4852 - binary_accuracy: 0.6696 - val_loss: 0.8892 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.4777 - binary_accuracy: 0.6839 - val_loss: 1.0118 - val_binary_accuracy: 0.5571\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4711 - binary_accuracy: 0.6893 - val_loss: 1.0078 - val_binary_accuracy: 0.4964\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4831 - binary_accuracy: 0.6795 - val_loss: 0.9846 - val_binary_accuracy: 0.5143\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4745 - binary_accuracy: 0.6884 - val_loss: 1.1574 - val_binary_accuracy: 0.5321\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.6156 - binary_accuracy: 0.6529\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 1.0826 - binary_accuracy: 0.5500\n",
      "training start... epochs = 11\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_65 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/11\n",
      "112/112 [==============================] - 46s 309ms/step - loss: 0.6916 - binary_accuracy: 0.5455 - val_loss: 0.6899 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/11\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.6650 - binary_accuracy: 0.5804 - val_loss: 0.6953 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/11\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.5893 - binary_accuracy: 0.6554 - val_loss: 0.7635 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/11\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5538 - binary_accuracy: 0.6759 - val_loss: 0.7153 - val_binary_accuracy: 0.5464\n",
      "Epoch 5/11\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.5071 - binary_accuracy: 0.6545 - val_loss: 0.8596 - val_binary_accuracy: 0.5536\n",
      "Epoch 6/11\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4769 - binary_accuracy: 0.6839 - val_loss: 0.9096 - val_binary_accuracy: 0.5429\n",
      "Epoch 7/11\n",
      "112/112 [==============================] - 28s 250ms/step - loss: 0.5303 - binary_accuracy: 0.6804 - val_loss: 0.8320 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/11\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4793 - binary_accuracy: 0.6893 - val_loss: 1.3397 - val_binary_accuracy: 0.5571\n",
      "Epoch 9/11\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4860 - binary_accuracy: 0.6839 - val_loss: 1.0625 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/11\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4714 - binary_accuracy: 0.6893 - val_loss: 1.0444 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/11\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4721 - binary_accuracy: 0.6866 - val_loss: 1.4285 - val_binary_accuracy: 0.5214\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.6715 - binary_accuracy: 0.6521\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 1.2850 - binary_accuracy: 0.5633\n",
      "training start... epochs = 12\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_66 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_56 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "112/112 [==============================] - 47s 315ms/step - loss: 0.6919 - binary_accuracy: 0.5295 - val_loss: 0.6903 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/12\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.6715 - binary_accuracy: 0.5813 - val_loss: 0.7101 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/12\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.6003 - binary_accuracy: 0.6438 - val_loss: 0.7037 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/12\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.5404 - binary_accuracy: 0.6786 - val_loss: 0.8384 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/12\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.5152 - binary_accuracy: 0.6723 - val_loss: 0.8482 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/12\n",
      "112/112 [==============================] - 28s 251ms/step - loss: 0.4834 - binary_accuracy: 0.6821 - val_loss: 0.7885 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/12\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4825 - binary_accuracy: 0.6759 - val_loss: 1.0175 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/12\n",
      "112/112 [==============================] - 28s 252ms/step - loss: 0.4788 - binary_accuracy: 0.6705 - val_loss: 0.9277 - val_binary_accuracy: 0.5286\n",
      "Epoch 9/12\n",
      "112/112 [==============================] - 28s 248ms/step - loss: 0.4764 - binary_accuracy: 0.6795 - val_loss: 0.9840 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/12\n",
      "112/112 [==============================] - 28s 249ms/step - loss: 0.4672 - binary_accuracy: 0.6830 - val_loss: 1.1729 - val_binary_accuracy: 0.5536\n",
      "Epoch 11/12\n",
      "112/112 [==============================] - 28s 247ms/step - loss: 0.4769 - binary_accuracy: 0.6964 - val_loss: 0.9474 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/12\n",
      "112/112 [==============================] - 28s 246ms/step - loss: 0.4868 - binary_accuracy: 0.6750 - val_loss: 0.8696 - val_binary_accuracy: 0.5321\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5572 - binary_accuracy: 0.6514\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 0.8645 - binary_accuracy: 0.5517\n",
      "training start... epochs = 13\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_67 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_57 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/13\n",
      "112/112 [==============================] - 45s 306ms/step - loss: 0.6917 - binary_accuracy: 0.5312 - val_loss: 0.6905 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/13\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.6743 - binary_accuracy: 0.5893 - val_loss: 0.6982 - val_binary_accuracy: 0.5393\n",
      "Epoch 3/13\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.6103 - binary_accuracy: 0.6482 - val_loss: 0.6902 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/13\n",
      "112/112 [==============================] - 29s 257ms/step - loss: 0.5629 - binary_accuracy: 0.6723 - val_loss: 0.8095 - val_binary_accuracy: 0.5464\n",
      "Epoch 5/13\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.5172 - binary_accuracy: 0.6902 - val_loss: 0.7564 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/13\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.4926 - binary_accuracy: 0.6830 - val_loss: 0.9089 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/13\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4817 - binary_accuracy: 0.6812 - val_loss: 1.0302 - val_binary_accuracy: 0.5464\n",
      "Epoch 8/13\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4819 - binary_accuracy: 0.6893 - val_loss: 0.8263 - val_binary_accuracy: 0.5214\n",
      "Epoch 9/13\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4938 - binary_accuracy: 0.6670 - val_loss: 0.9740 - val_binary_accuracy: 0.5143\n",
      "Epoch 10/13\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4802 - binary_accuracy: 0.6795 - val_loss: 1.0677 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/13\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4777 - binary_accuracy: 0.6705 - val_loss: 1.0615 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/13\n",
      "112/112 [==============================] - 29s 256ms/step - loss: 0.4786 - binary_accuracy: 0.6893 - val_loss: 1.1583 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/13\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4771 - binary_accuracy: 0.6857 - val_loss: 1.2534 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6278 - binary_accuracy: 0.6579\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.0652 - binary_accuracy: 0.5833\n",
      "training start... epochs = 14\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_68 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_58 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/14\n",
      "112/112 [==============================] - 48s 322ms/step - loss: 0.6924 - binary_accuracy: 0.5339 - val_loss: 0.6896 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/14\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.6832 - binary_accuracy: 0.5652 - val_loss: 0.6897 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/14\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.6075 - binary_accuracy: 0.6402 - val_loss: 0.7506 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/14\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.5526 - binary_accuracy: 0.6696 - val_loss: 0.9406 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/14\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4986 - binary_accuracy: 0.6643 - val_loss: 0.9576 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/14\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4922 - binary_accuracy: 0.6536 - val_loss: 1.0121 - val_binary_accuracy: 0.5429\n",
      "Epoch 7/14\n",
      "112/112 [==============================] - 28s 255ms/step - loss: 0.4874 - binary_accuracy: 0.6679 - val_loss: 1.0597 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/14\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.4742 - binary_accuracy: 0.6893 - val_loss: 1.3946 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/14\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4800 - binary_accuracy: 0.6804 - val_loss: 1.0572 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/14\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4694 - binary_accuracy: 0.6768 - val_loss: 1.2180 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/14\n",
      "112/112 [==============================] - 28s 253ms/step - loss: 0.4640 - binary_accuracy: 0.6866 - val_loss: 1.1939 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/14\n",
      "112/112 [==============================] - 28s 254ms/step - loss: 0.4635 - binary_accuracy: 0.6839 - val_loss: 1.3080 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 29s 262ms/step - loss: 0.4845 - binary_accuracy: 0.6777 - val_loss: 0.9331 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/14\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.4723 - binary_accuracy: 0.6545 - val_loss: 1.1193 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5977 - binary_accuracy: 0.6543\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.1367 - binary_accuracy: 0.5550\n",
      "training start... epochs = 15\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_69 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_59 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "112/112 [==============================] - 49s 328ms/step - loss: 0.6927 - binary_accuracy: 0.5134 - val_loss: 0.6895 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/15\n",
      "112/112 [==============================] - 31s 272ms/step - loss: 0.6729 - binary_accuracy: 0.5786 - val_loss: 0.6910 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/15\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.5905 - binary_accuracy: 0.6616 - val_loss: 0.7579 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/15\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.5482 - binary_accuracy: 0.6750 - val_loss: 0.9271 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/15\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.5161 - binary_accuracy: 0.6598 - val_loss: 0.8849 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/15\n",
      "112/112 [==============================] - 30s 266ms/step - loss: 0.4778 - binary_accuracy: 0.6821 - val_loss: 1.0790 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/15\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.4672 - binary_accuracy: 0.6821 - val_loss: 1.2290 - val_binary_accuracy: 0.5250\n",
      "Epoch 8/15\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4650 - binary_accuracy: 0.6821 - val_loss: 1.3096 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/15\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4747 - binary_accuracy: 0.6884 - val_loss: 1.0796 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/15\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4710 - binary_accuracy: 0.6670 - val_loss: 1.2378 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/15\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4666 - binary_accuracy: 0.6750 - val_loss: 1.1593 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/15\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4675 - binary_accuracy: 0.6795 - val_loss: 1.3671 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/15\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4653 - binary_accuracy: 0.6812 - val_loss: 1.2037 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/15\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4728 - binary_accuracy: 0.6750 - val_loss: 1.3633 - val_binary_accuracy: 0.5500\n",
      "Epoch 15/15\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4650 - binary_accuracy: 0.6812 - val_loss: 1.4778 - val_binary_accuracy: 0.5286\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6668 - binary_accuracy: 0.6507\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.4304 - binary_accuracy: 0.5567\n",
      "training start... epochs = 16\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_70 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_60 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "112/112 [==============================] - 50s 333ms/step - loss: 0.6916 - binary_accuracy: 0.5125 - val_loss: 0.6900 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/16\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.6590 - binary_accuracy: 0.5848 - val_loss: 0.6854 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/16\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.5960 - binary_accuracy: 0.6446 - val_loss: 0.8014 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/16\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.5633 - binary_accuracy: 0.6795 - val_loss: 0.8301 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/16\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.5086 - binary_accuracy: 0.6839 - val_loss: 0.9187 - val_binary_accuracy: 0.5464\n",
      "Epoch 6/16\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.4788 - binary_accuracy: 0.6857 - val_loss: 1.1921 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/16\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4750 - binary_accuracy: 0.6848 - val_loss: 1.8529 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/16\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4797 - binary_accuracy: 0.6795 - val_loss: 0.9485 - val_binary_accuracy: 0.5464\n",
      "Epoch 9/16\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4886 - binary_accuracy: 0.6911 - val_loss: 0.7424 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/16\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.5100 - binary_accuracy: 0.6661 - val_loss: 0.8339 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/16\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4870 - binary_accuracy: 0.6589 - val_loss: 0.9419 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/16\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4823 - binary_accuracy: 0.6696 - val_loss: 0.9867 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/16\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4805 - binary_accuracy: 0.6795 - val_loss: 1.0557 - val_binary_accuracy: 0.5321\n",
      "Epoch 14/16\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4805 - binary_accuracy: 0.6786 - val_loss: 1.0763 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/16\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4767 - binary_accuracy: 0.6741 - val_loss: 1.1032 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/16\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4771 - binary_accuracy: 0.6804 - val_loss: 1.0495 - val_binary_accuracy: 0.5571\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.5883 - binary_accuracy: 0.6564\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.0973 - binary_accuracy: 0.5533\n",
      "training start... epochs = 17\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_71 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/17\n",
      "112/112 [==============================] - 49s 329ms/step - loss: 0.6911 - binary_accuracy: 0.5357 - val_loss: 0.6900 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/17\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.6683 - binary_accuracy: 0.5705 - val_loss: 0.6851 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/17\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.5948 - binary_accuracy: 0.6545 - val_loss: 0.7487 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/17\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.6213 - binary_accuracy: 0.6500 - val_loss: 0.7421 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/17\n",
      "112/112 [==============================] - 30s 267ms/step - loss: 0.5701 - binary_accuracy: 0.6589 - val_loss: 0.7726 - val_binary_accuracy: 0.5393\n",
      "Epoch 6/17\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.4985 - binary_accuracy: 0.6812 - val_loss: 0.8371 - val_binary_accuracy: 0.5464\n",
      "Epoch 7/17\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4812 - binary_accuracy: 0.6821 - val_loss: 0.8035 - val_binary_accuracy: 0.5429\n",
      "Epoch 8/17\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4728 - binary_accuracy: 0.6830 - val_loss: 0.8997 - val_binary_accuracy: 0.5786\n",
      "Epoch 9/17\n",
      "112/112 [==============================] - 29s 264ms/step - loss: 0.4877 - binary_accuracy: 0.6696 - val_loss: 0.9362 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/17\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4735 - binary_accuracy: 0.6857 - val_loss: 1.0992 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/17\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4704 - binary_accuracy: 0.6857 - val_loss: 0.9646 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/17\n",
      "112/112 [==============================] - 29s 258ms/step - loss: 0.4789 - binary_accuracy: 0.6812 - val_loss: 1.1785 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/17\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4728 - binary_accuracy: 0.6893 - val_loss: 1.2654 - val_binary_accuracy: 0.5500\n",
      "Epoch 14/17\n",
      "112/112 [==============================] - 29s 259ms/step - loss: 0.4757 - binary_accuracy: 0.6929 - val_loss: 0.9896 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/17\n",
      "112/112 [==============================] - 29s 262ms/step - loss: 0.4696 - binary_accuracy: 0.6902 - val_loss: 1.1042 - val_binary_accuracy: 0.5393\n",
      "Epoch 16/17\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4693 - binary_accuracy: 0.6911 - val_loss: 1.1539 - val_binary_accuracy: 0.5500\n",
      "Epoch 17/17\n",
      "112/112 [==============================] - 29s 260ms/step - loss: 0.4663 - binary_accuracy: 0.6893 - val_loss: 1.1529 - val_binary_accuracy: 0.5500\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6026 - binary_accuracy: 0.6621\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.0774 - binary_accuracy: 0.5667\n",
      "training start... epochs = 18\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_72 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_62 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "112/112 [==============================] - 50s 337ms/step - loss: 0.6916 - binary_accuracy: 0.5321 - val_loss: 0.6898 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/18\n",
      "112/112 [==============================] - 32s 281ms/step - loss: 0.6746 - binary_accuracy: 0.5634 - val_loss: 0.6931 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/18\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.5955 - binary_accuracy: 0.6554 - val_loss: 0.7810 - val_binary_accuracy: 0.5679\n",
      "Epoch 4/18\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.5376 - binary_accuracy: 0.6634 - val_loss: 0.8800 - val_binary_accuracy: 0.5429\n",
      "Epoch 5/18\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4976 - binary_accuracy: 0.6661 - val_loss: 0.8232 - val_binary_accuracy: 0.5571\n",
      "Epoch 6/18\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5196 - binary_accuracy: 0.6830 - val_loss: 0.8834 - val_binary_accuracy: 0.5607\n",
      "Epoch 7/18\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4718 - binary_accuracy: 0.6866 - val_loss: 0.9966 - val_binary_accuracy: 0.5429\n",
      "Epoch 8/18\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4869 - binary_accuracy: 0.6786 - val_loss: 0.9176 - val_binary_accuracy: 0.5679\n",
      "Epoch 9/18\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.4799 - binary_accuracy: 0.6839 - val_loss: 1.0380 - val_binary_accuracy: 0.5607\n",
      "Epoch 10/18\n",
      "112/112 [==============================] - 30s 268ms/step - loss: 0.4766 - binary_accuracy: 0.6902 - val_loss: 0.9345 - val_binary_accuracy: 0.5464\n",
      "Epoch 11/18\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.5178 - binary_accuracy: 0.6652 - val_loss: 0.8421 - val_binary_accuracy: 0.5429\n",
      "Epoch 12/18\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4932 - binary_accuracy: 0.6687 - val_loss: 0.8349 - val_binary_accuracy: 0.5429\n",
      "Epoch 13/18\n",
      "112/112 [==============================] - 29s 263ms/step - loss: 0.4854 - binary_accuracy: 0.6786 - val_loss: 0.8762 - val_binary_accuracy: 0.5464\n",
      "Epoch 14/18\n",
      "112/112 [==============================] - 29s 261ms/step - loss: 0.4852 - binary_accuracy: 0.6705 - val_loss: 0.9235 - val_binary_accuracy: 0.5464\n",
      "Epoch 15/18\n",
      "112/112 [==============================] - 30s 264ms/step - loss: 0.4828 - binary_accuracy: 0.6786 - val_loss: 0.9374 - val_binary_accuracy: 0.5429\n",
      "Epoch 16/18\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4821 - binary_accuracy: 0.6759 - val_loss: 0.9537 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 30s 266ms/step - loss: 0.4805 - binary_accuracy: 0.6795 - val_loss: 0.9765 - val_binary_accuracy: 0.5393\n",
      "Epoch 18/18\n",
      "112/112 [==============================] - 30s 265ms/step - loss: 0.4810 - binary_accuracy: 0.6634 - val_loss: 1.0053 - val_binary_accuracy: 0.5321\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.5836 - binary_accuracy: 0.6500\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 1.0368 - binary_accuracy: 0.5683\n",
      "training start... epochs = 19\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_73 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/19\n",
      "112/112 [==============================] - 52s 345ms/step - loss: 0.6920 - binary_accuracy: 0.5188 - val_loss: 0.6897 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/19\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.7050 - binary_accuracy: 0.5688 - val_loss: 0.6888 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/19\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.6258 - binary_accuracy: 0.6250 - val_loss: 0.7067 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/19\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.5731 - binary_accuracy: 0.6714 - val_loss: 0.7613 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/19\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.5553 - binary_accuracy: 0.6750 - val_loss: 0.8086 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/19\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.5102 - binary_accuracy: 0.6679 - val_loss: 0.8915 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/19\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4818 - binary_accuracy: 0.6848 - val_loss: 0.9846 - val_binary_accuracy: 0.5321\n",
      "Epoch 8/19\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4837 - binary_accuracy: 0.6634 - val_loss: 0.9712 - val_binary_accuracy: 0.5393\n",
      "Epoch 9/19\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.4755 - binary_accuracy: 0.6875 - val_loss: 1.0831 - val_binary_accuracy: 0.5536\n",
      "Epoch 10/19\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4764 - binary_accuracy: 0.6839 - val_loss: 1.0782 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/19\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.4742 - binary_accuracy: 0.6893 - val_loss: 1.1513 - val_binary_accuracy: 0.5464\n",
      "Epoch 12/19\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4822 - binary_accuracy: 0.6848 - val_loss: 1.1542 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/19\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4797 - binary_accuracy: 0.6875 - val_loss: 1.1906 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/19\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4741 - binary_accuracy: 0.6893 - val_loss: 1.1608 - val_binary_accuracy: 0.5429\n",
      "Epoch 15/19\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4761 - binary_accuracy: 0.6866 - val_loss: 1.1881 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/19\n",
      "112/112 [==============================] - 30s 269ms/step - loss: 0.4731 - binary_accuracy: 0.6893 - val_loss: 1.2764 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/19\n",
      "112/112 [==============================] - 30s 270ms/step - loss: 0.4730 - binary_accuracy: 0.6893 - val_loss: 1.2408 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/19\n",
      "112/112 [==============================] - 31s 274ms/step - loss: 0.4706 - binary_accuracy: 0.6893 - val_loss: 1.2435 - val_binary_accuracy: 0.5500\n",
      "Epoch 19/19\n",
      "112/112 [==============================] - 30s 271ms/step - loss: 0.4857 - binary_accuracy: 0.6741 - val_loss: 1.2538 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6390 - binary_accuracy: 0.6500\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.2122 - binary_accuracy: 0.5667\n",
      "training start... epochs = 20\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_74 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_64 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_152 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "112/112 [==============================] - 52s 357ms/step - loss: 0.6912 - binary_accuracy: 0.5259 - val_loss: 0.6903 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/20\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.6757 - binary_accuracy: 0.5643 - val_loss: 0.6920 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/20\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.6040 - binary_accuracy: 0.6473 - val_loss: 0.7952 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.5491 - binary_accuracy: 0.6741 - val_loss: 0.7794 - val_binary_accuracy: 0.5143\n",
      "Epoch 5/20\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5023 - binary_accuracy: 0.6768 - val_loss: 0.8615 - val_binary_accuracy: 0.5143\n",
      "Epoch 6/20\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.5721 - binary_accuracy: 0.6429 - val_loss: 0.8384 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/20\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.5077 - binary_accuracy: 0.6580 - val_loss: 0.8274 - val_binary_accuracy: 0.5464\n",
      "Epoch 8/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.5042 - binary_accuracy: 0.6634 - val_loss: 0.8386 - val_binary_accuracy: 0.5429\n",
      "Epoch 9/20\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4975 - binary_accuracy: 0.6616 - val_loss: 0.8293 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/20\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.4882 - binary_accuracy: 0.6750 - val_loss: 0.8625 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/20\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4805 - binary_accuracy: 0.6634 - val_loss: 0.8811 - val_binary_accuracy: 0.5464\n",
      "Epoch 12/20\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4752 - binary_accuracy: 0.6857 - val_loss: 0.8831 - val_binary_accuracy: 0.5214\n",
      "Epoch 13/20\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.4716 - binary_accuracy: 0.6893 - val_loss: 0.9555 - val_binary_accuracy: 0.5464\n",
      "Epoch 14/20\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4773 - binary_accuracy: 0.6920 - val_loss: 0.8188 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/20\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.4808 - binary_accuracy: 0.6670 - val_loss: 0.8478 - val_binary_accuracy: 0.5643\n",
      "Epoch 16/20\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4737 - binary_accuracy: 0.6857 - val_loss: 0.8765 - val_binary_accuracy: 0.5714\n",
      "Epoch 17/20\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4720 - binary_accuracy: 0.6902 - val_loss: 0.8829 - val_binary_accuracy: 0.5786\n",
      "Epoch 18/20\n",
      "112/112 [==============================] - 30s 272ms/step - loss: 0.4920 - binary_accuracy: 0.6866 - val_loss: 0.8106 - val_binary_accuracy: 0.5393\n",
      "Epoch 19/20\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.4821 - binary_accuracy: 0.6777 - val_loss: 0.8531 - val_binary_accuracy: 0.5321\n",
      "Epoch 20/20\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4797 - binary_accuracy: 0.6786 - val_loss: 0.9146 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5652 - binary_accuracy: 0.6500\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 0.9144 - binary_accuracy: 0.5600\n",
      "training start... epochs = 21\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_75 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_65 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "112/112 [==============================] - 55s 365ms/step - loss: 0.6924 - binary_accuracy: 0.5214 - val_loss: 0.6908 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/21\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.6947 - binary_accuracy: 0.5607 - val_loss: 0.6919 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/21\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.6382 - binary_accuracy: 0.6196 - val_loss: 0.7404 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/21\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.5692 - binary_accuracy: 0.6670 - val_loss: 0.8991 - val_binary_accuracy: 0.5214\n",
      "Epoch 5/21\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.5493 - binary_accuracy: 0.6786 - val_loss: 0.8291 - val_binary_accuracy: 0.4929\n",
      "Epoch 6/21\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.5015 - binary_accuracy: 0.6750 - val_loss: 1.0405 - val_binary_accuracy: 0.5071\n",
      "Epoch 7/21\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4755 - binary_accuracy: 0.6643 - val_loss: 1.1814 - val_binary_accuracy: 0.5286\n",
      "Epoch 8/21\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4686 - binary_accuracy: 0.6732 - val_loss: 1.3514 - val_binary_accuracy: 0.5429\n",
      "Epoch 9/21\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4686 - binary_accuracy: 0.6777 - val_loss: 1.1752 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/21\n",
      "112/112 [==============================] - 31s 273ms/step - loss: 0.4948 - binary_accuracy: 0.6750 - val_loss: 1.0032 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/21\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4798 - binary_accuracy: 0.6732 - val_loss: 1.1524 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/21\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4675 - binary_accuracy: 0.6795 - val_loss: 1.3058 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/21\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.4628 - binary_accuracy: 0.6866 - val_loss: 1.5073 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/21\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4819 - binary_accuracy: 0.6705 - val_loss: 1.3033 - val_binary_accuracy: 0.5464\n",
      "Epoch 15/21\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4622 - binary_accuracy: 0.6911 - val_loss: 1.3761 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/21\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.4627 - binary_accuracy: 0.6839 - val_loss: 1.5329 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/21\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4610 - binary_accuracy: 0.6893 - val_loss: 1.5162 - val_binary_accuracy: 0.5500\n",
      "Epoch 18/21\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4848 - binary_accuracy: 0.6866 - val_loss: 1.3024 - val_binary_accuracy: 0.5429\n",
      "Epoch 19/21\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.4732 - binary_accuracy: 0.6857 - val_loss: 1.3715 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/21\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4697 - binary_accuracy: 0.6875 - val_loss: 1.4586 - val_binary_accuracy: 0.5357\n",
      "Epoch 21/21\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.4683 - binary_accuracy: 0.6866 - val_loss: 1.6072 - val_binary_accuracy: 0.5429\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6951 - binary_accuracy: 0.6586\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.4340 - binary_accuracy: 0.5667\n",
      "training start... epochs = 22\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_76 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_66 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_156 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/22\n",
      "112/112 [==============================] - 55s 372ms/step - loss: 0.6928 - binary_accuracy: 0.5134 - val_loss: 0.6888 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/22\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.6649 - binary_accuracy: 0.5732 - val_loss: 0.7213 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/22\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.7806 - binary_accuracy: 0.6464 - val_loss: 0.7151 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/22\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.5708 - binary_accuracy: 0.6634 - val_loss: 0.7269 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5270 - binary_accuracy: 0.6759 - val_loss: 0.8021 - val_binary_accuracy: 0.4964\n",
      "Epoch 6/22\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4994 - binary_accuracy: 0.6482 - val_loss: 0.8940 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/22\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4798 - binary_accuracy: 0.6830 - val_loss: 1.0175 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/22\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4814 - binary_accuracy: 0.6554 - val_loss: 0.9617 - val_binary_accuracy: 0.5393\n",
      "Epoch 9/22\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4788 - binary_accuracy: 0.6750 - val_loss: 1.0781 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/22\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4779 - binary_accuracy: 0.6848 - val_loss: 1.2413 - val_binary_accuracy: 0.5286\n",
      "Epoch 11/22\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4996 - binary_accuracy: 0.6714 - val_loss: 0.8684 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/22\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4812 - binary_accuracy: 0.6804 - val_loss: 0.9950 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/22\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4749 - binary_accuracy: 0.6857 - val_loss: 1.0912 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/22\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4753 - binary_accuracy: 0.6884 - val_loss: 1.0535 - val_binary_accuracy: 0.5286\n",
      "Epoch 15/22\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4749 - binary_accuracy: 0.6812 - val_loss: 1.1013 - val_binary_accuracy: 0.5250\n",
      "Epoch 16/22\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4827 - binary_accuracy: 0.6848 - val_loss: 1.2014 - val_binary_accuracy: 0.5321\n",
      "Epoch 17/22\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4788 - binary_accuracy: 0.6884 - val_loss: 1.0399 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/22\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4742 - binary_accuracy: 0.6768 - val_loss: 1.1992 - val_binary_accuracy: 0.5321\n",
      "Epoch 19/22\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4694 - binary_accuracy: 0.6902 - val_loss: 1.2968 - val_binary_accuracy: 0.5250\n",
      "Epoch 20/22\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4650 - binary_accuracy: 0.6893 - val_loss: 1.4357 - val_binary_accuracy: 0.5071\n",
      "Epoch 21/22\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4627 - binary_accuracy: 0.6848 - val_loss: 1.3759 - val_binary_accuracy: 0.5357\n",
      "Epoch 22/22\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4672 - binary_accuracy: 0.6821 - val_loss: 1.4788 - val_binary_accuracy: 0.5143\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6649 - binary_accuracy: 0.6536\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.4672 - binary_accuracy: 0.5383\n",
      "training start... epochs = 23\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_77 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_67 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_152 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_153 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "112/112 [==============================] - 58s 386ms/step - loss: 0.6916 - binary_accuracy: 0.5277 - val_loss: 0.6926 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/23\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.6712 - binary_accuracy: 0.5679 - val_loss: 0.6949 - val_binary_accuracy: 0.5321\n",
      "Epoch 3/23\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.5997 - binary_accuracy: 0.6420 - val_loss: 0.6860 - val_binary_accuracy: 0.5429\n",
      "Epoch 4/23\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.5627 - binary_accuracy: 0.6571 - val_loss: 0.7074 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/23\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.5239 - binary_accuracy: 0.6643 - val_loss: 0.8575 - val_binary_accuracy: 0.5607\n",
      "Epoch 6/23\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4921 - binary_accuracy: 0.6714 - val_loss: 0.9163 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/23\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4791 - binary_accuracy: 0.6607 - val_loss: 1.0923 - val_binary_accuracy: 0.5607\n",
      "Epoch 8/23\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.5472 - binary_accuracy: 0.6857 - val_loss: 0.8239 - val_binary_accuracy: 0.5429\n",
      "Epoch 9/23\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4802 - binary_accuracy: 0.6839 - val_loss: 0.8956 - val_binary_accuracy: 0.5643\n",
      "Epoch 10/23\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4777 - binary_accuracy: 0.6857 - val_loss: 1.0231 - val_binary_accuracy: 0.5429\n",
      "Epoch 11/23\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4756 - binary_accuracy: 0.6848 - val_loss: 1.0987 - val_binary_accuracy: 0.5536\n",
      "Epoch 12/23\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4790 - binary_accuracy: 0.6866 - val_loss: 0.9412 - val_binary_accuracy: 0.5607\n",
      "Epoch 13/23\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4736 - binary_accuracy: 0.6884 - val_loss: 1.0832 - val_binary_accuracy: 0.5679\n",
      "Epoch 14/23\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4690 - binary_accuracy: 0.6875 - val_loss: 1.1756 - val_binary_accuracy: 0.5714\n",
      "Epoch 15/23\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4705 - binary_accuracy: 0.6857 - val_loss: 1.2171 - val_binary_accuracy: 0.5714\n",
      "Epoch 16/23\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.4743 - binary_accuracy: 0.6893 - val_loss: 1.1592 - val_binary_accuracy: 0.5643\n",
      "Epoch 17/23\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4714 - binary_accuracy: 0.6893 - val_loss: 1.3117 - val_binary_accuracy: 0.5714\n",
      "Epoch 18/23\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4709 - binary_accuracy: 0.6893 - val_loss: 1.2183 - val_binary_accuracy: 0.5679\n",
      "Epoch 19/23\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.4674 - binary_accuracy: 0.6893 - val_loss: 1.2757 - val_binary_accuracy: 0.5607\n",
      "Epoch 20/23\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4617 - binary_accuracy: 0.6893 - val_loss: 1.4760 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/23\n",
      "112/112 [==============================] - 31s 275ms/step - loss: 0.5481 - binary_accuracy: 0.6991 - val_loss: 0.8533 - val_binary_accuracy: 0.6250\n",
      "Epoch 22/23\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4577 - binary_accuracy: 0.7777 - val_loss: 1.0370 - val_binary_accuracy: 0.6357\n",
      "Epoch 23/23\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4461 - binary_accuracy: 0.7723 - val_loss: 1.0322 - val_binary_accuracy: 0.6357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.5509 - binary_accuracy: 0.7557\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.9560 - binary_accuracy: 0.6100\n",
      "training start... epochs = 24\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_78 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_68 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_154 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_160 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_155 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      "112/112 [==============================] - 56s 375ms/step - loss: 0.6916 - binary_accuracy: 0.5259 - val_loss: 0.6901 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/24\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.6722 - binary_accuracy: 0.5777 - val_loss: 0.6885 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/24\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.5949 - binary_accuracy: 0.6304 - val_loss: 0.8022 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/24\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.5573 - binary_accuracy: 0.6777 - val_loss: 0.8340 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/24\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.5796 - binary_accuracy: 0.6536 - val_loss: 0.7272 - val_binary_accuracy: 0.5500\n",
      "Epoch 6/24\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4969 - binary_accuracy: 0.6750 - val_loss: 0.8082 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/24\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4868 - binary_accuracy: 0.6821 - val_loss: 0.9005 - val_binary_accuracy: 0.5500\n",
      "Epoch 8/24\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4747 - binary_accuracy: 0.6866 - val_loss: 0.9804 - val_binary_accuracy: 0.5500\n",
      "Epoch 9/24\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4713 - binary_accuracy: 0.6875 - val_loss: 1.0628 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/24\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4720 - binary_accuracy: 0.6938 - val_loss: 1.0034 - val_binary_accuracy: 0.5429\n",
      "Epoch 11/24\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4670 - binary_accuracy: 0.6875 - val_loss: 1.1029 - val_binary_accuracy: 0.5500\n",
      "Epoch 12/24\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4662 - binary_accuracy: 0.6821 - val_loss: 1.1312 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/24\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4686 - binary_accuracy: 0.6830 - val_loss: 1.1294 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/24\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.4783 - binary_accuracy: 0.6929 - val_loss: 1.0055 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/24\n",
      "112/112 [==============================] - 32s 291ms/step - loss: 0.5164 - binary_accuracy: 0.6812 - val_loss: 0.8609 - val_binary_accuracy: 0.5321\n",
      "Epoch 16/24\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.4829 - binary_accuracy: 0.6786 - val_loss: 0.9444 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/24\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4742 - binary_accuracy: 0.6857 - val_loss: 1.0078 - val_binary_accuracy: 0.5607\n",
      "Epoch 18/24\n",
      "112/112 [==============================] - 31s 281ms/step - loss: 0.7272 - binary_accuracy: 0.6491 - val_loss: 0.7332 - val_binary_accuracy: 0.4893\n",
      "Epoch 19/24\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.5923 - binary_accuracy: 0.6313 - val_loss: 0.7762 - val_binary_accuracy: 0.5179\n",
      "Epoch 20/24\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.5268 - binary_accuracy: 0.6670 - val_loss: 0.8853 - val_binary_accuracy: 0.5214\n",
      "Epoch 21/24\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4997 - binary_accuracy: 0.6687 - val_loss: 0.9049 - val_binary_accuracy: 0.5250\n",
      "Epoch 22/24\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4872 - binary_accuracy: 0.6786 - val_loss: 0.9538 - val_binary_accuracy: 0.5179\n",
      "Epoch 23/24\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4804 - binary_accuracy: 0.6830 - val_loss: 1.0104 - val_binary_accuracy: 0.5393\n",
      "Epoch 24/24\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4765 - binary_accuracy: 0.6893 - val_loss: 1.0655 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 110ms/step - loss: 0.5908 - binary_accuracy: 0.6586\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.9428 - binary_accuracy: 0.5700\n",
      "training start... epochs = 25\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_79 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_69 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_156 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_157 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "112/112 [==============================] - 57s 396ms/step - loss: 0.6912 - binary_accuracy: 0.5446 - val_loss: 0.6888 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/25\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.8394 - binary_accuracy: 0.5330 - val_loss: 0.6939 - val_binary_accuracy: 0.4893\n",
      "Epoch 3/25\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.6759 - binary_accuracy: 0.6018 - val_loss: 0.6890 - val_binary_accuracy: 0.5250\n",
      "Epoch 4/25\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.6117 - binary_accuracy: 0.6304 - val_loss: 0.7477 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/25\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.5373 - binary_accuracy: 0.6705 - val_loss: 0.7617 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/25\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.5210 - binary_accuracy: 0.6607 - val_loss: 0.8180 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/25\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4970 - binary_accuracy: 0.6759 - val_loss: 0.7872 - val_binary_accuracy: 0.5571\n",
      "Epoch 8/25\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4875 - binary_accuracy: 0.6607 - val_loss: 0.8003 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/25\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5042 - binary_accuracy: 0.6580 - val_loss: 0.7662 - val_binary_accuracy: 0.5321\n",
      "Epoch 10/25\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4980 - binary_accuracy: 0.6705 - val_loss: 0.8374 - val_binary_accuracy: 0.5357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4864 - binary_accuracy: 0.6795 - val_loss: 0.9413 - val_binary_accuracy: 0.5500\n",
      "Epoch 12/25\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4775 - binary_accuracy: 0.6741 - val_loss: 1.0173 - val_binary_accuracy: 0.5464\n",
      "Epoch 13/25\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4786 - binary_accuracy: 0.6670 - val_loss: 1.0602 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/25\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4735 - binary_accuracy: 0.6839 - val_loss: 1.0397 - val_binary_accuracy: 0.5214\n",
      "Epoch 15/25\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4995 - binary_accuracy: 0.6893 - val_loss: 0.9640 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/25\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4729 - binary_accuracy: 0.6902 - val_loss: 1.0144 - val_binary_accuracy: 0.5179\n",
      "Epoch 17/25\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4893 - binary_accuracy: 0.6804 - val_loss: 0.9826 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/25\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4793 - binary_accuracy: 0.6866 - val_loss: 1.0294 - val_binary_accuracy: 0.5464\n",
      "Epoch 19/25\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4772 - binary_accuracy: 0.6804 - val_loss: 1.0921 - val_binary_accuracy: 0.5464\n",
      "Epoch 20/25\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4723 - binary_accuracy: 0.6848 - val_loss: 1.1463 - val_binary_accuracy: 0.5536\n",
      "Epoch 21/25\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4737 - binary_accuracy: 0.6839 - val_loss: 1.1605 - val_binary_accuracy: 0.5536\n",
      "Epoch 22/25\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4696 - binary_accuracy: 0.6857 - val_loss: 1.2208 - val_binary_accuracy: 0.5536\n",
      "Epoch 23/25\n",
      "112/112 [==============================] - 31s 277ms/step - loss: 0.4638 - binary_accuracy: 0.6964 - val_loss: 1.2881 - val_binary_accuracy: 0.5500\n",
      "Epoch 24/25\n",
      "112/112 [==============================] - 31s 276ms/step - loss: 0.4653 - binary_accuracy: 0.6946 - val_loss: 1.3385 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/25\n",
      "112/112 [==============================] - 31s 278ms/step - loss: 0.4721 - binary_accuracy: 0.6741 - val_loss: 1.1991 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.6076 - binary_accuracy: 0.6593\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.0148 - binary_accuracy: 0.5800\n",
      "training start... epochs = 26\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_80 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_70 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/26\n",
      "112/112 [==============================] - 57s 386ms/step - loss: 0.6915 - binary_accuracy: 0.5223 - val_loss: 0.6889 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/26\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.6663 - binary_accuracy: 0.5705 - val_loss: 0.6979 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/26\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.5900 - binary_accuracy: 0.6464 - val_loss: 0.7781 - val_binary_accuracy: 0.5107\n",
      "Epoch 4/26\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.5406 - binary_accuracy: 0.6741 - val_loss: 0.8410 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/26\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5203 - binary_accuracy: 0.6687 - val_loss: 0.8035 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/26\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4950 - binary_accuracy: 0.6696 - val_loss: 0.8656 - val_binary_accuracy: 0.5429\n",
      "Epoch 7/26\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4799 - binary_accuracy: 0.6723 - val_loss: 0.9955 - val_binary_accuracy: 0.5500\n",
      "Epoch 8/26\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4770 - binary_accuracy: 0.6759 - val_loss: 1.0570 - val_binary_accuracy: 0.5429\n",
      "Epoch 9/26\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4677 - binary_accuracy: 0.6902 - val_loss: 1.1906 - val_binary_accuracy: 0.5250\n",
      "Epoch 10/26\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4867 - binary_accuracy: 0.6768 - val_loss: 1.1040 - val_binary_accuracy: 0.5357\n",
      "Epoch 11/26\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4755 - binary_accuracy: 0.6848 - val_loss: 1.1216 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/26\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4732 - binary_accuracy: 0.6902 - val_loss: 1.1700 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/26\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4713 - binary_accuracy: 0.6946 - val_loss: 1.1621 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/26\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4837 - binary_accuracy: 0.6705 - val_loss: 1.1515 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/26\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4779 - binary_accuracy: 0.6848 - val_loss: 1.3186 - val_binary_accuracy: 0.5393\n",
      "Epoch 16/26\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4682 - binary_accuracy: 0.6938 - val_loss: 1.5155 - val_binary_accuracy: 0.5214\n",
      "Epoch 17/26\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4665 - binary_accuracy: 0.6830 - val_loss: 1.4616 - val_binary_accuracy: 0.5393\n",
      "Epoch 18/26\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4708 - binary_accuracy: 0.6848 - val_loss: 1.2246 - val_binary_accuracy: 0.5214\n",
      "Epoch 19/26\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4651 - binary_accuracy: 0.6821 - val_loss: 1.3371 - val_binary_accuracy: 0.5357\n",
      "Epoch 20/26\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4701 - binary_accuracy: 0.6857 - val_loss: 1.1521 - val_binary_accuracy: 0.5286\n",
      "Epoch 21/26\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4647 - binary_accuracy: 0.6857 - val_loss: 1.2305 - val_binary_accuracy: 0.5250\n",
      "Epoch 22/26\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4661 - binary_accuracy: 0.6857 - val_loss: 1.2966 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/26\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4640 - binary_accuracy: 0.6893 - val_loss: 1.4044 - val_binary_accuracy: 0.5393\n",
      "Epoch 24/26\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4683 - binary_accuracy: 0.6884 - val_loss: 1.3244 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/26\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4647 - binary_accuracy: 0.6893 - val_loss: 1.3662 - val_binary_accuracy: 0.5357\n",
      "Epoch 26/26\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4662 - binary_accuracy: 0.6875 - val_loss: 1.2776 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6304 - binary_accuracy: 0.6614\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1230 - binary_accuracy: 0.5700\n",
      "training start... epochs = 27\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_81 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_71 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_160 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_161 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/27\n",
      "112/112 [==============================] - 58s 399ms/step - loss: 0.6922 - binary_accuracy: 0.5161 - val_loss: 0.6896 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/27\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.6719 - binary_accuracy: 0.5688 - val_loss: 0.7038 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/27\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.5954 - binary_accuracy: 0.6518 - val_loss: 0.7356 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/27\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.5648 - binary_accuracy: 0.6777 - val_loss: 0.7767 - val_binary_accuracy: 0.5143\n",
      "Epoch 5/27\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.5241 - binary_accuracy: 0.6696 - val_loss: 0.9530 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/27\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4952 - binary_accuracy: 0.6643 - val_loss: 1.0056 - val_binary_accuracy: 0.5214\n",
      "Epoch 7/27\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4913 - binary_accuracy: 0.6768 - val_loss: 1.0268 - val_binary_accuracy: 0.5250\n",
      "Epoch 8/27\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4838 - binary_accuracy: 0.6804 - val_loss: 1.0252 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/27\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4770 - binary_accuracy: 0.6821 - val_loss: 1.1468 - val_binary_accuracy: 0.5214\n",
      "Epoch 10/27\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4821 - binary_accuracy: 0.6661 - val_loss: 0.9026 - val_binary_accuracy: 0.5321\n",
      "Epoch 11/27\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4801 - binary_accuracy: 0.6857 - val_loss: 1.1253 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/27\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4773 - binary_accuracy: 0.6875 - val_loss: 1.1346 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/27\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4754 - binary_accuracy: 0.6866 - val_loss: 1.2248 - val_binary_accuracy: 0.5321\n",
      "Epoch 14/27\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4726 - binary_accuracy: 0.6884 - val_loss: 1.2936 - val_binary_accuracy: 0.5321\n",
      "Epoch 15/27\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4717 - binary_accuracy: 0.6848 - val_loss: 1.3832 - val_binary_accuracy: 0.5286\n",
      "Epoch 16/27\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4670 - binary_accuracy: 0.6893 - val_loss: 1.5328 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/27\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4649 - binary_accuracy: 0.6857 - val_loss: 1.5140 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/27\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.5761 - binary_accuracy: 0.6652 - val_loss: 0.8464 - val_binary_accuracy: 0.5357\n",
      "Epoch 19/27\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4824 - binary_accuracy: 0.6830 - val_loss: 1.1656 - val_binary_accuracy: 0.5321\n",
      "Epoch 20/27\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4778 - binary_accuracy: 0.6884 - val_loss: 0.9726 - val_binary_accuracy: 0.5214\n",
      "Epoch 21/27\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4699 - binary_accuracy: 0.6875 - val_loss: 1.0488 - val_binary_accuracy: 0.5357\n",
      "Epoch 22/27\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4654 - binary_accuracy: 0.6893 - val_loss: 1.0955 - val_binary_accuracy: 0.5321\n",
      "Epoch 23/27\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4642 - binary_accuracy: 0.6893 - val_loss: 1.0752 - val_binary_accuracy: 0.5536\n",
      "Epoch 24/27\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4629 - binary_accuracy: 0.6875 - val_loss: 1.1844 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/27\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4673 - binary_accuracy: 0.6893 - val_loss: 1.1103 - val_binary_accuracy: 0.5500\n",
      "Epoch 26/27\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4709 - binary_accuracy: 0.6804 - val_loss: 1.1699 - val_binary_accuracy: 0.5429\n",
      "Epoch 27/27\n",
      "112/112 [==============================] - 32s 283ms/step - loss: 0.4656 - binary_accuracy: 0.6884 - val_loss: 1.1306 - val_binary_accuracy: 0.5321\n",
      "evaluating...\n",
      "140/140 [==============================] - 14s 103ms/step - loss: 0.5937 - binary_accuracy: 0.6579\n",
      "60/60 [==============================] - 6s 103ms/step - loss: 1.0054 - binary_accuracy: 0.5650\n",
      "training start... epochs = 28\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_82 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_72 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_162 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_163 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "112/112 [==============================] - 59s 391ms/step - loss: 0.6918 - binary_accuracy: 0.5330 - val_loss: 0.6904 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/28\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.6619 - binary_accuracy: 0.5911 - val_loss: 0.6920 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/28\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.5918 - binary_accuracy: 0.6464 - val_loss: 0.6868 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/28\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5572 - binary_accuracy: 0.6714 - val_loss: 1.0366 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/28\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.5542 - binary_accuracy: 0.6438 - val_loss: 0.7582 - val_binary_accuracy: 0.5286\n",
      "Epoch 6/28\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4920 - binary_accuracy: 0.6812 - val_loss: 1.0367 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/28\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4743 - binary_accuracy: 0.6866 - val_loss: 1.0785 - val_binary_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/28\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.6341 - binary_accuracy: 0.6589 - val_loss: 1.0792 - val_binary_accuracy: 0.5607\n",
      "Epoch 9/28\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.5385 - binary_accuracy: 0.6723 - val_loss: 1.0202 - val_binary_accuracy: 0.5464\n",
      "Epoch 10/28\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.5088 - binary_accuracy: 0.6884 - val_loss: 1.0629 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/28\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4988 - binary_accuracy: 0.6732 - val_loss: 1.1366 - val_binary_accuracy: 0.5393\n",
      "Epoch 12/28\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4880 - binary_accuracy: 0.6804 - val_loss: 1.1601 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/28\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4896 - binary_accuracy: 0.6705 - val_loss: 1.1985 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/28\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4849 - binary_accuracy: 0.6562 - val_loss: 1.2321 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/28\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4798 - binary_accuracy: 0.6804 - val_loss: 1.2790 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/28\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.5261 - binary_accuracy: 0.6589 - val_loss: 0.8146 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/28\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.4947 - binary_accuracy: 0.6679 - val_loss: 0.9623 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/28\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4888 - binary_accuracy: 0.6580 - val_loss: 1.0051 - val_binary_accuracy: 0.5036\n",
      "Epoch 19/28\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4790 - binary_accuracy: 0.6821 - val_loss: 1.0543 - val_binary_accuracy: 0.5179\n",
      "Epoch 20/28\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4802 - binary_accuracy: 0.6652 - val_loss: 1.0723 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/28\n",
      "112/112 [==============================] - 31s 279ms/step - loss: 0.4754 - binary_accuracy: 0.6893 - val_loss: 1.1332 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/28\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.4749 - binary_accuracy: 0.6848 - val_loss: 1.2247 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/28\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4704 - binary_accuracy: 0.6768 - val_loss: 1.2717 - val_binary_accuracy: 0.5071\n",
      "Epoch 24/28\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.4708 - binary_accuracy: 0.7268 - val_loss: 1.1754 - val_binary_accuracy: 0.5964\n",
      "Epoch 25/28\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.4474 - binary_accuracy: 0.7527 - val_loss: 1.0791 - val_binary_accuracy: 0.5143\n",
      "Epoch 26/28\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.4876 - binary_accuracy: 0.6812 - val_loss: 1.0123 - val_binary_accuracy: 0.5429\n",
      "Epoch 27/28\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4768 - binary_accuracy: 0.6812 - val_loss: 1.0718 - val_binary_accuracy: 0.5429\n",
      "Epoch 28/28\n",
      "112/112 [==============================] - 32s 282ms/step - loss: 0.4755 - binary_accuracy: 0.6893 - val_loss: 1.1892 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6139 - binary_accuracy: 0.6650\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.1527 - binary_accuracy: 0.5767\n",
      "training start... epochs = 29\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_83 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_73 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_164 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/29\n",
      "112/112 [==============================] - 55s 382ms/step - loss: 0.6921 - binary_accuracy: 0.5348 - val_loss: 0.6885 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/29\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.6557 - binary_accuracy: 0.5866 - val_loss: 0.6750 - val_binary_accuracy: 0.5464\n",
      "Epoch 3/29\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.5926 - binary_accuracy: 0.6545 - val_loss: 0.7279 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/29\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.5495 - binary_accuracy: 0.6750 - val_loss: 0.7207 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/29\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.5388 - binary_accuracy: 0.6491 - val_loss: 0.8854 - val_binary_accuracy: 0.5679\n",
      "Epoch 6/29\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.5075 - binary_accuracy: 0.6643 - val_loss: 0.9002 - val_binary_accuracy: 0.5571\n",
      "Epoch 7/29\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4776 - binary_accuracy: 0.6875 - val_loss: 1.2781 - val_binary_accuracy: 0.5679\n",
      "Epoch 8/29\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4799 - binary_accuracy: 0.6821 - val_loss: 1.0230 - val_binary_accuracy: 0.5500\n",
      "Epoch 9/29\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4751 - binary_accuracy: 0.6884 - val_loss: 1.1687 - val_binary_accuracy: 0.5500\n",
      "Epoch 10/29\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4700 - binary_accuracy: 0.6893 - val_loss: 1.1485 - val_binary_accuracy: 0.5571\n",
      "Epoch 11/29\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4684 - binary_accuracy: 0.6902 - val_loss: 1.3055 - val_binary_accuracy: 0.5714\n",
      "Epoch 12/29\n",
      "112/112 [==============================] - 32s 284ms/step - loss: 0.4858 - binary_accuracy: 0.6866 - val_loss: 1.0479 - val_binary_accuracy: 0.5750\n",
      "Epoch 13/29\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4647 - binary_accuracy: 0.6884 - val_loss: 1.1569 - val_binary_accuracy: 0.5429\n",
      "Epoch 14/29\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4640 - binary_accuracy: 0.6902 - val_loss: 1.1921 - val_binary_accuracy: 0.5643\n",
      "Epoch 15/29\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4680 - binary_accuracy: 0.6848 - val_loss: 0.9867 - val_binary_accuracy: 0.5500\n",
      "Epoch 16/29\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4785 - binary_accuracy: 0.6884 - val_loss: 0.9981 - val_binary_accuracy: 0.5464\n",
      "Epoch 17/29\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4738 - binary_accuracy: 0.6893 - val_loss: 1.0705 - val_binary_accuracy: 0.5536\n",
      "Epoch 18/29\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4736 - binary_accuracy: 0.6893 - val_loss: 1.1087 - val_binary_accuracy: 0.5607\n",
      "Epoch 19/29\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4735 - binary_accuracy: 0.6902 - val_loss: 1.1655 - val_binary_accuracy: 0.5607\n",
      "Epoch 20/29\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4714 - binary_accuracy: 0.6920 - val_loss: 1.2183 - val_binary_accuracy: 0.5607\n",
      "Epoch 21/29\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.8108 - binary_accuracy: 0.6339 - val_loss: 0.7753 - val_binary_accuracy: 0.5321\n",
      "Epoch 22/29\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.5414 - binary_accuracy: 0.6759 - val_loss: 0.8401 - val_binary_accuracy: 0.5750\n",
      "Epoch 23/29\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4985 - binary_accuracy: 0.6562 - val_loss: 0.8395 - val_binary_accuracy: 0.5857\n",
      "Epoch 24/29\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.5518 - binary_accuracy: 0.6848 - val_loss: 0.8976 - val_binary_accuracy: 0.5571\n",
      "Epoch 25/29\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.5242 - binary_accuracy: 0.6732 - val_loss: 0.8627 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/29\n",
      "112/112 [==============================] - 32s 286ms/step - loss: 0.5377 - binary_accuracy: 0.6875 - val_loss: 0.8965 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/29\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4825 - binary_accuracy: 0.6804 - val_loss: 0.9015 - val_binary_accuracy: 0.5429\n",
      "Epoch 28/29\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4848 - binary_accuracy: 0.6625 - val_loss: 0.9328 - val_binary_accuracy: 0.5679\n",
      "Epoch 29/29\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4762 - binary_accuracy: 0.6616 - val_loss: 0.9834 - val_binary_accuracy: 0.5571\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.5716 - binary_accuracy: 0.6629\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 0.9188 - binary_accuracy: 0.5967\n",
      "training start... epochs = 30\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_84 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_74 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 58s 391ms/step - loss: 0.6904 - binary_accuracy: 0.5286 - val_loss: 0.6924 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.6666 - binary_accuracy: 0.5580 - val_loss: 0.6871 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.5954 - binary_accuracy: 0.6473 - val_loss: 0.7566 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5518 - binary_accuracy: 0.6795 - val_loss: 0.9002 - val_binary_accuracy: 0.5321\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.5511 - binary_accuracy: 0.6687 - val_loss: 0.7266 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.5111 - binary_accuracy: 0.6509 - val_loss: 0.8487 - val_binary_accuracy: 0.5286\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4832 - binary_accuracy: 0.6723 - val_loss: 0.9480 - val_binary_accuracy: 0.5429\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4751 - binary_accuracy: 0.6759 - val_loss: 1.0309 - val_binary_accuracy: 0.5571\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4752 - binary_accuracy: 0.6705 - val_loss: 1.1245 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4695 - binary_accuracy: 0.6795 - val_loss: 0.9627 - val_binary_accuracy: 0.5321\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4777 - binary_accuracy: 0.6830 - val_loss: 1.0973 - val_binary_accuracy: 0.5250\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4729 - binary_accuracy: 0.6848 - val_loss: 1.2267 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4673 - binary_accuracy: 0.6866 - val_loss: 1.3114 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4695 - binary_accuracy: 0.6946 - val_loss: 1.3511 - val_binary_accuracy: 0.5429\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4614 - binary_accuracy: 0.6902 - val_loss: 1.4275 - val_binary_accuracy: 0.4929\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.8910 - binary_accuracy: 0.6196 - val_loss: 0.7092 - val_binary_accuracy: 0.5143\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.6182 - binary_accuracy: 0.6196 - val_loss: 0.7010 - val_binary_accuracy: 0.5179\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5966 - binary_accuracy: 0.6357 - val_loss: 0.7246 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5788 - binary_accuracy: 0.6429 - val_loss: 0.7867 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5324 - binary_accuracy: 0.6518 - val_loss: 0.7794 - val_binary_accuracy: 0.5179\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.5692 - binary_accuracy: 0.6580 - val_loss: 0.7462 - val_binary_accuracy: 0.5250\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.5209 - binary_accuracy: 0.6705 - val_loss: 0.7754 - val_binary_accuracy: 0.5179\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.5186 - binary_accuracy: 0.6509 - val_loss: 0.8144 - val_binary_accuracy: 0.4893\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.5010 - binary_accuracy: 0.6759 - val_loss: 0.8132 - val_binary_accuracy: 0.5179\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4950 - binary_accuracy: 0.6616 - val_loss: 0.8468 - val_binary_accuracy: 0.5143\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5053 - binary_accuracy: 0.6625 - val_loss: 0.8341 - val_binary_accuracy: 0.4857\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4913 - binary_accuracy: 0.6634 - val_loss: 0.8572 - val_binary_accuracy: 0.5214\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4932 - binary_accuracy: 0.6714 - val_loss: 0.8514 - val_binary_accuracy: 0.5214\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4976 - binary_accuracy: 0.6491 - val_loss: 0.8533 - val_binary_accuracy: 0.5250\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4982 - binary_accuracy: 0.6580 - val_loss: 0.8519 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5597 - binary_accuracy: 0.6093\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 0.8157 - binary_accuracy: 0.5033\n",
      "training start... epochs = 31\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_85 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_75 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_168 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/31\n",
      "112/112 [==============================] - 58s 396ms/step - loss: 0.6915 - binary_accuracy: 0.5018 - val_loss: 0.6918 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/31\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.6681 - binary_accuracy: 0.5714 - val_loss: 0.6976 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/31\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.5855 - binary_accuracy: 0.6545 - val_loss: 0.7507 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/31\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.5567 - binary_accuracy: 0.6732 - val_loss: 0.8849 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/31\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.5076 - binary_accuracy: 0.6795 - val_loss: 0.8497 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/31\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4837 - binary_accuracy: 0.6884 - val_loss: 1.3384 - val_binary_accuracy: 0.5179\n",
      "Epoch 7/31\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4761 - binary_accuracy: 0.6875 - val_loss: 1.0550 - val_binary_accuracy: 0.5286\n",
      "Epoch 8/31\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4711 - binary_accuracy: 0.6884 - val_loss: 1.1277 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/31\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4783 - binary_accuracy: 0.6866 - val_loss: 1.2182 - val_binary_accuracy: 0.5536\n",
      "Epoch 10/31\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4677 - binary_accuracy: 0.6893 - val_loss: 1.2239 - val_binary_accuracy: 0.5464\n",
      "Epoch 11/31\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4695 - binary_accuracy: 0.6893 - val_loss: 1.1530 - val_binary_accuracy: 0.5464\n",
      "Epoch 12/31\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4670 - binary_accuracy: 0.6946 - val_loss: 1.5125 - val_binary_accuracy: 0.5393\n",
      "Epoch 13/31\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4835 - binary_accuracy: 0.6848 - val_loss: 1.0902 - val_binary_accuracy: 0.5429\n",
      "Epoch 14/31\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4744 - binary_accuracy: 0.6893 - val_loss: 1.2913 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/31\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4723 - binary_accuracy: 0.6893 - val_loss: 1.3468 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/31\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4715 - binary_accuracy: 0.6893 - val_loss: 1.3754 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/31\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4768 - binary_accuracy: 0.6875 - val_loss: 1.1095 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/31\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4672 - binary_accuracy: 0.6893 - val_loss: 1.3001 - val_binary_accuracy: 0.5250\n",
      "Epoch 19/31\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4662 - binary_accuracy: 0.6812 - val_loss: 1.3420 - val_binary_accuracy: 0.5250\n",
      "Epoch 20/31\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4657 - binary_accuracy: 0.6893 - val_loss: 1.3713 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/31\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4627 - binary_accuracy: 0.6893 - val_loss: 1.4032 - val_binary_accuracy: 0.5357\n",
      "Epoch 22/31\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4665 - binary_accuracy: 0.6875 - val_loss: 1.1010 - val_binary_accuracy: 0.5429\n",
      "Epoch 23/31\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4763 - binary_accuracy: 0.6929 - val_loss: 0.9596 - val_binary_accuracy: 0.5179\n",
      "Epoch 24/31\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4769 - binary_accuracy: 0.6714 - val_loss: 1.2060 - val_binary_accuracy: 0.5286\n",
      "Epoch 25/31\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4744 - binary_accuracy: 0.6804 - val_loss: 1.2690 - val_binary_accuracy: 0.5321\n",
      "Epoch 26/31\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4689 - binary_accuracy: 0.6884 - val_loss: 1.6484 - val_binary_accuracy: 0.5393\n",
      "Epoch 27/31\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4642 - binary_accuracy: 0.6893 - val_loss: 1.7559 - val_binary_accuracy: 0.5357\n",
      "Epoch 28/31\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4630 - binary_accuracy: 0.6893 - val_loss: 1.7619 - val_binary_accuracy: 0.5393\n",
      "Epoch 29/31\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4604 - binary_accuracy: 0.6893 - val_loss: 1.9243 - val_binary_accuracy: 0.5464\n",
      "Epoch 30/31\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5678 - binary_accuracy: 0.6812 - val_loss: 1.1940 - val_binary_accuracy: 0.5214\n",
      "Epoch 31/31\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4681 - binary_accuracy: 0.6893 - val_loss: 1.3756 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.6478 - binary_accuracy: 0.6593\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.1823 - binary_accuracy: 0.5567\n",
      "training start... epochs = 32\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_86 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_76 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_176 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "112/112 [==============================] - 60s 401ms/step - loss: 0.6901 - binary_accuracy: 0.5188 - val_loss: 0.6908 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/32\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.6572 - binary_accuracy: 0.5902 - val_loss: 0.6825 - val_binary_accuracy: 0.5357\n",
      "Epoch 3/32\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.5749 - binary_accuracy: 0.6732 - val_loss: 0.7439 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/32\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.5236 - binary_accuracy: 0.6750 - val_loss: 0.8058 - val_binary_accuracy: 0.5464\n",
      "Epoch 5/32\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4851 - binary_accuracy: 0.6732 - val_loss: 0.8106 - val_binary_accuracy: 0.5607\n",
      "Epoch 6/32\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4747 - binary_accuracy: 0.6741 - val_loss: 1.0523 - val_binary_accuracy: 0.5679\n",
      "Epoch 7/32\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4794 - binary_accuracy: 0.6777 - val_loss: 0.9789 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/32\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4867 - binary_accuracy: 0.6848 - val_loss: 0.8764 - val_binary_accuracy: 0.5071\n",
      "Epoch 9/32\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4905 - binary_accuracy: 0.6661 - val_loss: 0.9626 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/32\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4951 - binary_accuracy: 0.6634 - val_loss: 0.9356 - val_binary_accuracy: 0.5214\n",
      "Epoch 11/32\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4985 - binary_accuracy: 0.6741 - val_loss: 0.8967 - val_binary_accuracy: 0.5286\n",
      "Epoch 12/32\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4870 - binary_accuracy: 0.6696 - val_loss: 0.9612 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/32\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4850 - binary_accuracy: 0.6786 - val_loss: 0.9840 - val_binary_accuracy: 0.5286\n",
      "Epoch 14/32\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4858 - binary_accuracy: 0.6795 - val_loss: 1.0553 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/32\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4817 - binary_accuracy: 0.6821 - val_loss: 1.1760 - val_binary_accuracy: 0.5464\n",
      "Epoch 16/32\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4794 - binary_accuracy: 0.6866 - val_loss: 1.3484 - val_binary_accuracy: 0.5321\n",
      "Epoch 17/32\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4754 - binary_accuracy: 0.6804 - val_loss: 1.5551 - val_binary_accuracy: 0.5393\n",
      "Epoch 18/32\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4753 - binary_accuracy: 0.6884 - val_loss: 1.6903 - val_binary_accuracy: 0.5429\n",
      "Epoch 19/32\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4730 - binary_accuracy: 0.6893 - val_loss: 1.7318 - val_binary_accuracy: 0.5429\n",
      "Epoch 20/32\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4718 - binary_accuracy: 0.6893 - val_loss: 1.8071 - val_binary_accuracy: 0.5357\n",
      "Epoch 21/32\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4719 - binary_accuracy: 0.6884 - val_loss: 1.8191 - val_binary_accuracy: 0.5464\n",
      "Epoch 22/32\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4727 - binary_accuracy: 0.6902 - val_loss: 2.0329 - val_binary_accuracy: 0.5500\n",
      "Epoch 23/32\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4914 - binary_accuracy: 0.6875 - val_loss: 1.1290 - val_binary_accuracy: 0.5250\n",
      "Epoch 24/32\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4740 - binary_accuracy: 0.6964 - val_loss: 1.3781 - val_binary_accuracy: 0.5214\n",
      "Epoch 25/32\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4709 - binary_accuracy: 0.6946 - val_loss: 1.4254 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/32\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4729 - binary_accuracy: 0.6821 - val_loss: 1.4229 - val_binary_accuracy: 0.5500\n",
      "Epoch 27/32\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4736 - binary_accuracy: 0.6902 - val_loss: 1.4445 - val_binary_accuracy: 0.5464\n",
      "Epoch 28/32\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4704 - binary_accuracy: 0.6902 - val_loss: 1.5043 - val_binary_accuracy: 0.5464\n",
      "Epoch 29/32\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4685 - binary_accuracy: 0.6875 - val_loss: 1.9479 - val_binary_accuracy: 0.5357\n",
      "Epoch 30/32\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.5067 - binary_accuracy: 0.6732 - val_loss: 1.1051 - val_binary_accuracy: 0.5214\n",
      "Epoch 31/32\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4843 - binary_accuracy: 0.6741 - val_loss: 1.0716 - val_binary_accuracy: 0.5214\n",
      "Epoch 32/32\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4799 - binary_accuracy: 0.6759 - val_loss: 1.0861 - val_binary_accuracy: 0.5250\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.5995 - binary_accuracy: 0.6464\n",
      "60/60 [==============================] - 6s 103ms/step - loss: 1.0581 - binary_accuracy: 0.5717\n",
      "training start... epochs = 33\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_87 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_77 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/33\n",
      "112/112 [==============================] - 59s 398ms/step - loss: 0.6909 - binary_accuracy: 0.5366 - val_loss: 0.6888 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/33\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.7604 - binary_accuracy: 0.5500 - val_loss: 0.6932 - val_binary_accuracy: 0.5143\n",
      "Epoch 3/33\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.6302 - binary_accuracy: 0.6313 - val_loss: 0.7280 - val_binary_accuracy: 0.5179\n",
      "Epoch 4/33\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.5870 - binary_accuracy: 0.6473 - val_loss: 0.7686 - val_binary_accuracy: 0.5107\n",
      "Epoch 5/33\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.5485 - binary_accuracy: 0.6696 - val_loss: 0.8450 - val_binary_accuracy: 0.5107\n",
      "Epoch 6/33\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.5104 - binary_accuracy: 0.6598 - val_loss: 0.9541 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/33\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4901 - binary_accuracy: 0.6687 - val_loss: 0.9678 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/33\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4852 - binary_accuracy: 0.6661 - val_loss: 1.0806 - val_binary_accuracy: 0.5071\n",
      "Epoch 9/33\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4775 - binary_accuracy: 0.6750 - val_loss: 1.1343 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/33\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4752 - binary_accuracy: 0.6518 - val_loss: 1.2964 - val_binary_accuracy: 0.5107\n",
      "Epoch 11/33\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4879 - binary_accuracy: 0.6723 - val_loss: 1.2961 - val_binary_accuracy: 0.5036\n",
      "Epoch 12/33\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4761 - binary_accuracy: 0.6786 - val_loss: 1.1720 - val_binary_accuracy: 0.5143\n",
      "Epoch 13/33\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4712 - binary_accuracy: 0.6687 - val_loss: 1.2337 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/33\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4754 - binary_accuracy: 0.6777 - val_loss: 1.2992 - val_binary_accuracy: 0.5036\n",
      "Epoch 15/33\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4716 - binary_accuracy: 0.6768 - val_loss: 1.2270 - val_binary_accuracy: 0.5143\n",
      "Epoch 16/33\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4711 - binary_accuracy: 0.6777 - val_loss: 1.2717 - val_binary_accuracy: 0.5179\n",
      "Epoch 17/33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4684 - binary_accuracy: 0.6777 - val_loss: 1.4214 - val_binary_accuracy: 0.5143\n",
      "Epoch 18/33\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4676 - binary_accuracy: 0.6777 - val_loss: 1.5128 - val_binary_accuracy: 0.5179\n",
      "Epoch 19/33\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4697 - binary_accuracy: 0.6741 - val_loss: 1.6000 - val_binary_accuracy: 0.5107\n",
      "Epoch 20/33\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4923 - binary_accuracy: 0.6598 - val_loss: 1.2179 - val_binary_accuracy: 0.5143\n",
      "Epoch 21/33\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4710 - binary_accuracy: 0.6768 - val_loss: 1.2059 - val_binary_accuracy: 0.5107\n",
      "Epoch 22/33\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4662 - binary_accuracy: 0.6786 - val_loss: 1.2864 - val_binary_accuracy: 0.5179\n",
      "Epoch 23/33\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4663 - binary_accuracy: 0.6848 - val_loss: 1.3300 - val_binary_accuracy: 0.4679\n",
      "Epoch 24/33\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4675 - binary_accuracy: 0.6759 - val_loss: 1.4051 - val_binary_accuracy: 0.5179\n",
      "Epoch 25/33\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4671 - binary_accuracy: 0.6821 - val_loss: 1.3639 - val_binary_accuracy: 0.5321\n",
      "Epoch 26/33\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4667 - binary_accuracy: 0.6839 - val_loss: 1.4928 - val_binary_accuracy: 0.5286\n",
      "Epoch 27/33\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4644 - binary_accuracy: 0.7000 - val_loss: 1.5080 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/33\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4602 - binary_accuracy: 0.6884 - val_loss: 1.3268 - val_binary_accuracy: 0.4929\n",
      "Epoch 29/33\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4771 - binary_accuracy: 0.6562 - val_loss: 1.3982 - val_binary_accuracy: 0.4893\n",
      "Epoch 30/33\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4638 - binary_accuracy: 0.6884 - val_loss: 1.5778 - val_binary_accuracy: 0.5179\n",
      "Epoch 31/33\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4522 - binary_accuracy: 0.7018 - val_loss: 1.5855 - val_binary_accuracy: 0.5036\n",
      "Epoch 32/33\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4528 - binary_accuracy: 0.7107 - val_loss: 1.5558 - val_binary_accuracy: 0.5143\n",
      "Epoch 33/33\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4427 - binary_accuracy: 0.7098 - val_loss: 1.6474 - val_binary_accuracy: 0.5250\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6791 - binary_accuracy: 0.6750\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.6365 - binary_accuracy: 0.5350\n",
      "training start... epochs = 34\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_88 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_78 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/34\n",
      "112/112 [==============================] - 58s 396ms/step - loss: 0.6932 - binary_accuracy: 0.5241 - val_loss: 0.6916 - val_binary_accuracy: 0.5107\n",
      "Epoch 2/34\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.6983 - binary_accuracy: 0.5598 - val_loss: 0.6869 - val_binary_accuracy: 0.5393\n",
      "Epoch 3/34\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.6105 - binary_accuracy: 0.6411 - val_loss: 0.6997 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/34\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.5589 - binary_accuracy: 0.6714 - val_loss: 0.8569 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/34\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5222 - binary_accuracy: 0.6562 - val_loss: 0.8953 - val_binary_accuracy: 0.5536\n",
      "Epoch 6/34\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4900 - binary_accuracy: 0.6607 - val_loss: 0.9541 - val_binary_accuracy: 0.5536\n",
      "Epoch 7/34\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4820 - binary_accuracy: 0.6705 - val_loss: 0.9421 - val_binary_accuracy: 0.5536\n",
      "Epoch 8/34\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4723 - binary_accuracy: 0.6857 - val_loss: 1.0427 - val_binary_accuracy: 0.5464\n",
      "Epoch 9/34\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4706 - binary_accuracy: 0.6830 - val_loss: 1.1631 - val_binary_accuracy: 0.5500\n",
      "Epoch 10/34\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4642 - binary_accuracy: 0.6839 - val_loss: 1.2885 - val_binary_accuracy: 0.5536\n",
      "Epoch 11/34\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4851 - binary_accuracy: 0.6929 - val_loss: 0.8607 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/34\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4763 - binary_accuracy: 0.6938 - val_loss: 0.9955 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/34\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4718 - binary_accuracy: 0.6920 - val_loss: 1.1964 - val_binary_accuracy: 0.5464\n",
      "Epoch 14/34\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4665 - binary_accuracy: 0.6902 - val_loss: 1.2237 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/34\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4541 - binary_accuracy: 0.6982 - val_loss: 1.3679 - val_binary_accuracy: 0.5536\n",
      "Epoch 16/34\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4599 - binary_accuracy: 0.6920 - val_loss: 1.5059 - val_binary_accuracy: 0.5536\n",
      "Epoch 17/34\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4566 - binary_accuracy: 0.6920 - val_loss: 1.4254 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/34\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4591 - binary_accuracy: 0.6946 - val_loss: 1.5280 - val_binary_accuracy: 0.5464\n",
      "Epoch 19/34\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4548 - binary_accuracy: 0.6884 - val_loss: 1.6974 - val_binary_accuracy: 0.5357\n",
      "Epoch 20/34\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4846 - binary_accuracy: 0.6884 - val_loss: 1.1287 - val_binary_accuracy: 0.5250\n",
      "Epoch 21/34\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4444 - binary_accuracy: 0.7196 - val_loss: 1.4405 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/34\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4517 - binary_accuracy: 0.7134 - val_loss: 1.2904 - val_binary_accuracy: 0.5393\n",
      "Epoch 23/34\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.7126 - binary_accuracy: 0.6384 - val_loss: 0.7725 - val_binary_accuracy: 0.5107\n",
      "Epoch 24/34\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.6143 - binary_accuracy: 0.6187 - val_loss: 0.7312 - val_binary_accuracy: 0.5250\n",
      "Epoch 25/34\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5523 - binary_accuracy: 0.6518 - val_loss: 0.7767 - val_binary_accuracy: 0.4964\n",
      "Epoch 26/34\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.5206 - binary_accuracy: 0.6670 - val_loss: 0.8984 - val_binary_accuracy: 0.5036\n",
      "Epoch 27/34\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5301 - binary_accuracy: 0.6509 - val_loss: 0.8472 - val_binary_accuracy: 0.4964\n",
      "Epoch 28/34\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.5218 - binary_accuracy: 0.6518 - val_loss: 0.8649 - val_binary_accuracy: 0.5286\n",
      "Epoch 29/34\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.5614 - binary_accuracy: 0.6250 - val_loss: 0.7685 - val_binary_accuracy: 0.4929\n",
      "Epoch 30/34\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.5193 - binary_accuracy: 0.6821 - val_loss: 0.9364 - val_binary_accuracy: 0.5036\n",
      "Epoch 31/34\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.5053 - binary_accuracy: 0.6527 - val_loss: 0.8578 - val_binary_accuracy: 0.5321\n",
      "Epoch 32/34\n",
      "112/112 [==============================] - 32s 287ms/step - loss: 0.5056 - binary_accuracy: 0.6616 - val_loss: 0.8795 - val_binary_accuracy: 0.5071\n",
      "Epoch 33/34\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4994 - binary_accuracy: 0.6339 - val_loss: 0.8575 - val_binary_accuracy: 0.5286\n",
      "Epoch 34/34\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4925 - binary_accuracy: 0.6696 - val_loss: 0.8962 - val_binary_accuracy: 0.5286\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.5715 - binary_accuracy: 0.6564\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 0.8179 - binary_accuracy: 0.5717\n",
      "training start... epochs = 35\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_89 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_79 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "112/112 [==============================] - 59s 401ms/step - loss: 0.6921 - binary_accuracy: 0.5250 - val_loss: 0.6901 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/35\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.6570 - binary_accuracy: 0.5920 - val_loss: 0.6915 - val_binary_accuracy: 0.5500\n",
      "Epoch 3/35\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.5841 - binary_accuracy: 0.6554 - val_loss: 0.7251 - val_binary_accuracy: 0.5679\n",
      "Epoch 4/35\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.5735 - binary_accuracy: 0.6714 - val_loss: 0.7792 - val_binary_accuracy: 0.5536\n",
      "Epoch 5/35\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.5065 - binary_accuracy: 0.6536 - val_loss: 0.8946 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/35\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4764 - binary_accuracy: 0.6875 - val_loss: 1.0315 - val_binary_accuracy: 0.5429\n",
      "Epoch 7/35\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4713 - binary_accuracy: 0.6839 - val_loss: 1.0974 - val_binary_accuracy: 0.5500\n",
      "Epoch 8/35\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4764 - binary_accuracy: 0.6804 - val_loss: 0.9748 - val_binary_accuracy: 0.5500\n",
      "Epoch 9/35\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4727 - binary_accuracy: 0.6893 - val_loss: 0.9499 - val_binary_accuracy: 0.5464\n",
      "Epoch 10/35\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4777 - binary_accuracy: 0.6812 - val_loss: 0.8992 - val_binary_accuracy: 0.5250\n",
      "Epoch 11/35\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4764 - binary_accuracy: 0.6875 - val_loss: 1.0850 - val_binary_accuracy: 0.5536\n",
      "Epoch 12/35\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4879 - binary_accuracy: 0.6804 - val_loss: 0.9352 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/35\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4812 - binary_accuracy: 0.6795 - val_loss: 1.0431 - val_binary_accuracy: 0.5321\n",
      "Epoch 14/35\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4742 - binary_accuracy: 0.6821 - val_loss: 1.2029 - val_binary_accuracy: 0.5464\n",
      "Epoch 15/35\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4801 - binary_accuracy: 0.6786 - val_loss: 0.9804 - val_binary_accuracy: 0.5536\n",
      "Epoch 16/35\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4737 - binary_accuracy: 0.6893 - val_loss: 1.1474 - val_binary_accuracy: 0.5464\n",
      "Epoch 17/35\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4710 - binary_accuracy: 0.6893 - val_loss: 1.1765 - val_binary_accuracy: 0.5500\n",
      "Epoch 18/35\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4692 - binary_accuracy: 0.6902 - val_loss: 1.2194 - val_binary_accuracy: 0.5607\n",
      "Epoch 19/35\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4778 - binary_accuracy: 0.6955 - val_loss: 1.0154 - val_binary_accuracy: 0.5500\n",
      "Epoch 20/35\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4717 - binary_accuracy: 0.6884 - val_loss: 1.0755 - val_binary_accuracy: 0.5464\n",
      "Epoch 21/35\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4658 - binary_accuracy: 0.6884 - val_loss: 1.1170 - val_binary_accuracy: 0.5571\n",
      "Epoch 22/35\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4640 - binary_accuracy: 0.6902 - val_loss: 1.1319 - val_binary_accuracy: 0.5500\n",
      "Epoch 23/35\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4635 - binary_accuracy: 0.6902 - val_loss: 1.1494 - val_binary_accuracy: 0.5679\n",
      "Epoch 24/35\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4651 - binary_accuracy: 0.6884 - val_loss: 1.0656 - val_binary_accuracy: 0.5536\n",
      "Epoch 25/35\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4707 - binary_accuracy: 0.6893 - val_loss: 1.1062 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/35\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4691 - binary_accuracy: 0.6893 - val_loss: 1.1524 - val_binary_accuracy: 0.5429\n",
      "Epoch 27/35\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4672 - binary_accuracy: 0.6902 - val_loss: 1.2042 - val_binary_accuracy: 0.5500\n",
      "Epoch 28/35\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4654 - binary_accuracy: 0.6902 - val_loss: 1.2063 - val_binary_accuracy: 0.5429\n",
      "Epoch 29/35\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4629 - binary_accuracy: 0.6920 - val_loss: 1.6263 - val_binary_accuracy: 0.5857\n",
      "Epoch 30/35\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.5239 - binary_accuracy: 0.6839 - val_loss: 0.9823 - val_binary_accuracy: 0.5500\n",
      "Epoch 31/35\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4658 - binary_accuracy: 0.6893 - val_loss: 1.0962 - val_binary_accuracy: 0.5536\n",
      "Epoch 32/35\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4678 - binary_accuracy: 0.6830 - val_loss: 1.2173 - val_binary_accuracy: 0.5321\n",
      "Epoch 33/35\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4671 - binary_accuracy: 0.6795 - val_loss: 1.1437 - val_binary_accuracy: 0.5464\n",
      "Epoch 34/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4672 - binary_accuracy: 0.6893 - val_loss: 1.2335 - val_binary_accuracy: 0.5464\n",
      "Epoch 35/35\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4635 - binary_accuracy: 0.6893 - val_loss: 1.2742 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.6255 - binary_accuracy: 0.6614\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.0802 - binary_accuracy: 0.5850\n",
      "training start... epochs = 36\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_90 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_80 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/36\n",
      "112/112 [==============================] - 59s 410ms/step - loss: 0.6932 - binary_accuracy: 0.5080 - val_loss: 0.6907 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/36\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.6718 - binary_accuracy: 0.5652 - val_loss: 0.6860 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/36\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.6167 - binary_accuracy: 0.6545 - val_loss: 0.7340 - val_binary_accuracy: 0.5214\n",
      "Epoch 4/36\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.5645 - binary_accuracy: 0.6464 - val_loss: 0.8199 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/36\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.5138 - binary_accuracy: 0.6777 - val_loss: 1.0243 - val_binary_accuracy: 0.5179\n",
      "Epoch 6/36\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4833 - binary_accuracy: 0.6750 - val_loss: 1.0597 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/36\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4801 - binary_accuracy: 0.6839 - val_loss: 1.1179 - val_binary_accuracy: 0.5321\n",
      "Epoch 8/36\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4707 - binary_accuracy: 0.6795 - val_loss: 1.2018 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/36\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4727 - binary_accuracy: 0.6848 - val_loss: 1.3487 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/36\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4648 - binary_accuracy: 0.6893 - val_loss: 1.3820 - val_binary_accuracy: 0.5250\n",
      "Epoch 11/36\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4650 - binary_accuracy: 0.6884 - val_loss: 1.2817 - val_binary_accuracy: 0.5214\n",
      "Epoch 12/36\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4717 - binary_accuracy: 0.6857 - val_loss: 1.5157 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4698 - binary_accuracy: 0.6875 - val_loss: 1.3904 - val_binary_accuracy: 0.5214\n",
      "Epoch 14/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4817 - binary_accuracy: 0.6750 - val_loss: 1.1213 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4798 - binary_accuracy: 0.6866 - val_loss: 1.2245 - val_binary_accuracy: 0.5214\n",
      "Epoch 16/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4739 - binary_accuracy: 0.6893 - val_loss: 1.2915 - val_binary_accuracy: 0.5250\n",
      "Epoch 17/36\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4736 - binary_accuracy: 0.6893 - val_loss: 1.3300 - val_binary_accuracy: 0.5286\n",
      "Epoch 18/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4746 - binary_accuracy: 0.6893 - val_loss: 1.3421 - val_binary_accuracy: 0.5250\n",
      "Epoch 19/36\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4732 - binary_accuracy: 0.6893 - val_loss: 1.3639 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/36\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4729 - binary_accuracy: 0.6893 - val_loss: 1.3749 - val_binary_accuracy: 0.5357\n",
      "Epoch 21/36\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4713 - binary_accuracy: 0.6893 - val_loss: 1.4037 - val_binary_accuracy: 0.5393\n",
      "Epoch 22/36\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4728 - binary_accuracy: 0.6893 - val_loss: 1.4263 - val_binary_accuracy: 0.5321\n",
      "Epoch 23/36\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4714 - binary_accuracy: 0.6893 - val_loss: 1.4096 - val_binary_accuracy: 0.5464\n",
      "Epoch 24/36\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4696 - binary_accuracy: 0.6893 - val_loss: 1.4581 - val_binary_accuracy: 0.5464\n",
      "Epoch 25/36\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4678 - binary_accuracy: 0.6893 - val_loss: 1.5144 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/36\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4689 - binary_accuracy: 0.6866 - val_loss: 1.6171 - val_binary_accuracy: 0.5536\n",
      "Epoch 27/36\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4653 - binary_accuracy: 0.6893 - val_loss: 1.7236 - val_binary_accuracy: 0.5536\n",
      "Epoch 28/36\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4638 - binary_accuracy: 0.6893 - val_loss: 1.7105 - val_binary_accuracy: 0.5607\n",
      "Epoch 29/36\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4621 - binary_accuracy: 0.6911 - val_loss: 1.6709 - val_binary_accuracy: 0.5679\n",
      "Epoch 30/36\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.5071 - binary_accuracy: 0.6821 - val_loss: 1.0915 - val_binary_accuracy: 0.5321\n",
      "Epoch 31/36\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4828 - binary_accuracy: 0.6768 - val_loss: 1.2613 - val_binary_accuracy: 0.5321\n",
      "Epoch 32/36\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4748 - binary_accuracy: 0.6777 - val_loss: 1.2959 - val_binary_accuracy: 0.5286\n",
      "Epoch 33/36\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4738 - binary_accuracy: 0.6777 - val_loss: 1.3485 - val_binary_accuracy: 0.5286\n",
      "Epoch 34/36\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4732 - binary_accuracy: 0.6777 - val_loss: 1.4034 - val_binary_accuracy: 0.5286\n",
      "Epoch 35/36\n",
      "112/112 [==============================] - 33s 290ms/step - loss: 0.4725 - binary_accuracy: 0.6777 - val_loss: 1.4167 - val_binary_accuracy: 0.5286\n",
      "Epoch 36/36\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4727 - binary_accuracy: 0.6786 - val_loss: 1.4479 - val_binary_accuracy: 0.5286\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6671 - binary_accuracy: 0.6500\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.2793 - binary_accuracy: 0.5717\n",
      "training start... epochs = 37\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_91 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_81 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_180 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/37\n",
      "112/112 [==============================] - 60s 408ms/step - loss: 0.6918 - binary_accuracy: 0.5312 - val_loss: 0.6892 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/37\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.6683 - binary_accuracy: 0.5830 - val_loss: 0.6930 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/37\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.6027 - binary_accuracy: 0.6571 - val_loss: 0.7026 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/37\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.5583 - binary_accuracy: 0.6670 - val_loss: 0.7805 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/37\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.5109 - binary_accuracy: 0.6768 - val_loss: 0.8210 - val_binary_accuracy: 0.5464\n",
      "Epoch 6/37\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4797 - binary_accuracy: 0.6634 - val_loss: 0.9623 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/37\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4716 - binary_accuracy: 0.6830 - val_loss: 0.9647 - val_binary_accuracy: 0.5321\n",
      "Epoch 8/37\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4681 - binary_accuracy: 0.6893 - val_loss: 1.1147 - val_binary_accuracy: 0.5464\n",
      "Epoch 9/37\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4728 - binary_accuracy: 0.6982 - val_loss: 1.0310 - val_binary_accuracy: 0.5393\n",
      "Epoch 10/37\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4913 - binary_accuracy: 0.6839 - val_loss: 0.8220 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/37\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4803 - binary_accuracy: 0.6821 - val_loss: 1.1029 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/37\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4746 - binary_accuracy: 0.6893 - val_loss: 1.1328 - val_binary_accuracy: 0.5500\n",
      "Epoch 13/37\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4693 - binary_accuracy: 0.6893 - val_loss: 1.1610 - val_binary_accuracy: 0.5571\n",
      "Epoch 14/37\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4674 - binary_accuracy: 0.6893 - val_loss: 1.2367 - val_binary_accuracy: 0.5500\n",
      "Epoch 15/37\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4839 - binary_accuracy: 0.6732 - val_loss: 1.0302 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/37\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4829 - binary_accuracy: 0.6804 - val_loss: 1.0535 - val_binary_accuracy: 0.5429\n",
      "Epoch 17/37\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4756 - binary_accuracy: 0.6893 - val_loss: 1.1202 - val_binary_accuracy: 0.5500\n",
      "Epoch 18/37\n",
      "112/112 [==============================] - 33s 291ms/step - loss: 0.4728 - binary_accuracy: 0.6893 - val_loss: 1.1512 - val_binary_accuracy: 0.5536\n",
      "Epoch 19/37\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4731 - binary_accuracy: 0.6893 - val_loss: 1.1578 - val_binary_accuracy: 0.5536\n",
      "Epoch 20/37\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4724 - binary_accuracy: 0.6893 - val_loss: 1.1725 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/37\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4705 - binary_accuracy: 0.6893 - val_loss: 1.1726 - val_binary_accuracy: 0.5500\n",
      "Epoch 22/37\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4700 - binary_accuracy: 0.6893 - val_loss: 1.1698 - val_binary_accuracy: 0.5536\n",
      "Epoch 23/37\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4644 - binary_accuracy: 0.6893 - val_loss: 1.4871 - val_binary_accuracy: 0.5357\n",
      "Epoch 24/37\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.5640 - binary_accuracy: 0.6696 - val_loss: 0.9316 - val_binary_accuracy: 0.5321\n",
      "Epoch 25/37\n",
      "112/112 [==============================] - 32s 288ms/step - loss: 0.4773 - binary_accuracy: 0.6786 - val_loss: 0.9773 - val_binary_accuracy: 0.5464\n",
      "Epoch 26/37\n",
      "112/112 [==============================] - 32s 289ms/step - loss: 0.4835 - binary_accuracy: 0.6696 - val_loss: 0.8955 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/37\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4831 - binary_accuracy: 0.6812 - val_loss: 0.9692 - val_binary_accuracy: 0.5393\n",
      "Epoch 28/37\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4794 - binary_accuracy: 0.6812 - val_loss: 1.0401 - val_binary_accuracy: 0.5500\n",
      "Epoch 29/37\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4764 - binary_accuracy: 0.6857 - val_loss: 1.1320 - val_binary_accuracy: 0.5143\n",
      "Epoch 30/37\n",
      "112/112 [==============================] - 32s 285ms/step - loss: 0.4735 - binary_accuracy: 0.6777 - val_loss: 1.1959 - val_binary_accuracy: 0.5357\n",
      "Epoch 31/37\n",
      "112/112 [==============================] - 33s 292ms/step - loss: 0.4739 - binary_accuracy: 0.6893 - val_loss: 1.2486 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/37\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4775 - binary_accuracy: 0.6857 - val_loss: 1.1089 - val_binary_accuracy: 0.5464\n",
      "Epoch 33/37\n",
      "112/112 [==============================] - 33s 300ms/step - loss: 0.4735 - binary_accuracy: 0.6893 - val_loss: 1.1547 - val_binary_accuracy: 0.5393\n",
      "Epoch 34/37\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4724 - binary_accuracy: 0.6893 - val_loss: 1.1856 - val_binary_accuracy: 0.5500\n",
      "Epoch 35/37\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4721 - binary_accuracy: 0.6893 - val_loss: 1.2068 - val_binary_accuracy: 0.5464\n",
      "Epoch 36/37\n",
      "112/112 [==============================] - 33s 293ms/step - loss: 0.4710 - binary_accuracy: 0.6884 - val_loss: 1.2357 - val_binary_accuracy: 0.5464\n",
      "Epoch 37/37\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4701 - binary_accuracy: 0.6893 - val_loss: 1.2550 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.6266 - binary_accuracy: 0.6614\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.1216 - binary_accuracy: 0.5717\n",
      "training start... epochs = 38\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_92 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_82 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_188 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/38\n",
      "112/112 [==============================] - 58s 409ms/step - loss: 0.6921 - binary_accuracy: 0.5259 - val_loss: 0.6897 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/38\n",
      "112/112 [==============================] - 39s 349ms/step - loss: 0.6583 - binary_accuracy: 0.5804 - val_loss: 0.6982 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/38\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.5975 - binary_accuracy: 0.6580 - val_loss: 0.7442 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/38\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.5634 - binary_accuracy: 0.6732 - val_loss: 0.8527 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/38\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.5227 - binary_accuracy: 0.6661 - val_loss: 1.0320 - val_binary_accuracy: 0.5214\n",
      "Epoch 6/38\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.5036 - binary_accuracy: 0.6607 - val_loss: 0.9249 - val_binary_accuracy: 0.5250\n",
      "Epoch 7/38\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.5538 - binary_accuracy: 0.6723 - val_loss: 0.9189 - val_binary_accuracy: 0.5214\n",
      "Epoch 8/38\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4809 - binary_accuracy: 0.6866 - val_loss: 1.0012 - val_binary_accuracy: 0.5321\n",
      "Epoch 9/38\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4712 - binary_accuracy: 0.6884 - val_loss: 1.1548 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/38\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4653 - binary_accuracy: 0.6786 - val_loss: 1.4733 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/38\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4900 - binary_accuracy: 0.6821 - val_loss: 0.9760 - val_binary_accuracy: 0.5464\n",
      "Epoch 12/38\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4764 - binary_accuracy: 0.6893 - val_loss: 1.0426 - val_binary_accuracy: 0.5464\n",
      "Epoch 13/38\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4744 - binary_accuracy: 0.6893 - val_loss: 1.0961 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/38\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4742 - binary_accuracy: 0.6893 - val_loss: 1.1324 - val_binary_accuracy: 0.5429\n",
      "Epoch 15/38\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4718 - binary_accuracy: 0.6893 - val_loss: 1.1541 - val_binary_accuracy: 0.5429\n",
      "Epoch 16/38\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4709 - binary_accuracy: 0.6893 - val_loss: 1.2244 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/38\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4749 - binary_accuracy: 0.6866 - val_loss: 1.3775 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/38\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.5070 - binary_accuracy: 0.6768 - val_loss: 1.1229 - val_binary_accuracy: 0.5393\n",
      "Epoch 19/38\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4782 - binary_accuracy: 0.6839 - val_loss: 1.0122 - val_binary_accuracy: 0.5357\n",
      "Epoch 20/38\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4999 - binary_accuracy: 0.6598 - val_loss: 0.9362 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/38\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4764 - binary_accuracy: 0.6732 - val_loss: 0.9459 - val_binary_accuracy: 0.5179\n",
      "Epoch 22/38\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4781 - binary_accuracy: 0.6759 - val_loss: 0.9852 - val_binary_accuracy: 0.5429\n",
      "Epoch 23/38\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4703 - binary_accuracy: 0.6795 - val_loss: 1.2050 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/38\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4975 - binary_accuracy: 0.6821 - val_loss: 0.9906 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/38\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4728 - binary_accuracy: 0.6804 - val_loss: 1.0217 - val_binary_accuracy: 0.5357\n",
      "Epoch 26/38\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4717 - binary_accuracy: 0.6768 - val_loss: 1.0472 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/38\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4718 - binary_accuracy: 0.6812 - val_loss: 1.1311 - val_binary_accuracy: 0.5357\n",
      "Epoch 28/38\n",
      "112/112 [==============================] - 34s 298ms/step - loss: 0.4955 - binary_accuracy: 0.6696 - val_loss: 0.9750 - val_binary_accuracy: 0.5357\n",
      "Epoch 29/38\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4788 - binary_accuracy: 0.6687 - val_loss: 1.0335 - val_binary_accuracy: 0.5321\n",
      "Epoch 30/38\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4732 - binary_accuracy: 0.6839 - val_loss: 1.0924 - val_binary_accuracy: 0.5393\n",
      "Epoch 31/38\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4686 - binary_accuracy: 0.6875 - val_loss: 1.1684 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/38\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4625 - binary_accuracy: 0.6893 - val_loss: 1.3006 - val_binary_accuracy: 0.5429\n",
      "Epoch 33/38\n",
      "112/112 [==============================] - 33s 296ms/step - loss: 0.4687 - binary_accuracy: 0.6964 - val_loss: 1.2684 - val_binary_accuracy: 0.5464\n",
      "Epoch 34/38\n",
      "112/112 [==============================] - 33s 294ms/step - loss: 0.4674 - binary_accuracy: 0.6786 - val_loss: 1.3322 - val_binary_accuracy: 0.5464\n",
      "Epoch 35/38\n",
      "112/112 [==============================] - 32s 290ms/step - loss: 0.4666 - binary_accuracy: 0.6991 - val_loss: 1.4610 - val_binary_accuracy: 0.5036\n",
      "Epoch 36/38\n",
      "112/112 [==============================] - 33s 297ms/step - loss: 0.4687 - binary_accuracy: 0.6812 - val_loss: 1.6216 - val_binary_accuracy: 0.5321\n",
      "Epoch 37/38\n",
      "112/112 [==============================] - 33s 295ms/step - loss: 0.4627 - binary_accuracy: 0.6911 - val_loss: 1.7576 - val_binary_accuracy: 0.5357\n",
      "Epoch 38/38\n",
      "112/112 [==============================] - 32s 291ms/step - loss: 0.5823 - binary_accuracy: 0.7071 - val_loss: 1.1244 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6012 - binary_accuracy: 0.6600\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.0397 - binary_accuracy: 0.5550\n",
      "training start... epochs = 39\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_93 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_83 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/39\n",
      "112/112 [==============================] - 61s 403ms/step - loss: 0.6916 - binary_accuracy: 0.5295 - val_loss: 0.6894 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/39\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.6733 - binary_accuracy: 0.5759 - val_loss: 0.6864 - val_binary_accuracy: 0.5393\n",
      "Epoch 3/39\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.5962 - binary_accuracy: 0.6589 - val_loss: 0.8259 - val_binary_accuracy: 0.5107\n",
      "Epoch 4/39\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.5511 - binary_accuracy: 0.6759 - val_loss: 0.8907 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4950 - binary_accuracy: 0.6795 - val_loss: 0.8857 - val_binary_accuracy: 0.5393\n",
      "Epoch 6/39\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4755 - binary_accuracy: 0.6875 - val_loss: 0.9780 - val_binary_accuracy: 0.5464\n",
      "Epoch 7/39\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4761 - binary_accuracy: 0.6839 - val_loss: 1.2020 - val_binary_accuracy: 0.5571\n",
      "Epoch 8/39\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4720 - binary_accuracy: 0.6884 - val_loss: 1.1624 - val_binary_accuracy: 0.5571\n",
      "Epoch 9/39\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4720 - binary_accuracy: 0.6902 - val_loss: 1.0578 - val_binary_accuracy: 0.5429\n",
      "Epoch 10/39\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4663 - binary_accuracy: 0.6911 - val_loss: 1.2778 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/39\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4681 - binary_accuracy: 0.6830 - val_loss: 1.1962 - val_binary_accuracy: 0.5429\n",
      "Epoch 12/39\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4670 - binary_accuracy: 0.6759 - val_loss: 1.3144 - val_binary_accuracy: 0.5607\n",
      "Epoch 13/39\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4860 - binary_accuracy: 0.6732 - val_loss: 1.2764 - val_binary_accuracy: 0.5429\n",
      "Epoch 14/39\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4730 - binary_accuracy: 0.6768 - val_loss: 1.2658 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/39\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4665 - binary_accuracy: 0.6893 - val_loss: 1.3073 - val_binary_accuracy: 0.5464\n",
      "Epoch 16/39\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4870 - binary_accuracy: 0.6830 - val_loss: 1.4193 - val_binary_accuracy: 0.5321\n",
      "Epoch 17/39\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4703 - binary_accuracy: 0.6884 - val_loss: 1.2795 - val_binary_accuracy: 0.5357\n",
      "Epoch 18/39\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4858 - binary_accuracy: 0.6723 - val_loss: 0.8742 - val_binary_accuracy: 0.5214\n",
      "Epoch 19/39\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4947 - binary_accuracy: 0.6696 - val_loss: 0.9415 - val_binary_accuracy: 0.5143\n",
      "Epoch 20/39\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4732 - binary_accuracy: 0.6759 - val_loss: 1.0717 - val_binary_accuracy: 0.5214\n",
      "Epoch 21/39\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.5226 - binary_accuracy: 0.6723 - val_loss: 0.9376 - val_binary_accuracy: 0.5036\n",
      "Epoch 22/39\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4785 - binary_accuracy: 0.6768 - val_loss: 0.9815 - val_binary_accuracy: 0.5036\n",
      "Epoch 23/39\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4749 - binary_accuracy: 0.6768 - val_loss: 1.0324 - val_binary_accuracy: 0.5036\n",
      "Epoch 24/39\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4697 - binary_accuracy: 0.6777 - val_loss: 1.1036 - val_binary_accuracy: 0.5071\n",
      "Epoch 25/39\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4726 - binary_accuracy: 0.6625 - val_loss: 1.0840 - val_binary_accuracy: 0.5179\n",
      "Epoch 26/39\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4733 - binary_accuracy: 0.6750 - val_loss: 1.0909 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/39\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4706 - binary_accuracy: 0.6518 - val_loss: 1.4830 - val_binary_accuracy: 0.5429\n",
      "Epoch 28/39\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4753 - binary_accuracy: 0.6804 - val_loss: 1.0387 - val_binary_accuracy: 0.5286\n",
      "Epoch 29/39\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4703 - binary_accuracy: 0.6759 - val_loss: 1.1331 - val_binary_accuracy: 0.5321\n",
      "Epoch 30/39\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4776 - binary_accuracy: 0.6643 - val_loss: 1.0434 - val_binary_accuracy: 0.5321\n",
      "Epoch 31/39\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4779 - binary_accuracy: 0.6786 - val_loss: 1.1067 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/39\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4720 - binary_accuracy: 0.6723 - val_loss: 1.1508 - val_binary_accuracy: 0.5321\n",
      "Epoch 33/39\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4659 - binary_accuracy: 0.6866 - val_loss: 1.1460 - val_binary_accuracy: 0.5071\n",
      "Epoch 34/39\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4823 - binary_accuracy: 0.6643 - val_loss: 1.1384 - val_binary_accuracy: 0.5321\n",
      "Epoch 35/39\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4784 - binary_accuracy: 0.6652 - val_loss: 1.1827 - val_binary_accuracy: 0.5393\n",
      "Epoch 36/39\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4738 - binary_accuracy: 0.6759 - val_loss: 1.2365 - val_binary_accuracy: 0.5393\n",
      "Epoch 37/39\n",
      "112/112 [==============================] - 34s 299ms/step - loss: 0.4726 - binary_accuracy: 0.6875 - val_loss: 1.3098 - val_binary_accuracy: 0.5357\n",
      "Epoch 38/39\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4686 - binary_accuracy: 0.6857 - val_loss: 1.5565 - val_binary_accuracy: 0.5464\n",
      "Epoch 39/39\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4665 - binary_accuracy: 0.6884 - val_loss: 1.6302 - val_binary_accuracy: 0.5429\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.6967 - binary_accuracy: 0.6600\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.5019 - binary_accuracy: 0.5800\n",
      "training start... epochs = 40\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_94 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_84 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_192 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "112/112 [==============================] - 63s 441ms/step - loss: 0.6922 - binary_accuracy: 0.5286 - val_loss: 0.6904 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/40\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.7060 - binary_accuracy: 0.5661 - val_loss: 0.6951 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/40\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.6236 - binary_accuracy: 0.6482 - val_loss: 0.7119 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/40\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.5386 - binary_accuracy: 0.6687 - val_loss: 0.7440 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/40\n",
      "112/112 [==============================] - 38s 344ms/step - loss: 0.5048 - binary_accuracy: 0.6607 - val_loss: 0.8566 - val_binary_accuracy: 0.5357\n",
      "Epoch 6/40\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.4741 - binary_accuracy: 0.6821 - val_loss: 0.9007 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/40\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4679 - binary_accuracy: 0.6812 - val_loss: 0.9380 - val_binary_accuracy: 0.5464\n",
      "Epoch 8/40\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4741 - binary_accuracy: 0.6866 - val_loss: 0.8952 - val_binary_accuracy: 0.5571\n",
      "Epoch 9/40\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.4997 - binary_accuracy: 0.6938 - val_loss: 0.8567 - val_binary_accuracy: 0.5357\n",
      "Epoch 10/40\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4728 - binary_accuracy: 0.6884 - val_loss: 0.9281 - val_binary_accuracy: 0.5321\n",
      "Epoch 11/40\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4634 - binary_accuracy: 0.6893 - val_loss: 1.0883 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/40\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4602 - binary_accuracy: 0.6857 - val_loss: 1.0427 - val_binary_accuracy: 0.5429\n",
      "Epoch 13/40\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4637 - binary_accuracy: 0.6893 - val_loss: 1.1351 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/40\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.5342 - binary_accuracy: 0.6679 - val_loss: 0.8091 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/40\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4846 - binary_accuracy: 0.6768 - val_loss: 0.8780 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/40\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4797 - binary_accuracy: 0.6777 - val_loss: 0.9160 - val_binary_accuracy: 0.5500\n",
      "Epoch 17/40\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4784 - binary_accuracy: 0.6786 - val_loss: 0.9356 - val_binary_accuracy: 0.5500\n",
      "Epoch 18/40\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4751 - binary_accuracy: 0.6795 - val_loss: 0.9818 - val_binary_accuracy: 0.5464\n",
      "Epoch 19/40\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4707 - binary_accuracy: 0.6795 - val_loss: 1.0410 - val_binary_accuracy: 0.5536\n",
      "Epoch 20/40\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4837 - binary_accuracy: 0.6768 - val_loss: 0.8915 - val_binary_accuracy: 0.5286\n",
      "Epoch 21/40\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4731 - binary_accuracy: 0.6562 - val_loss: 0.9256 - val_binary_accuracy: 0.5607\n",
      "Epoch 22/40\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4673 - binary_accuracy: 0.6812 - val_loss: 1.0189 - val_binary_accuracy: 0.5643\n",
      "Epoch 23/40\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4739 - binary_accuracy: 0.6786 - val_loss: 0.9051 - val_binary_accuracy: 0.5679\n",
      "Epoch 24/40\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4684 - binary_accuracy: 0.6750 - val_loss: 1.1424 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/40\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4693 - binary_accuracy: 0.6732 - val_loss: 1.1585 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/40\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4681 - binary_accuracy: 0.6795 - val_loss: 1.0160 - val_binary_accuracy: 0.5607\n",
      "Epoch 27/40\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4583 - binary_accuracy: 0.6946 - val_loss: 1.0518 - val_binary_accuracy: 0.5643\n",
      "Epoch 28/40\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4565 - binary_accuracy: 0.6732 - val_loss: 1.1367 - val_binary_accuracy: 0.5571\n",
      "Epoch 29/40\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4635 - binary_accuracy: 0.6714 - val_loss: 1.0526 - val_binary_accuracy: 0.5500\n",
      "Epoch 30/40\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4728 - binary_accuracy: 0.6893 - val_loss: 1.0627 - val_binary_accuracy: 0.5536\n",
      "Epoch 31/40\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4675 - binary_accuracy: 0.6884 - val_loss: 1.0976 - val_binary_accuracy: 0.5536\n",
      "Epoch 32/40\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4662 - binary_accuracy: 0.6884 - val_loss: 1.1371 - val_binary_accuracy: 0.5571\n",
      "Epoch 33/40\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4649 - binary_accuracy: 0.6946 - val_loss: 1.2055 - val_binary_accuracy: 0.5464\n",
      "Epoch 34/40\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4898 - binary_accuracy: 0.6670 - val_loss: 1.1063 - val_binary_accuracy: 0.5500\n",
      "Epoch 35/40\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4691 - binary_accuracy: 0.6893 - val_loss: 1.1598 - val_binary_accuracy: 0.5571\n",
      "Epoch 36/40\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4652 - binary_accuracy: 0.6893 - val_loss: 1.1814 - val_binary_accuracy: 0.5607\n",
      "Epoch 37/40\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4638 - binary_accuracy: 0.6893 - val_loss: 1.2068 - val_binary_accuracy: 0.5571\n",
      "Epoch 38/40\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4646 - binary_accuracy: 0.6902 - val_loss: 1.2160 - val_binary_accuracy: 0.5571\n",
      "Epoch 39/40\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4627 - binary_accuracy: 0.6893 - val_loss: 1.2339 - val_binary_accuracy: 0.5607\n",
      "Epoch 40/40\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4574 - binary_accuracy: 0.6893 - val_loss: 1.2644 - val_binary_accuracy: 0.5679\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.6169 - binary_accuracy: 0.6650\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 1.2882 - binary_accuracy: 0.5683\n",
      "training start... epochs = 41\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_95 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/41\n",
      "112/112 [==============================] - 62s 422ms/step - loss: 0.6912 - binary_accuracy: 0.5384 - val_loss: 0.6900 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/41\n",
      "112/112 [==============================] - 39s 347ms/step - loss: 0.6829 - binary_accuracy: 0.5598 - val_loss: 0.6893 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/41\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.6095 - binary_accuracy: 0.6402 - val_loss: 0.7590 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/41\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.5570 - binary_accuracy: 0.6687 - val_loss: 0.7944 - val_binary_accuracy: 0.5357\n",
      "Epoch 5/41\n",
      "112/112 [==============================] - 37s 335ms/step - loss: 0.5016 - binary_accuracy: 0.6643 - val_loss: 0.8304 - val_binary_accuracy: 0.5393\n",
      "Epoch 6/41\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.4865 - binary_accuracy: 0.6866 - val_loss: 0.9645 - val_binary_accuracy: 0.5464\n",
      "Epoch 7/41\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4872 - binary_accuracy: 0.6812 - val_loss: 0.9821 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/41\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4769 - binary_accuracy: 0.6812 - val_loss: 1.0933 - val_binary_accuracy: 0.5393\n",
      "Epoch 9/41\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4748 - binary_accuracy: 0.6875 - val_loss: 1.1353 - val_binary_accuracy: 0.5393\n",
      "Epoch 10/41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 37s 333ms/step - loss: 0.4719 - binary_accuracy: 0.6893 - val_loss: 1.2051 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/41\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4668 - binary_accuracy: 0.6848 - val_loss: 1.4136 - val_binary_accuracy: 0.5429\n",
      "Epoch 12/41\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4657 - binary_accuracy: 0.6839 - val_loss: 1.6083 - val_binary_accuracy: 0.5571\n",
      "Epoch 13/41\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4688 - binary_accuracy: 0.6795 - val_loss: 1.3657 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/41\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4598 - binary_accuracy: 0.6893 - val_loss: 1.2924 - val_binary_accuracy: 0.5321\n",
      "Epoch 15/41\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4597 - binary_accuracy: 0.6893 - val_loss: 1.3203 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/41\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4590 - binary_accuracy: 0.6893 - val_loss: 1.4226 - val_binary_accuracy: 0.5571\n",
      "Epoch 17/41\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4574 - binary_accuracy: 0.6848 - val_loss: 1.5250 - val_binary_accuracy: 0.5536\n",
      "Epoch 18/41\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4656 - binary_accuracy: 0.6705 - val_loss: 1.3497 - val_binary_accuracy: 0.5464\n",
      "Epoch 19/41\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4548 - binary_accuracy: 0.6893 - val_loss: 1.4033 - val_binary_accuracy: 0.5464\n",
      "Epoch 20/41\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4513 - binary_accuracy: 0.6732 - val_loss: 1.4646 - val_binary_accuracy: 0.5393\n",
      "Epoch 21/41\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4579 - binary_accuracy: 0.6938 - val_loss: 1.5526 - val_binary_accuracy: 0.5393\n",
      "Epoch 22/41\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4556 - binary_accuracy: 0.6723 - val_loss: 1.6511 - val_binary_accuracy: 0.5393\n",
      "Epoch 23/41\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4492 - binary_accuracy: 0.6884 - val_loss: 1.5112 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/41\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4479 - binary_accuracy: 0.6893 - val_loss: 1.6739 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/41\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4458 - binary_accuracy: 0.6893 - val_loss: 1.7163 - val_binary_accuracy: 0.5393\n",
      "Epoch 26/41\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4529 - binary_accuracy: 0.6875 - val_loss: 1.6191 - val_binary_accuracy: 0.5357\n",
      "Epoch 27/41\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4556 - binary_accuracy: 0.6866 - val_loss: 1.5015 - val_binary_accuracy: 0.5429\n",
      "Epoch 28/41\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4472 - binary_accuracy: 0.6848 - val_loss: 1.6437 - val_binary_accuracy: 0.5286\n",
      "Epoch 29/41\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4452 - binary_accuracy: 0.6893 - val_loss: 1.8118 - val_binary_accuracy: 0.5214\n",
      "Epoch 30/41\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4445 - binary_accuracy: 0.6875 - val_loss: 1.9497 - val_binary_accuracy: 0.5357\n",
      "Epoch 31/41\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4554 - binary_accuracy: 0.6875 - val_loss: 1.4799 - val_binary_accuracy: 0.5214\n",
      "Epoch 32/41\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4451 - binary_accuracy: 0.6830 - val_loss: 1.5718 - val_binary_accuracy: 0.5286\n",
      "Epoch 33/41\n",
      "112/112 [==============================] - 33s 298ms/step - loss: 0.4666 - binary_accuracy: 0.6964 - val_loss: 1.3073 - val_binary_accuracy: 0.5357\n",
      "Epoch 34/41\n",
      "112/112 [==============================] - 33s 299ms/step - loss: 0.4634 - binary_accuracy: 0.6777 - val_loss: 1.5719 - val_binary_accuracy: 0.5393\n",
      "Epoch 35/41\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4490 - binary_accuracy: 0.6929 - val_loss: 1.6837 - val_binary_accuracy: 0.5143\n",
      "Epoch 36/41\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4463 - binary_accuracy: 0.6759 - val_loss: 1.6628 - val_binary_accuracy: 0.5250\n",
      "Epoch 37/41\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4457 - binary_accuracy: 0.6768 - val_loss: 1.6862 - val_binary_accuracy: 0.5250\n",
      "Epoch 38/41\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4465 - binary_accuracy: 0.6875 - val_loss: 1.7178 - val_binary_accuracy: 0.5143\n",
      "Epoch 39/41\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4483 - binary_accuracy: 0.6911 - val_loss: 1.7284 - val_binary_accuracy: 0.5179\n",
      "Epoch 40/41\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4486 - binary_accuracy: 0.6893 - val_loss: 1.8655 - val_binary_accuracy: 0.5250\n",
      "Epoch 41/41\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4489 - binary_accuracy: 0.6893 - val_loss: 1.5958 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.6860 - binary_accuracy: 0.6586\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 1.3307 - binary_accuracy: 0.5483\n",
      "training start... epochs = 42\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_96 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_86 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_196 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/42\n",
      "112/112 [==============================] - 61s 421ms/step - loss: 0.6911 - binary_accuracy: 0.5241 - val_loss: 0.6890 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/42\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.6625 - binary_accuracy: 0.5777 - val_loss: 0.6989 - val_binary_accuracy: 0.5286\n",
      "Epoch 3/42\n",
      "112/112 [==============================] - 39s 345ms/step - loss: 0.5916 - binary_accuracy: 0.6634 - val_loss: 0.7357 - val_binary_accuracy: 0.5321\n",
      "Epoch 4/42\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.5338 - binary_accuracy: 0.6732 - val_loss: 0.7622 - val_binary_accuracy: 0.5179\n",
      "Epoch 5/42\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.4888 - binary_accuracy: 0.6786 - val_loss: 1.0287 - val_binary_accuracy: 0.5214\n",
      "Epoch 6/42\n",
      "112/112 [==============================] - 36s 326ms/step - loss: 0.4884 - binary_accuracy: 0.6759 - val_loss: 0.8256 - val_binary_accuracy: 0.5107\n",
      "Epoch 7/42\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4722 - binary_accuracy: 0.6821 - val_loss: 1.1683 - val_binary_accuracy: 0.5393\n",
      "Epoch 8/42\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4819 - binary_accuracy: 0.6759 - val_loss: 0.9770 - val_binary_accuracy: 0.5357\n",
      "Epoch 9/42\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4739 - binary_accuracy: 0.6884 - val_loss: 1.2118 - val_binary_accuracy: 0.5464\n",
      "Epoch 10/42\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4647 - binary_accuracy: 0.6893 - val_loss: 1.1972 - val_binary_accuracy: 0.5429\n",
      "Epoch 11/42\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4587 - binary_accuracy: 0.6893 - val_loss: 1.5593 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/42\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5152 - binary_accuracy: 0.6696 - val_loss: 0.8046 - val_binary_accuracy: 0.5250\n",
      "Epoch 13/42\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4960 - binary_accuracy: 0.6723 - val_loss: 0.8600 - val_binary_accuracy: 0.5250\n",
      "Epoch 14/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4850 - binary_accuracy: 0.6777 - val_loss: 0.9085 - val_binary_accuracy: 0.5250\n",
      "Epoch 15/42\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4815 - binary_accuracy: 0.6812 - val_loss: 0.9577 - val_binary_accuracy: 0.5357\n",
      "Epoch 16/42\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4794 - binary_accuracy: 0.6714 - val_loss: 0.9991 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/42\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4786 - binary_accuracy: 0.6759 - val_loss: 1.0542 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/42\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4749 - binary_accuracy: 0.6821 - val_loss: 1.1143 - val_binary_accuracy: 0.5107\n",
      "Epoch 19/42\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4726 - binary_accuracy: 0.6893 - val_loss: 1.1658 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/42\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4700 - binary_accuracy: 0.6893 - val_loss: 1.2111 - val_binary_accuracy: 0.5393\n",
      "Epoch 21/42\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4684 - binary_accuracy: 0.6857 - val_loss: 1.3062 - val_binary_accuracy: 0.5286\n",
      "Epoch 22/42\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4647 - binary_accuracy: 0.6866 - val_loss: 1.3953 - val_binary_accuracy: 0.5250\n",
      "Epoch 23/42\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4626 - binary_accuracy: 0.6893 - val_loss: 1.4727 - val_binary_accuracy: 0.5357\n",
      "Epoch 24/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4598 - binary_accuracy: 0.6893 - val_loss: 1.6305 - val_binary_accuracy: 0.5321\n",
      "Epoch 25/42\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4588 - binary_accuracy: 0.6973 - val_loss: 1.6534 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/42\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4601 - binary_accuracy: 0.6893 - val_loss: 1.5683 - val_binary_accuracy: 0.5286\n",
      "Epoch 27/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4598 - binary_accuracy: 0.6893 - val_loss: 1.7491 - val_binary_accuracy: 0.5250\n",
      "Epoch 28/42\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4585 - binary_accuracy: 0.6875 - val_loss: 1.7038 - val_binary_accuracy: 0.5250\n",
      "Epoch 29/42\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4571 - binary_accuracy: 0.6884 - val_loss: 1.8036 - val_binary_accuracy: 0.5107\n",
      "Epoch 30/42\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4577 - binary_accuracy: 0.6893 - val_loss: 1.8590 - val_binary_accuracy: 0.5179\n",
      "Epoch 31/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4566 - binary_accuracy: 0.6911 - val_loss: 1.8773 - val_binary_accuracy: 0.5179\n",
      "Epoch 32/42\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4561 - binary_accuracy: 0.6911 - val_loss: 1.9457 - val_binary_accuracy: 0.5357\n",
      "Epoch 33/42\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4651 - binary_accuracy: 0.6795 - val_loss: 1.5178 - val_binary_accuracy: 0.5214\n",
      "Epoch 34/42\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4660 - binary_accuracy: 0.6830 - val_loss: 2.1825 - val_binary_accuracy: 0.5071\n",
      "Epoch 35/42\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4831 - binary_accuracy: 0.6795 - val_loss: 1.1176 - val_binary_accuracy: 0.4964\n",
      "Epoch 36/42\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4724 - binary_accuracy: 0.6866 - val_loss: 1.3216 - val_binary_accuracy: 0.4964\n",
      "Epoch 37/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4614 - binary_accuracy: 0.6884 - val_loss: 1.4365 - val_binary_accuracy: 0.5036\n",
      "Epoch 38/42\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4563 - binary_accuracy: 0.6920 - val_loss: 1.7035 - val_binary_accuracy: 0.5393\n",
      "Epoch 39/42\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4691 - binary_accuracy: 0.6911 - val_loss: 1.2882 - val_binary_accuracy: 0.5179\n",
      "Epoch 40/42\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4677 - binary_accuracy: 0.6893 - val_loss: 1.3961 - val_binary_accuracy: 0.5179\n",
      "Epoch 41/42\n",
      "112/112 [==============================] - 34s 300ms/step - loss: 0.4660 - binary_accuracy: 0.6857 - val_loss: 1.5306 - val_binary_accuracy: 0.5214\n",
      "Epoch 42/42\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4635 - binary_accuracy: 0.6902 - val_loss: 1.6632 - val_binary_accuracy: 0.5036\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.7008 - binary_accuracy: 0.6521\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.4672 - binary_accuracy: 0.5633\n",
      "training start... epochs = 43\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_97 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_87 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/43\n",
      "112/112 [==============================] - 62s 423ms/step - loss: 0.6890 - binary_accuracy: 0.5384 - val_loss: 0.6922 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/43\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.6626 - binary_accuracy: 0.5893 - val_loss: 0.7169 - val_binary_accuracy: 0.5179\n",
      "Epoch 3/43\n",
      "112/112 [==============================] - 38s 338ms/step - loss: 0.5820 - binary_accuracy: 0.6518 - val_loss: 0.9162 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/43\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.5401 - binary_accuracy: 0.6768 - val_loss: 0.8785 - val_binary_accuracy: 0.5250\n",
      "Epoch 5/43\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.4960 - binary_accuracy: 0.6589 - val_loss: 0.9023 - val_binary_accuracy: 0.5429\n",
      "Epoch 6/43\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.4806 - binary_accuracy: 0.6821 - val_loss: 0.9964 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/43\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4773 - binary_accuracy: 0.6821 - val_loss: 0.9269 - val_binary_accuracy: 0.5357\n",
      "Epoch 8/43\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4765 - binary_accuracy: 0.6866 - val_loss: 1.0370 - val_binary_accuracy: 0.5250\n",
      "Epoch 9/43\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4731 - binary_accuracy: 0.6893 - val_loss: 1.1224 - val_binary_accuracy: 0.5321\n",
      "Epoch 10/43\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4733 - binary_accuracy: 0.6893 - val_loss: 1.1927 - val_binary_accuracy: 0.5393\n",
      "Epoch 11/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4681 - binary_accuracy: 0.6884 - val_loss: 1.2284 - val_binary_accuracy: 0.5571\n",
      "Epoch 12/43\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4682 - binary_accuracy: 0.6893 - val_loss: 1.3115 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/43\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4716 - binary_accuracy: 0.6875 - val_loss: 1.1985 - val_binary_accuracy: 0.5357\n",
      "Epoch 14/43\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4698 - binary_accuracy: 0.6848 - val_loss: 1.2186 - val_binary_accuracy: 0.5321\n",
      "Epoch 15/43\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4677 - binary_accuracy: 0.6884 - val_loss: 1.1829 - val_binary_accuracy: 0.5429\n",
      "Epoch 16/43\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4649 - binary_accuracy: 0.6884 - val_loss: 1.0580 - val_binary_accuracy: 0.5429\n",
      "Epoch 17/43\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4708 - binary_accuracy: 0.6875 - val_loss: 1.2087 - val_binary_accuracy: 0.5321\n",
      "Epoch 18/43\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4630 - binary_accuracy: 0.6884 - val_loss: 1.2824 - val_binary_accuracy: 0.5321\n",
      "Epoch 19/43\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4602 - binary_accuracy: 0.6902 - val_loss: 1.5094 - val_binary_accuracy: 0.5286\n",
      "Epoch 20/43\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4781 - binary_accuracy: 0.6804 - val_loss: 1.1144 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/43\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4702 - binary_accuracy: 0.6857 - val_loss: 1.3447 - val_binary_accuracy: 0.5071\n",
      "Epoch 22/43\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4634 - binary_accuracy: 0.6777 - val_loss: 1.2074 - val_binary_accuracy: 0.5393\n",
      "Epoch 23/43\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4687 - binary_accuracy: 0.6741 - val_loss: 1.0474 - val_binary_accuracy: 0.5321\n",
      "Epoch 24/43\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4621 - binary_accuracy: 0.6893 - val_loss: 1.1688 - val_binary_accuracy: 0.5786\n",
      "Epoch 25/43\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4579 - binary_accuracy: 0.6812 - val_loss: 1.1410 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/43\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4550 - binary_accuracy: 0.6812 - val_loss: 1.2763 - val_binary_accuracy: 0.5500\n",
      "Epoch 27/43\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.6464 - binary_accuracy: 0.6438 - val_loss: 0.7113 - val_binary_accuracy: 0.5286\n",
      "Epoch 28/43\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.6048 - binary_accuracy: 0.6339 - val_loss: 0.7408 - val_binary_accuracy: 0.5107\n",
      "Epoch 29/43\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.5483 - binary_accuracy: 0.6607 - val_loss: 0.8764 - val_binary_accuracy: 0.5464\n",
      "Epoch 30/43\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.5145 - binary_accuracy: 0.6607 - val_loss: 0.9078 - val_binary_accuracy: 0.5536\n",
      "Epoch 31/43\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4946 - binary_accuracy: 0.6821 - val_loss: 0.8679 - val_binary_accuracy: 0.5179\n",
      "Epoch 32/43\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4906 - binary_accuracy: 0.6634 - val_loss: 0.9463 - val_binary_accuracy: 0.5500\n",
      "Epoch 33/43\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4843 - binary_accuracy: 0.6607 - val_loss: 0.9814 - val_binary_accuracy: 0.5429\n",
      "Epoch 34/43\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4773 - binary_accuracy: 0.6732 - val_loss: 1.1121 - val_binary_accuracy: 0.5536\n",
      "Epoch 35/43\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4697 - binary_accuracy: 0.6723 - val_loss: 1.0755 - val_binary_accuracy: 0.5500\n",
      "Epoch 36/43\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4655 - binary_accuracy: 0.6830 - val_loss: 0.9534 - val_binary_accuracy: 0.5536\n",
      "Epoch 37/43\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4658 - binary_accuracy: 0.6848 - val_loss: 1.1729 - val_binary_accuracy: 0.5464\n",
      "Epoch 38/43\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4593 - binary_accuracy: 0.6821 - val_loss: 1.1620 - val_binary_accuracy: 0.5464\n",
      "Epoch 39/43\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4638 - binary_accuracy: 0.6866 - val_loss: 1.2518 - val_binary_accuracy: 0.5571\n",
      "Epoch 40/43\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4950 - binary_accuracy: 0.6562 - val_loss: 1.2177 - val_binary_accuracy: 0.5464\n",
      "Epoch 41/43\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4716 - binary_accuracy: 0.6714 - val_loss: 1.3280 - val_binary_accuracy: 0.5464\n",
      "Epoch 42/43\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4623 - binary_accuracy: 0.6661 - val_loss: 1.3860 - val_binary_accuracy: 0.5464\n",
      "Epoch 43/43\n",
      "112/112 [==============================] - 34s 301ms/step - loss: 0.4621 - binary_accuracy: 0.6634 - val_loss: 1.4201 - val_binary_accuracy: 0.5464\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 104ms/step - loss: 0.6496 - binary_accuracy: 0.6607\n",
      "60/60 [==============================] - 6s 104ms/step - loss: 1.5031 - binary_accuracy: 0.5700\n",
      "training start... epochs = 44\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_98 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_88 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_200 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_201 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/44\n",
      "112/112 [==============================] - 62s 432ms/step - loss: 0.6926 - binary_accuracy: 0.5312 - val_loss: 0.6893 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/44\n",
      "112/112 [==============================] - 40s 354ms/step - loss: 0.6652 - binary_accuracy: 0.5804 - val_loss: 0.6959 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/44\n",
      "112/112 [==============================] - 38s 343ms/step - loss: 0.5901 - binary_accuracy: 0.6536 - val_loss: 0.7295 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/44\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.5231 - binary_accuracy: 0.6643 - val_loss: 0.8190 - val_binary_accuracy: 0.5464\n",
      "Epoch 5/44\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.5244 - binary_accuracy: 0.6875 - val_loss: 0.8095 - val_binary_accuracy: 0.5643\n",
      "Epoch 6/44\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.4749 - binary_accuracy: 0.6911 - val_loss: 0.9739 - val_binary_accuracy: 0.5750\n",
      "Epoch 7/44\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.5288 - binary_accuracy: 0.6777 - val_loss: 0.7944 - val_binary_accuracy: 0.5429\n",
      "Epoch 8/44\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4809 - binary_accuracy: 0.6804 - val_loss: 0.8670 - val_binary_accuracy: 0.5571\n",
      "Epoch 9/44\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4723 - binary_accuracy: 0.6804 - val_loss: 0.9803 - val_binary_accuracy: 0.5571\n",
      "Epoch 10/44\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4913 - binary_accuracy: 0.6750 - val_loss: 0.8646 - val_binary_accuracy: 0.5500\n",
      "Epoch 11/44\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4811 - binary_accuracy: 0.6741 - val_loss: 0.9854 - val_binary_accuracy: 0.5429\n",
      "Epoch 12/44\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4770 - binary_accuracy: 0.6884 - val_loss: 1.0263 - val_binary_accuracy: 0.5429\n",
      "Epoch 13/44\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4773 - binary_accuracy: 0.6821 - val_loss: 1.0631 - val_binary_accuracy: 0.5500\n",
      "Epoch 14/44\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4759 - binary_accuracy: 0.6893 - val_loss: 1.0907 - val_binary_accuracy: 0.5500\n",
      "Epoch 15/44\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4754 - binary_accuracy: 0.6893 - val_loss: 1.1319 - val_binary_accuracy: 0.5500\n",
      "Epoch 16/44\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4751 - binary_accuracy: 0.6893 - val_loss: 1.1825 - val_binary_accuracy: 0.5464\n",
      "Epoch 17/44\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4727 - binary_accuracy: 0.6911 - val_loss: 1.1207 - val_binary_accuracy: 0.5500\n",
      "Epoch 18/44\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4758 - binary_accuracy: 0.6893 - val_loss: 1.1968 - val_binary_accuracy: 0.5393\n",
      "Epoch 19/44\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4737 - binary_accuracy: 0.6893 - val_loss: 1.2268 - val_binary_accuracy: 0.5500\n",
      "Epoch 20/44\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4719 - binary_accuracy: 0.6893 - val_loss: 1.2459 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/44\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4688 - binary_accuracy: 0.6893 - val_loss: 1.3038 - val_binary_accuracy: 0.5536\n",
      "Epoch 22/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4746 - binary_accuracy: 0.6848 - val_loss: 1.2367 - val_binary_accuracy: 0.5429\n",
      "Epoch 23/44\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4731 - binary_accuracy: 0.6884 - val_loss: 1.2744 - val_binary_accuracy: 0.5464\n",
      "Epoch 24/44\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4718 - binary_accuracy: 0.6893 - val_loss: 1.3107 - val_binary_accuracy: 0.5500\n",
      "Epoch 25/44\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4708 - binary_accuracy: 0.6893 - val_loss: 1.3273 - val_binary_accuracy: 0.5500\n",
      "Epoch 26/44\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4707 - binary_accuracy: 0.6893 - val_loss: 1.3500 - val_binary_accuracy: 0.5464\n",
      "Epoch 27/44\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4698 - binary_accuracy: 0.6893 - val_loss: 1.3893 - val_binary_accuracy: 0.5500\n",
      "Epoch 28/44\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4689 - binary_accuracy: 0.6830 - val_loss: 1.4273 - val_binary_accuracy: 0.5500\n",
      "Epoch 29/44\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4661 - binary_accuracy: 0.6938 - val_loss: 1.5173 - val_binary_accuracy: 0.5643\n",
      "Epoch 30/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4810 - binary_accuracy: 0.6848 - val_loss: 1.3298 - val_binary_accuracy: 0.5357\n",
      "Epoch 31/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4747 - binary_accuracy: 0.6875 - val_loss: 1.4381 - val_binary_accuracy: 0.5500\n",
      "Epoch 32/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4754 - binary_accuracy: 0.6893 - val_loss: 1.2418 - val_binary_accuracy: 0.5393\n",
      "Epoch 33/44\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4675 - binary_accuracy: 0.6893 - val_loss: 1.3063 - val_binary_accuracy: 0.5393\n",
      "Epoch 34/44\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4653 - binary_accuracy: 0.6902 - val_loss: 1.3981 - val_binary_accuracy: 0.5321\n",
      "Epoch 35/44\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4819 - binary_accuracy: 0.6911 - val_loss: 1.2618 - val_binary_accuracy: 0.5464\n",
      "Epoch 36/44\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4745 - binary_accuracy: 0.6750 - val_loss: 1.2475 - val_binary_accuracy: 0.5571\n",
      "Epoch 37/44\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4718 - binary_accuracy: 0.6884 - val_loss: 1.1698 - val_binary_accuracy: 0.5321\n",
      "Epoch 38/44\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4628 - binary_accuracy: 0.6893 - val_loss: 1.2850 - val_binary_accuracy: 0.5393\n",
      "Epoch 39/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4575 - binary_accuracy: 0.6893 - val_loss: 1.1956 - val_binary_accuracy: 0.5464\n",
      "Epoch 40/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4602 - binary_accuracy: 0.6893 - val_loss: 1.2759 - val_binary_accuracy: 0.5393\n",
      "Epoch 41/44\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4595 - binary_accuracy: 0.6893 - val_loss: 1.3268 - val_binary_accuracy: 0.5500\n",
      "Epoch 42/44\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4665 - binary_accuracy: 0.6866 - val_loss: 1.3017 - val_binary_accuracy: 0.5321\n",
      "Epoch 43/44\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4483 - binary_accuracy: 0.6884 - val_loss: 1.2669 - val_binary_accuracy: 0.5429\n",
      "Epoch 44/44\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4639 - binary_accuracy: 0.6723 - val_loss: 1.3446 - val_binary_accuracy: 0.5571\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 105ms/step - loss: 0.6308 - binary_accuracy: 0.6629\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.2445 - binary_accuracy: 0.5667\n",
      "training start... epochs = 45\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_99 (Embedding)    (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_89 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_202 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_203 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/45\n",
      "112/112 [==============================] - 63s 432ms/step - loss: 0.6923 - binary_accuracy: 0.5250 - val_loss: 0.6900 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/45\n",
      "112/112 [==============================] - 40s 355ms/step - loss: 0.6661 - binary_accuracy: 0.5571 - val_loss: 0.7550 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/45\n",
      "112/112 [==============================] - 39s 344ms/step - loss: 0.5910 - binary_accuracy: 0.6545 - val_loss: 0.8433 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/45\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.5555 - binary_accuracy: 0.6670 - val_loss: 0.7910 - val_binary_accuracy: 0.5143\n",
      "Epoch 5/45\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.4995 - binary_accuracy: 0.6830 - val_loss: 0.9124 - val_binary_accuracy: 0.5321\n",
      "Epoch 6/45\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.4770 - binary_accuracy: 0.6884 - val_loss: 0.9311 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/45\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.5003 - binary_accuracy: 0.6607 - val_loss: 0.8670 - val_binary_accuracy: 0.5036\n",
      "Epoch 8/45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 37s 327ms/step - loss: 0.4919 - binary_accuracy: 0.6786 - val_loss: 0.9560 - val_binary_accuracy: 0.5107\n",
      "Epoch 9/45\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.4830 - binary_accuracy: 0.6830 - val_loss: 1.0317 - val_binary_accuracy: 0.5107\n",
      "Epoch 10/45\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4766 - binary_accuracy: 0.6830 - val_loss: 1.0943 - val_binary_accuracy: 0.5036\n",
      "Epoch 11/45\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4695 - binary_accuracy: 0.6884 - val_loss: 1.2395 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/45\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4628 - binary_accuracy: 0.6848 - val_loss: 1.7313 - val_binary_accuracy: 0.4964\n",
      "Epoch 13/45\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4793 - binary_accuracy: 0.6777 - val_loss: 1.1095 - val_binary_accuracy: 0.4929\n",
      "Epoch 14/45\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4744 - binary_accuracy: 0.6723 - val_loss: 1.2236 - val_binary_accuracy: 0.4893\n",
      "Epoch 15/45\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4638 - binary_accuracy: 0.6884 - val_loss: 1.4770 - val_binary_accuracy: 0.5071\n",
      "Epoch 16/45\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4614 - binary_accuracy: 0.6884 - val_loss: 1.2076 - val_binary_accuracy: 0.4821\n",
      "Epoch 17/45\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4637 - binary_accuracy: 0.6875 - val_loss: 1.4363 - val_binary_accuracy: 0.4964\n",
      "Epoch 18/45\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.7697 - binary_accuracy: 0.6554 - val_loss: 0.8186 - val_binary_accuracy: 0.5286\n",
      "Epoch 19/45\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.6668 - binary_accuracy: 0.5804 - val_loss: 0.7216 - val_binary_accuracy: 0.5143\n",
      "Epoch 20/45\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5837 - binary_accuracy: 0.6366 - val_loss: 0.7163 - val_binary_accuracy: 0.5464\n",
      "Epoch 21/45\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.5505 - binary_accuracy: 0.6482 - val_loss: 0.7611 - val_binary_accuracy: 0.5286\n",
      "Epoch 22/45\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.5313 - binary_accuracy: 0.6580 - val_loss: 0.7682 - val_binary_accuracy: 0.5071\n",
      "Epoch 23/45\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.5179 - binary_accuracy: 0.6750 - val_loss: 0.7836 - val_binary_accuracy: 0.5357\n",
      "Epoch 24/45\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5095 - binary_accuracy: 0.6518 - val_loss: 0.8025 - val_binary_accuracy: 0.5250\n",
      "Epoch 25/45\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.5016 - binary_accuracy: 0.6589 - val_loss: 0.8093 - val_binary_accuracy: 0.5250\n",
      "Epoch 26/45\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4883 - binary_accuracy: 0.6518 - val_loss: 0.8281 - val_binary_accuracy: 0.5393\n",
      "Epoch 27/45\n",
      "112/112 [==============================] - 34s 302ms/step - loss: 0.4733 - binary_accuracy: 0.7036 - val_loss: 0.8790 - val_binary_accuracy: 0.5071\n",
      "Epoch 28/45\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4637 - binary_accuracy: 0.6946 - val_loss: 0.9748 - val_binary_accuracy: 0.4964\n",
      "Epoch 29/45\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4574 - binary_accuracy: 0.7089 - val_loss: 0.9840 - val_binary_accuracy: 0.5107\n",
      "Epoch 30/45\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4380 - binary_accuracy: 0.7277 - val_loss: 1.0336 - val_binary_accuracy: 0.5393\n",
      "Epoch 31/45\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.5053 - binary_accuracy: 0.6812 - val_loss: 0.8929 - val_binary_accuracy: 0.5143\n",
      "Epoch 32/45\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4820 - binary_accuracy: 0.6875 - val_loss: 0.9030 - val_binary_accuracy: 0.4893\n",
      "Epoch 33/45\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.4579 - binary_accuracy: 0.6964 - val_loss: 1.2505 - val_binary_accuracy: 0.5464\n",
      "Epoch 34/45\n",
      "112/112 [==============================] - 34s 308ms/step - loss: 0.5165 - binary_accuracy: 0.6491 - val_loss: 0.8842 - val_binary_accuracy: 0.5071\n",
      "Epoch 35/45\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4879 - binary_accuracy: 0.6741 - val_loss: 0.9273 - val_binary_accuracy: 0.5107\n",
      "Epoch 36/45\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4805 - binary_accuracy: 0.6893 - val_loss: 0.9448 - val_binary_accuracy: 0.5071\n",
      "Epoch 37/45\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4807 - binary_accuracy: 0.6812 - val_loss: 0.9257 - val_binary_accuracy: 0.5071\n",
      "Epoch 38/45\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4703 - binary_accuracy: 0.6687 - val_loss: 0.9374 - val_binary_accuracy: 0.5107\n",
      "Epoch 39/45\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4538 - binary_accuracy: 0.6955 - val_loss: 1.1389 - val_binary_accuracy: 0.4786\n",
      "Epoch 40/45\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4239 - binary_accuracy: 0.7393 - val_loss: 1.1273 - val_binary_accuracy: 0.5321\n",
      "Epoch 41/45\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4561 - binary_accuracy: 0.7116 - val_loss: 0.9538 - val_binary_accuracy: 0.5286\n",
      "Epoch 42/45\n",
      "112/112 [==============================] - 34s 303ms/step - loss: 0.4711 - binary_accuracy: 0.6777 - val_loss: 1.0109 - val_binary_accuracy: 0.5143\n",
      "Epoch 43/45\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4469 - binary_accuracy: 0.7214 - val_loss: 1.0727 - val_binary_accuracy: 0.5321\n",
      "Epoch 44/45\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4117 - binary_accuracy: 0.7446 - val_loss: 1.1196 - val_binary_accuracy: 0.5321\n",
      "Epoch 45/45\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4611 - binary_accuracy: 0.6884 - val_loss: 1.0919 - val_binary_accuracy: 0.5179\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 107ms/step - loss: 0.5777 - binary_accuracy: 0.6714\n",
      "60/60 [==============================] - 6s 108ms/step - loss: 1.1761 - binary_accuracy: 0.5150\n",
      "training start... epochs = 46\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_100 (Embedding)   (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_90 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_204 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_205 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/46\n",
      "112/112 [==============================] - 62s 423ms/step - loss: 0.6918 - binary_accuracy: 0.5420 - val_loss: 0.6893 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/46\n",
      "112/112 [==============================] - 40s 355ms/step - loss: 0.6662 - binary_accuracy: 0.5848 - val_loss: 0.6911 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/46\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.5789 - binary_accuracy: 0.6670 - val_loss: 1.0761 - val_binary_accuracy: 0.5393\n",
      "Epoch 4/46\n",
      "112/112 [==============================] - 38s 336ms/step - loss: 0.5402 - binary_accuracy: 0.6821 - val_loss: 0.8119 - val_binary_accuracy: 0.5393\n",
      "Epoch 5/46\n",
      "112/112 [==============================] - 37s 333ms/step - loss: 0.5034 - binary_accuracy: 0.6518 - val_loss: 0.9834 - val_binary_accuracy: 0.5429\n",
      "Epoch 6/46\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5068 - binary_accuracy: 0.6750 - val_loss: 0.8484 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4775 - binary_accuracy: 0.6821 - val_loss: 0.9663 - val_binary_accuracy: 0.5536\n",
      "Epoch 8/46\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.5140 - binary_accuracy: 0.6741 - val_loss: 1.0051 - val_binary_accuracy: 0.5536\n",
      "Epoch 9/46\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4753 - binary_accuracy: 0.6884 - val_loss: 1.0999 - val_binary_accuracy: 0.5536\n",
      "Epoch 10/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4744 - binary_accuracy: 0.6875 - val_loss: 1.0726 - val_binary_accuracy: 0.5143\n",
      "Epoch 11/46\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4930 - binary_accuracy: 0.6795 - val_loss: 0.9767 - val_binary_accuracy: 0.5321\n",
      "Epoch 12/46\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4750 - binary_accuracy: 0.6723 - val_loss: 1.0087 - val_binary_accuracy: 0.5321\n",
      "Epoch 13/46\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4700 - binary_accuracy: 0.6848 - val_loss: 1.0891 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4664 - binary_accuracy: 0.6893 - val_loss: 1.1538 - val_binary_accuracy: 0.5429\n",
      "Epoch 15/46\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4650 - binary_accuracy: 0.6893 - val_loss: 1.1985 - val_binary_accuracy: 0.5393\n",
      "Epoch 16/46\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4701 - binary_accuracy: 0.6848 - val_loss: 0.9655 - val_binary_accuracy: 0.5250\n",
      "Epoch 17/46\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4844 - binary_accuracy: 0.6750 - val_loss: 1.0503 - val_binary_accuracy: 0.5393\n",
      "Epoch 18/46\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4768 - binary_accuracy: 0.6795 - val_loss: 1.2472 - val_binary_accuracy: 0.5464\n",
      "Epoch 19/46\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4705 - binary_accuracy: 0.6893 - val_loss: 1.5060 - val_binary_accuracy: 0.5429\n",
      "Epoch 20/46\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4683 - binary_accuracy: 0.6893 - val_loss: 1.4755 - val_binary_accuracy: 0.5500\n",
      "Epoch 21/46\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4653 - binary_accuracy: 0.6893 - val_loss: 1.4707 - val_binary_accuracy: 0.5500\n",
      "Epoch 22/46\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4650 - binary_accuracy: 0.6893 - val_loss: 1.4798 - val_binary_accuracy: 0.5464\n",
      "Epoch 23/46\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4636 - binary_accuracy: 0.6893 - val_loss: 1.5412 - val_binary_accuracy: 0.5429\n",
      "Epoch 24/46\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4643 - binary_accuracy: 0.6893 - val_loss: 1.5019 - val_binary_accuracy: 0.5393\n",
      "Epoch 25/46\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4640 - binary_accuracy: 0.6893 - val_loss: 1.5211 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4638 - binary_accuracy: 0.6893 - val_loss: 1.5559 - val_binary_accuracy: 0.5500\n",
      "Epoch 27/46\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4690 - binary_accuracy: 0.6893 - val_loss: 1.4419 - val_binary_accuracy: 0.5393\n",
      "Epoch 28/46\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4663 - binary_accuracy: 0.6893 - val_loss: 1.4604 - val_binary_accuracy: 0.5429\n",
      "Epoch 29/46\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4640 - binary_accuracy: 0.6893 - val_loss: 1.4972 - val_binary_accuracy: 0.5429\n",
      "Epoch 30/46\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4637 - binary_accuracy: 0.6893 - val_loss: 1.5732 - val_binary_accuracy: 0.5393\n",
      "Epoch 31/46\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.5413 - binary_accuracy: 0.6911 - val_loss: 1.4344 - val_binary_accuracy: 0.5464\n",
      "Epoch 32/46\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4850 - binary_accuracy: 0.6875 - val_loss: 1.2901 - val_binary_accuracy: 0.5607\n",
      "Epoch 33/46\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4744 - binary_accuracy: 0.6893 - val_loss: 0.9773 - val_binary_accuracy: 0.5321\n",
      "Epoch 34/46\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4695 - binary_accuracy: 0.6884 - val_loss: 1.1429 - val_binary_accuracy: 0.5357\n",
      "Epoch 35/46\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4638 - binary_accuracy: 0.6893 - val_loss: 1.2297 - val_binary_accuracy: 0.5286\n",
      "Epoch 36/46\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4609 - binary_accuracy: 0.6893 - val_loss: 1.2268 - val_binary_accuracy: 0.5286\n",
      "Epoch 37/46\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4574 - binary_accuracy: 0.6902 - val_loss: 1.3358 - val_binary_accuracy: 0.5429\n",
      "Epoch 38/46\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4707 - binary_accuracy: 0.6920 - val_loss: 1.0399 - val_binary_accuracy: 0.5179\n",
      "Epoch 39/46\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4611 - binary_accuracy: 0.6866 - val_loss: 1.1086 - val_binary_accuracy: 0.5357\n",
      "Epoch 40/46\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4557 - binary_accuracy: 0.6625 - val_loss: 1.1936 - val_binary_accuracy: 0.5357\n",
      "Epoch 41/46\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4539 - binary_accuracy: 0.6920 - val_loss: 1.2227 - val_binary_accuracy: 0.5286\n",
      "Epoch 42/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.6020 - binary_accuracy: 0.7429 - val_loss: 0.9534 - val_binary_accuracy: 0.5857\n",
      "Epoch 43/46\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4457 - binary_accuracy: 0.7884 - val_loss: 0.9785 - val_binary_accuracy: 0.5893\n",
      "Epoch 44/46\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.4315 - binary_accuracy: 0.7741 - val_loss: 1.1174 - val_binary_accuracy: 0.5821\n",
      "Epoch 45/46\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4539 - binary_accuracy: 0.7232 - val_loss: 1.1313 - val_binary_accuracy: 0.5464\n",
      "Epoch 46/46\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4818 - binary_accuracy: 0.6812 - val_loss: 1.0642 - val_binary_accuracy: 0.5393\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5942 - binary_accuracy: 0.6607\n",
      "60/60 [==============================] - 6s 107ms/step - loss: 0.9631 - binary_accuracy: 0.5567\n",
      "training start... epochs = 47\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_101 (Embedding)   (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_91 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_206 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_207 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 62s 424ms/step - loss: 0.6925 - binary_accuracy: 0.5188 - val_loss: 0.6895 - val_binary_accuracy: 0.5321\n",
      "Epoch 2/47\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.6895 - binary_accuracy: 0.5705 - val_loss: 0.6880 - val_binary_accuracy: 0.5107\n",
      "Epoch 3/47\n",
      "112/112 [==============================] - 39s 346ms/step - loss: 0.6036 - binary_accuracy: 0.6384 - val_loss: 0.7154 - val_binary_accuracy: 0.5500\n",
      "Epoch 4/47\n",
      "112/112 [==============================] - 38s 337ms/step - loss: 0.5490 - binary_accuracy: 0.6670 - val_loss: 0.7333 - val_binary_accuracy: 0.5571\n",
      "Epoch 5/47\n",
      "112/112 [==============================] - 37s 334ms/step - loss: 0.5025 - binary_accuracy: 0.6848 - val_loss: 0.7878 - val_binary_accuracy: 0.5464\n",
      "Epoch 6/47\n",
      "112/112 [==============================] - 36s 326ms/step - loss: 0.4832 - binary_accuracy: 0.6795 - val_loss: 1.0233 - val_binary_accuracy: 0.5464\n",
      "Epoch 7/47\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4752 - binary_accuracy: 0.6911 - val_loss: 1.1074 - val_binary_accuracy: 0.5500\n",
      "Epoch 8/47\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4729 - binary_accuracy: 0.6884 - val_loss: 1.2198 - val_binary_accuracy: 0.5464\n",
      "Epoch 9/47\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4736 - binary_accuracy: 0.6875 - val_loss: 1.0843 - val_binary_accuracy: 0.5393\n",
      "Epoch 10/47\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.4977 - binary_accuracy: 0.6830 - val_loss: 0.8882 - val_binary_accuracy: 0.5536\n",
      "Epoch 11/47\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4795 - binary_accuracy: 0.6830 - val_loss: 1.2621 - val_binary_accuracy: 0.5500\n",
      "Epoch 12/47\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4933 - binary_accuracy: 0.6696 - val_loss: 0.8432 - val_binary_accuracy: 0.5357\n",
      "Epoch 13/47\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.4786 - binary_accuracy: 0.6795 - val_loss: 1.0762 - val_binary_accuracy: 0.5393\n",
      "Epoch 14/47\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4677 - binary_accuracy: 0.6777 - val_loss: 1.2063 - val_binary_accuracy: 0.5357\n",
      "Epoch 15/47\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4629 - binary_accuracy: 0.6786 - val_loss: 1.2708 - val_binary_accuracy: 0.5321\n",
      "Epoch 16/47\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4609 - binary_accuracy: 0.6839 - val_loss: 1.2457 - val_binary_accuracy: 0.5357\n",
      "Epoch 17/47\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4592 - binary_accuracy: 0.6893 - val_loss: 1.3679 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/47\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4793 - binary_accuracy: 0.6884 - val_loss: 1.0944 - val_binary_accuracy: 0.5357\n",
      "Epoch 19/47\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4683 - binary_accuracy: 0.6893 - val_loss: 1.1518 - val_binary_accuracy: 0.5429\n",
      "Epoch 20/47\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4638 - binary_accuracy: 0.6893 - val_loss: 1.2834 - val_binary_accuracy: 0.5429\n",
      "Epoch 21/47\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4678 - binary_accuracy: 0.6884 - val_loss: 1.5105 - val_binary_accuracy: 0.5250\n",
      "Epoch 22/47\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4678 - binary_accuracy: 0.6884 - val_loss: 1.1762 - val_binary_accuracy: 0.5429\n",
      "Epoch 23/47\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4644 - binary_accuracy: 0.6893 - val_loss: 1.2109 - val_binary_accuracy: 0.5464\n",
      "Epoch 24/47\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4597 - binary_accuracy: 0.6893 - val_loss: 1.2835 - val_binary_accuracy: 0.5464\n",
      "Epoch 25/47\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.5140 - binary_accuracy: 0.6893 - val_loss: 1.1664 - val_binary_accuracy: 0.5393\n",
      "Epoch 26/47\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4683 - binary_accuracy: 0.6938 - val_loss: 1.0349 - val_binary_accuracy: 0.5536\n",
      "Epoch 27/47\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.5096 - binary_accuracy: 0.7705 - val_loss: 0.8332 - val_binary_accuracy: 0.5750\n",
      "Epoch 28/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4787 - binary_accuracy: 0.6955 - val_loss: 1.0138 - val_binary_accuracy: 0.5357\n",
      "Epoch 29/47\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4311 - binary_accuracy: 0.7795 - val_loss: 0.9628 - val_binary_accuracy: 0.6250\n",
      "Epoch 30/47\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4502 - binary_accuracy: 0.7580 - val_loss: 0.9916 - val_binary_accuracy: 0.5714\n",
      "Epoch 31/47\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4512 - binary_accuracy: 0.7304 - val_loss: 0.9908 - val_binary_accuracy: 0.5571\n",
      "Epoch 32/47\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4510 - binary_accuracy: 0.7679 - val_loss: 1.0692 - val_binary_accuracy: 0.6179\n",
      "Epoch 33/47\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4204 - binary_accuracy: 0.7884 - val_loss: 1.0960 - val_binary_accuracy: 0.6214\n",
      "Epoch 34/47\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4281 - binary_accuracy: 0.7821 - val_loss: 1.0883 - val_binary_accuracy: 0.6429\n",
      "Epoch 35/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4319 - binary_accuracy: 0.7902 - val_loss: 1.1726 - val_binary_accuracy: 0.5464\n",
      "Epoch 36/47\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4330 - binary_accuracy: 0.7821 - val_loss: 1.0968 - val_binary_accuracy: 0.5893\n",
      "Epoch 37/47\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4156 - binary_accuracy: 0.7893 - val_loss: 1.1387 - val_binary_accuracy: 0.5964\n",
      "Epoch 38/47\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4376 - binary_accuracy: 0.7839 - val_loss: 1.3304 - val_binary_accuracy: 0.5679\n",
      "Epoch 39/47\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4239 - binary_accuracy: 0.7830 - val_loss: 1.2810 - val_binary_accuracy: 0.5964\n",
      "Epoch 40/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4153 - binary_accuracy: 0.7911 - val_loss: 1.2898 - val_binary_accuracy: 0.6071\n",
      "Epoch 41/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4094 - binary_accuracy: 0.7964 - val_loss: 1.3203 - val_binary_accuracy: 0.6107\n",
      "Epoch 42/47\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.5027 - binary_accuracy: 0.6795 - val_loss: 1.0551 - val_binary_accuracy: 0.5250\n",
      "Epoch 43/47\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4745 - binary_accuracy: 0.6741 - val_loss: 1.1213 - val_binary_accuracy: 0.5464\n",
      "Epoch 44/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4665 - binary_accuracy: 0.6795 - val_loss: 1.1733 - val_binary_accuracy: 0.5464\n",
      "Epoch 45/47\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4558 - binary_accuracy: 0.6741 - val_loss: 1.1751 - val_binary_accuracy: 0.6071\n",
      "Epoch 46/47\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4163 - binary_accuracy: 0.7714 - val_loss: 1.2324 - val_binary_accuracy: 0.5857\n",
      "Epoch 47/47\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4147 - binary_accuracy: 0.7741 - val_loss: 1.2479 - val_binary_accuracy: 0.5929\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.5796 - binary_accuracy: 0.7407\n",
      "60/60 [==============================] - 6s 105ms/step - loss: 1.1438 - binary_accuracy: 0.5800\n",
      "training start... epochs = 48\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_102 (Embedding)   (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_92 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_202 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_208 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_209 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/48\n",
      "112/112 [==============================] - 63s 428ms/step - loss: 0.6926 - binary_accuracy: 0.5018 - val_loss: 0.6900 - val_binary_accuracy: 0.5357\n",
      "Epoch 2/48\n",
      "112/112 [==============================] - 39s 348ms/step - loss: 0.6724 - binary_accuracy: 0.5571 - val_loss: 0.7058 - val_binary_accuracy: 0.5214\n",
      "Epoch 3/48\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.5945 - binary_accuracy: 0.6571 - val_loss: 0.7039 - val_binary_accuracy: 0.5357\n",
      "Epoch 4/48\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.5329 - binary_accuracy: 0.6670 - val_loss: 0.7648 - val_binary_accuracy: 0.5429\n",
      "Epoch 5/48\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.4963 - binary_accuracy: 0.6670 - val_loss: 0.8982 - val_binary_accuracy: 0.5250\n",
      "Epoch 6/48\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.4846 - binary_accuracy: 0.6821 - val_loss: 0.8408 - val_binary_accuracy: 0.5393\n",
      "Epoch 7/48\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.4727 - binary_accuracy: 0.6875 - val_loss: 1.2046 - val_binary_accuracy: 0.5429\n",
      "Epoch 8/48\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.4701 - binary_accuracy: 0.6839 - val_loss: 0.9557 - val_binary_accuracy: 0.5607\n",
      "Epoch 9/48\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4677 - binary_accuracy: 0.6875 - val_loss: 1.0678 - val_binary_accuracy: 0.5536\n",
      "Epoch 10/48\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4696 - binary_accuracy: 0.6848 - val_loss: 1.0237 - val_binary_accuracy: 0.5536\n",
      "Epoch 11/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4657 - binary_accuracy: 0.6893 - val_loss: 1.0938 - val_binary_accuracy: 0.5643\n",
      "Epoch 12/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4645 - binary_accuracy: 0.6902 - val_loss: 1.1706 - val_binary_accuracy: 0.5679\n",
      "Epoch 13/48\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4731 - binary_accuracy: 0.6875 - val_loss: 0.9653 - val_binary_accuracy: 0.5464\n",
      "Epoch 14/48\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4642 - binary_accuracy: 0.6893 - val_loss: 1.0328 - val_binary_accuracy: 0.5464\n",
      "Epoch 15/48\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.5175 - binary_accuracy: 0.6866 - val_loss: 0.9253 - val_binary_accuracy: 0.5393\n",
      "Epoch 16/48\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4661 - binary_accuracy: 0.6839 - val_loss: 0.9565 - val_binary_accuracy: 0.5393\n",
      "Epoch 17/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4744 - binary_accuracy: 0.6839 - val_loss: 0.8874 - val_binary_accuracy: 0.5429\n",
      "Epoch 18/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4679 - binary_accuracy: 0.6786 - val_loss: 1.0340 - val_binary_accuracy: 0.5536\n",
      "Epoch 19/48\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4662 - binary_accuracy: 0.6893 - val_loss: 1.0395 - val_binary_accuracy: 0.5429\n",
      "Epoch 20/48\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4615 - binary_accuracy: 0.6893 - val_loss: 1.2072 - val_binary_accuracy: 0.5393\n",
      "Epoch 21/48\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4583 - binary_accuracy: 0.6920 - val_loss: 1.2974 - val_binary_accuracy: 0.5464\n",
      "Epoch 22/48\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4578 - binary_accuracy: 0.6839 - val_loss: 1.1789 - val_binary_accuracy: 0.5464\n",
      "Epoch 23/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4672 - binary_accuracy: 0.6893 - val_loss: 1.0828 - val_binary_accuracy: 0.5286\n",
      "Epoch 24/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4711 - binary_accuracy: 0.6768 - val_loss: 1.2680 - val_binary_accuracy: 0.5464\n",
      "Epoch 25/48\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4606 - binary_accuracy: 0.6866 - val_loss: 1.4801 - val_binary_accuracy: 0.5429\n",
      "Epoch 26/48\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4613 - binary_accuracy: 0.6857 - val_loss: 1.3879 - val_binary_accuracy: 0.5464\n",
      "Epoch 27/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4611 - binary_accuracy: 0.6902 - val_loss: 1.4837 - val_binary_accuracy: 0.5464\n",
      "Epoch 28/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4730 - binary_accuracy: 0.6839 - val_loss: 1.3848 - val_binary_accuracy: 0.5214\n",
      "Epoch 29/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4626 - binary_accuracy: 0.6795 - val_loss: 1.4534 - val_binary_accuracy: 0.5464\n",
      "Epoch 30/48\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4616 - binary_accuracy: 0.6955 - val_loss: 1.4787 - val_binary_accuracy: 0.5286\n",
      "Epoch 31/48\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4616 - binary_accuracy: 0.6946 - val_loss: 1.6427 - val_binary_accuracy: 0.5571\n",
      "Epoch 32/48\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4578 - binary_accuracy: 0.6866 - val_loss: 1.3021 - val_binary_accuracy: 0.5393\n",
      "Epoch 33/48\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4643 - binary_accuracy: 0.6893 - val_loss: 1.1544 - val_binary_accuracy: 0.5286\n",
      "Epoch 34/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4606 - binary_accuracy: 0.6848 - val_loss: 1.3499 - val_binary_accuracy: 0.5357\n",
      "Epoch 35/48\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4732 - binary_accuracy: 0.6759 - val_loss: 1.2702 - val_binary_accuracy: 0.5214\n",
      "Epoch 36/48\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4670 - binary_accuracy: 0.6848 - val_loss: 1.1754 - val_binary_accuracy: 0.5321\n",
      "Epoch 37/48\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4620 - binary_accuracy: 0.6929 - val_loss: 1.3728 - val_binary_accuracy: 0.5429\n",
      "Epoch 38/48\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4562 - binary_accuracy: 0.6955 - val_loss: 1.5484 - val_binary_accuracy: 0.5393\n",
      "Epoch 39/48\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4580 - binary_accuracy: 0.6973 - val_loss: 1.8134 - val_binary_accuracy: 0.5179\n",
      "Epoch 40/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4869 - binary_accuracy: 0.6938 - val_loss: 1.1591 - val_binary_accuracy: 0.5393\n",
      "Epoch 41/48\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4562 - binary_accuracy: 0.7063 - val_loss: 1.2058 - val_binary_accuracy: 0.5571\n",
      "Epoch 42/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4741 - binary_accuracy: 0.6839 - val_loss: 1.3644 - val_binary_accuracy: 0.5250\n",
      "Epoch 43/48\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4610 - binary_accuracy: 0.6670 - val_loss: 1.3530 - val_binary_accuracy: 0.5393\n",
      "Epoch 44/48\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4470 - binary_accuracy: 0.7205 - val_loss: 1.3124 - val_binary_accuracy: 0.6000\n",
      "Epoch 45/48\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4211 - binary_accuracy: 0.7589 - val_loss: 1.3275 - val_binary_accuracy: 0.6071\n",
      "Epoch 46/48\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4245 - binary_accuracy: 0.7741 - val_loss: 1.3773 - val_binary_accuracy: 0.6679\n",
      "Epoch 47/48\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4293 - binary_accuracy: 0.7446 - val_loss: 1.3011 - val_binary_accuracy: 0.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/48\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4208 - binary_accuracy: 0.7661 - val_loss: 1.3352 - val_binary_accuracy: 0.6214\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 108ms/step - loss: 0.5989 - binary_accuracy: 0.7414\n",
      "60/60 [==============================] - 7s 122ms/step - loss: 1.2764 - binary_accuracy: 0.6000\n",
      "training start... epochs = 49\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_103 (Embedding)   (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_93 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_210 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_211 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/49\n",
      "112/112 [==============================] - 64s 443ms/step - loss: 0.6914 - binary_accuracy: 0.5357 - val_loss: 0.6889 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/49\n",
      "112/112 [==============================] - 40s 357ms/step - loss: 0.6669 - binary_accuracy: 0.5777 - val_loss: 0.6977 - val_binary_accuracy: 0.5250\n",
      "Epoch 3/49\n",
      "112/112 [==============================] - 39s 350ms/step - loss: 0.6025 - binary_accuracy: 0.6402 - val_loss: 0.7358 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/49\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.5053 - binary_accuracy: 0.6812 - val_loss: 0.7756 - val_binary_accuracy: 0.5429\n",
      "Epoch 5/49\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.5055 - binary_accuracy: 0.6598 - val_loss: 0.9030 - val_binary_accuracy: 0.5607\n",
      "Epoch 6/49\n",
      "112/112 [==============================] - 38s 340ms/step - loss: 0.4991 - binary_accuracy: 0.6643 - val_loss: 0.7853 - val_binary_accuracy: 0.5500\n",
      "Epoch 7/49\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.4712 - binary_accuracy: 0.6857 - val_loss: 0.8954 - val_binary_accuracy: 0.5464\n",
      "Epoch 8/49\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.4827 - binary_accuracy: 0.6938 - val_loss: 0.7780 - val_binary_accuracy: 0.5429\n",
      "Epoch 9/49\n",
      "112/112 [==============================] - 36s 326ms/step - loss: 0.4834 - binary_accuracy: 0.6705 - val_loss: 0.8965 - val_binary_accuracy: 0.5464\n",
      "Epoch 10/49\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.4677 - binary_accuracy: 0.6893 - val_loss: 1.0611 - val_binary_accuracy: 0.5750\n",
      "Epoch 11/49\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.5837 - binary_accuracy: 0.6625 - val_loss: 0.7435 - val_binary_accuracy: 0.5357\n",
      "Epoch 12/49\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4818 - binary_accuracy: 0.6670 - val_loss: 0.8374 - val_binary_accuracy: 0.5500\n",
      "Epoch 13/49\n",
      "112/112 [==============================] - 37s 328ms/step - loss: 0.5009 - binary_accuracy: 0.6500 - val_loss: 0.7782 - val_binary_accuracy: 0.5500\n",
      "Epoch 14/49\n",
      "112/112 [==============================] - 36s 324ms/step - loss: 0.4914 - binary_accuracy: 0.6652 - val_loss: 0.8176 - val_binary_accuracy: 0.5500\n",
      "Epoch 15/49\n",
      "112/112 [==============================] - 36s 326ms/step - loss: 0.4813 - binary_accuracy: 0.6875 - val_loss: 0.8684 - val_binary_accuracy: 0.5571\n",
      "Epoch 16/49\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4784 - binary_accuracy: 0.6768 - val_loss: 0.9137 - val_binary_accuracy: 0.5571\n",
      "Epoch 17/49\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4779 - binary_accuracy: 0.6893 - val_loss: 0.9522 - val_binary_accuracy: 0.5571\n",
      "Epoch 18/49\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4770 - binary_accuracy: 0.6857 - val_loss: 0.9771 - val_binary_accuracy: 0.5536\n",
      "Epoch 19/49\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4745 - binary_accuracy: 0.6893 - val_loss: 1.0061 - val_binary_accuracy: 0.5500\n",
      "Epoch 20/49\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4751 - binary_accuracy: 0.6786 - val_loss: 1.0288 - val_binary_accuracy: 0.5536\n",
      "Epoch 21/49\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4743 - binary_accuracy: 0.6902 - val_loss: 1.0506 - val_binary_accuracy: 0.5607\n",
      "Epoch 22/49\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4748 - binary_accuracy: 0.6839 - val_loss: 1.0756 - val_binary_accuracy: 0.5571\n",
      "Epoch 23/49\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4736 - binary_accuracy: 0.6911 - val_loss: 1.1205 - val_binary_accuracy: 0.5607\n",
      "Epoch 24/49\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4733 - binary_accuracy: 0.6920 - val_loss: 1.2067 - val_binary_accuracy: 0.5500\n",
      "Epoch 25/49\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4712 - binary_accuracy: 0.6911 - val_loss: 1.2057 - val_binary_accuracy: 0.5464\n",
      "Epoch 26/49\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4745 - binary_accuracy: 0.6920 - val_loss: 0.9898 - val_binary_accuracy: 0.5536\n",
      "Epoch 27/49\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4736 - binary_accuracy: 0.6884 - val_loss: 1.0320 - val_binary_accuracy: 0.5607\n",
      "Epoch 28/49\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4702 - binary_accuracy: 0.6929 - val_loss: 1.1510 - val_binary_accuracy: 0.5643\n",
      "Epoch 29/49\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4801 - binary_accuracy: 0.6911 - val_loss: 0.9964 - val_binary_accuracy: 0.5357\n",
      "Epoch 30/49\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4780 - binary_accuracy: 0.6848 - val_loss: 1.1765 - val_binary_accuracy: 0.5571\n",
      "Epoch 31/49\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4733 - binary_accuracy: 0.6884 - val_loss: 1.2371 - val_binary_accuracy: 0.5500\n",
      "Epoch 32/49\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4785 - binary_accuracy: 0.6866 - val_loss: 1.1311 - val_binary_accuracy: 0.5500\n",
      "Epoch 33/49\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4721 - binary_accuracy: 0.6893 - val_loss: 1.2333 - val_binary_accuracy: 0.5464\n",
      "Epoch 34/49\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4711 - binary_accuracy: 0.6893 - val_loss: 1.2819 - val_binary_accuracy: 0.5500\n",
      "Epoch 35/49\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4672 - binary_accuracy: 0.6893 - val_loss: 1.3164 - val_binary_accuracy: 0.5536\n",
      "Epoch 36/49\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4666 - binary_accuracy: 0.6893 - val_loss: 1.3543 - val_binary_accuracy: 0.5536\n",
      "Epoch 37/49\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4637 - binary_accuracy: 0.6893 - val_loss: 1.4022 - val_binary_accuracy: 0.5500\n",
      "Epoch 38/49\n",
      "112/112 [==============================] - 35s 311ms/step - loss: 0.4643 - binary_accuracy: 0.6893 - val_loss: 1.4227 - val_binary_accuracy: 0.5536\n",
      "Epoch 39/49\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4630 - binary_accuracy: 0.6893 - val_loss: 1.5036 - val_binary_accuracy: 0.5536\n",
      "Epoch 40/49\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4604 - binary_accuracy: 0.6893 - val_loss: 1.7161 - val_binary_accuracy: 0.5571\n",
      "Epoch 41/49\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4661 - binary_accuracy: 0.6866 - val_loss: 1.5663 - val_binary_accuracy: 0.5536\n",
      "Epoch 42/49\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4619 - binary_accuracy: 0.6893 - val_loss: 1.5523 - val_binary_accuracy: 0.5571\n",
      "Epoch 43/49\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4606 - binary_accuracy: 0.6893 - val_loss: 1.6360 - val_binary_accuracy: 0.5536\n",
      "Epoch 44/49\n",
      "112/112 [==============================] - 34s 305ms/step - loss: 0.4603 - binary_accuracy: 0.6893 - val_loss: 1.6590 - val_binary_accuracy: 0.5607\n",
      "Epoch 45/49\n",
      "112/112 [==============================] - 34s 304ms/step - loss: 0.4684 - binary_accuracy: 0.6732 - val_loss: 1.3966 - val_binary_accuracy: 0.5643\n",
      "Epoch 46/49\n",
      "112/112 [==============================] - 34s 306ms/step - loss: 0.4662 - binary_accuracy: 0.6893 - val_loss: 1.4159 - val_binary_accuracy: 0.5607\n",
      "Epoch 47/49\n",
      "112/112 [==============================] - 34s 307ms/step - loss: 0.4647 - binary_accuracy: 0.6893 - val_loss: 1.4453 - val_binary_accuracy: 0.5607\n",
      "Epoch 48/49\n",
      "112/112 [==============================] - 35s 308ms/step - loss: 0.4633 - binary_accuracy: 0.6893 - val_loss: 1.4924 - val_binary_accuracy: 0.5679\n",
      "Epoch 49/49\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4766 - binary_accuracy: 0.6848 - val_loss: 1.5133 - val_binary_accuracy: 0.5357\n",
      "evaluating...\n",
      "140/140 [==============================] - 15s 106ms/step - loss: 0.7020 - binary_accuracy: 0.6507\n",
      "60/60 [==============================] - 6s 106ms/step - loss: 1.3743 - binary_accuracy: 0.5667\n",
      "training start... epochs = 50\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_104 (Embedding)   (None, 759, 32)           160000    \n",
      "                                                                 \n",
      " lstm_94 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_212 (Dense)           (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_213 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,025\n",
      "Trainable params: 177,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "112/112 [==============================] - 64s 436ms/step - loss: 0.6909 - binary_accuracy: 0.5375 - val_loss: 0.6887 - val_binary_accuracy: 0.5393\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 41s 366ms/step - loss: 0.6621 - binary_accuracy: 0.5714 - val_loss: 0.8107 - val_binary_accuracy: 0.5321\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 39s 351ms/step - loss: 0.5801 - binary_accuracy: 0.6545 - val_loss: 0.7737 - val_binary_accuracy: 0.5286\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 38s 342ms/step - loss: 0.5165 - binary_accuracy: 0.6527 - val_loss: 0.8748 - val_binary_accuracy: 0.5286\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.6943 - binary_accuracy: 0.6357 - val_loss: 0.8017 - val_binary_accuracy: 0.5393\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 37s 330ms/step - loss: 0.5467 - binary_accuracy: 0.6848 - val_loss: 0.8866 - val_binary_accuracy: 0.5357\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.5157 - binary_accuracy: 0.6866 - val_loss: 0.8732 - val_binary_accuracy: 0.5321\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 38s 339ms/step - loss: 0.4949 - binary_accuracy: 0.6670 - val_loss: 0.9651 - val_binary_accuracy: 0.5286\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 37s 329ms/step - loss: 0.4782 - binary_accuracy: 0.6732 - val_loss: 1.0014 - val_binary_accuracy: 0.5286\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 37s 331ms/step - loss: 0.4793 - binary_accuracy: 0.6768 - val_loss: 1.0491 - val_binary_accuracy: 0.5607\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 36s 323ms/step - loss: 0.5100 - binary_accuracy: 0.6723 - val_loss: 0.7359 - val_binary_accuracy: 0.5500\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 37s 326ms/step - loss: 0.4913 - binary_accuracy: 0.6795 - val_loss: 0.9358 - val_binary_accuracy: 0.5286\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.4790 - binary_accuracy: 0.6839 - val_loss: 0.9443 - val_binary_accuracy: 0.5143\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4727 - binary_accuracy: 0.6848 - val_loss: 0.9771 - val_binary_accuracy: 0.5393\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.5240 - binary_accuracy: 0.6732 - val_loss: 0.6742 - val_binary_accuracy: 0.5750\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4988 - binary_accuracy: 0.6902 - val_loss: 0.9217 - val_binary_accuracy: 0.5464\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4868 - binary_accuracy: 0.6741 - val_loss: 0.8693 - val_binary_accuracy: 0.5464\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4788 - binary_accuracy: 0.6893 - val_loss: 0.9086 - val_binary_accuracy: 0.5393\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4788 - binary_accuracy: 0.6723 - val_loss: 1.0952 - val_binary_accuracy: 0.5500\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4776 - binary_accuracy: 0.6866 - val_loss: 1.0602 - val_binary_accuracy: 0.5536\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4736 - binary_accuracy: 0.6929 - val_loss: 1.0458 - val_binary_accuracy: 0.5786\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4810 - binary_accuracy: 0.6884 - val_loss: 1.5649 - val_binary_accuracy: 0.5500\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4747 - binary_accuracy: 0.6902 - val_loss: 1.6110 - val_binary_accuracy: 0.5607\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4711 - binary_accuracy: 0.6911 - val_loss: 1.7259 - val_binary_accuracy: 0.5714\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4674 - binary_accuracy: 0.7045 - val_loss: 1.8001 - val_binary_accuracy: 0.5786\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4944 - binary_accuracy: 0.6875 - val_loss: 1.2372 - val_binary_accuracy: 0.5393\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 36s 326ms/step - loss: 0.4822 - binary_accuracy: 0.6884 - val_loss: 1.2485 - val_binary_accuracy: 0.5393\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4757 - binary_accuracy: 0.6875 - val_loss: 1.2097 - val_binary_accuracy: 0.5393\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4722 - binary_accuracy: 0.6893 - val_loss: 1.2460 - val_binary_accuracy: 0.5357\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 37s 332ms/step - loss: 0.4720 - binary_accuracy: 0.6893 - val_loss: 1.3122 - val_binary_accuracy: 0.5286\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4782 - binary_accuracy: 0.6848 - val_loss: 1.0817 - val_binary_accuracy: 0.5357\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 35s 317ms/step - loss: 0.4878 - binary_accuracy: 0.6598 - val_loss: 1.0753 - val_binary_accuracy: 0.5429\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 35s 313ms/step - loss: 0.4814 - binary_accuracy: 0.6812 - val_loss: 1.1013 - val_binary_accuracy: 0.5393\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 35s 310ms/step - loss: 0.4800 - binary_accuracy: 0.6821 - val_loss: 1.1408 - val_binary_accuracy: 0.5393\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4804 - binary_accuracy: 0.6705 - val_loss: 1.1873 - val_binary_accuracy: 0.5429\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4769 - binary_accuracy: 0.6821 - val_loss: 1.2353 - val_binary_accuracy: 0.5571\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 35s 315ms/step - loss: 0.4782 - binary_accuracy: 0.6884 - val_loss: 1.2709 - val_binary_accuracy: 0.5464\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 36s 322ms/step - loss: 0.4774 - binary_accuracy: 0.6670 - val_loss: 1.3148 - val_binary_accuracy: 0.5536\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 35s 314ms/step - loss: 0.4746 - binary_accuracy: 0.6875 - val_loss: 1.4072 - val_binary_accuracy: 0.5464\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4707 - binary_accuracy: 0.6848 - val_loss: 1.3506 - val_binary_accuracy: 0.5464\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 36s 325ms/step - loss: 0.4645 - binary_accuracy: 0.6857 - val_loss: 1.5353 - val_binary_accuracy: 0.5429\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 36s 317ms/step - loss: 0.4950 - binary_accuracy: 0.6893 - val_loss: 1.0819 - val_binary_accuracy: 0.5500\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 36s 321ms/step - loss: 0.4745 - binary_accuracy: 0.6750 - val_loss: 1.0625 - val_binary_accuracy: 0.5357\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 37s 327ms/step - loss: 0.4701 - binary_accuracy: 0.6812 - val_loss: 1.1249 - val_binary_accuracy: 0.5464\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 36s 319ms/step - loss: 0.4678 - binary_accuracy: 0.6866 - val_loss: 1.1885 - val_binary_accuracy: 0.5464\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 36s 320ms/step - loss: 0.4634 - binary_accuracy: 0.6893 - val_loss: 1.3555 - val_binary_accuracy: 0.5536\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 36s 318ms/step - loss: 0.4769 - binary_accuracy: 0.6571 - val_loss: 1.1227 - val_binary_accuracy: 0.5143\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 35s 309ms/step - loss: 0.4741 - binary_accuracy: 0.6696 - val_loss: 1.1906 - val_binary_accuracy: 0.5500\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 35s 316ms/step - loss: 0.4718 - binary_accuracy: 0.6893 - val_loss: 1.2450 - val_binary_accuracy: 0.5536\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 35s 312ms/step - loss: 0.4705 - binary_accuracy: 0.6875 - val_loss: 1.2714 - val_binary_accuracy: 0.5571\n",
      "evaluating...\n",
      "140/140 [==============================] - 16s 114ms/step - loss: 0.6294 - binary_accuracy: 0.6629\n",
      "60/60 [==============================] - 7s 109ms/step - loss: 1.3546 - binary_accuracy: 0.5617\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_32(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(5000, 32),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm_32(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_32(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch, validation_split=0.2)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "print(\"-- 70% L --\")\n",
    "train_acc_32 = []\n",
    "test_acc_32 = []\n",
    "for epoch in range(10, 51):\n",
    "    res_lstm_70_32 = fit_train_lstm_32(train_padded_70, train_y, test_padded_70, test_y, L_70, epoch)\n",
    "    train_acc_32.append(res_lstm_70_32[0])\n",
    "    test_acc_32.append(res_lstm_70_32[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6931e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- LSTM report 2 --\n",
      "epoch = 10 train accuracy = 0.6528571248054504 test accuracy = 0.550000011920929\n",
      "epoch = 11 train accuracy = 0.6521428227424622 test accuracy = 0.5633333325386047\n",
      "epoch = 12 train accuracy = 0.6514285802841187 test accuracy = 0.5516666769981384\n",
      "epoch = 13 train accuracy = 0.6578571200370789 test accuracy = 0.5833333730697632\n",
      "epoch = 14 train accuracy = 0.654285728931427 test accuracy = 0.5550000071525574\n",
      "epoch = 15 train accuracy = 0.6507142782211304 test accuracy = 0.5566666722297668\n",
      "epoch = 16 train accuracy = 0.6564285755157471 test accuracy = 0.5533333420753479\n",
      "epoch = 17 train accuracy = 0.6621428728103638 test accuracy = 0.5666666626930237\n",
      "epoch = 18 train accuracy = 0.6499999761581421 test accuracy = 0.5683333277702332\n",
      "epoch = 19 train accuracy = 0.6499999761581421 test accuracy = 0.5666666626930237\n",
      "epoch = 20 train accuracy = 0.6499999761581421 test accuracy = 0.5600000023841858\n",
      "epoch = 21 train accuracy = 0.6585714221000671 test accuracy = 0.5666666626930237\n",
      "epoch = 22 train accuracy = 0.6535714268684387 test accuracy = 0.5383333563804626\n",
      "epoch = 23 train accuracy = 0.7557142972946167 test accuracy = 0.6100000143051147\n",
      "epoch = 24 train accuracy = 0.6585714221000671 test accuracy = 0.5699999928474426\n",
      "epoch = 25 train accuracy = 0.6592857241630554 test accuracy = 0.5800000429153442\n",
      "epoch = 26 train accuracy = 0.6614285707473755 test accuracy = 0.5699999928474426\n",
      "epoch = 27 train accuracy = 0.6578571200370789 test accuracy = 0.5649999976158142\n",
      "epoch = 28 train accuracy = 0.6650000214576721 test accuracy = 0.5766666531562805\n",
      "epoch = 29 train accuracy = 0.6628571152687073 test accuracy = 0.596666693687439\n",
      "epoch = 30 train accuracy = 0.6092857122421265 test accuracy = 0.503333330154419\n",
      "epoch = 31 train accuracy = 0.6592857241630554 test accuracy = 0.5566666722297668\n",
      "epoch = 32 train accuracy = 0.6464285850524902 test accuracy = 0.5716666579246521\n",
      "epoch = 33 train accuracy = 0.675000011920929 test accuracy = 0.5350000262260437\n",
      "epoch = 34 train accuracy = 0.6564285755157471 test accuracy = 0.5716666579246521\n",
      "epoch = 35 train accuracy = 0.6614285707473755 test accuracy = 0.5850000381469727\n",
      "epoch = 36 train accuracy = 0.6499999761581421 test accuracy = 0.5716666579246521\n",
      "epoch = 37 train accuracy = 0.6614285707473755 test accuracy = 0.5716666579246521\n",
      "epoch = 38 train accuracy = 0.6599999666213989 test accuracy = 0.5550000071525574\n",
      "epoch = 39 train accuracy = 0.6599999666213989 test accuracy = 0.5800000429153442\n",
      "epoch = 40 train accuracy = 0.6650000214576721 test accuracy = 0.5683333277702332\n",
      "epoch = 41 train accuracy = 0.6585714221000671 test accuracy = 0.5483333468437195\n",
      "epoch = 42 train accuracy = 0.6521428227424622 test accuracy = 0.5633333325386047\n",
      "epoch = 43 train accuracy = 0.6607142686843872 test accuracy = 0.5699999928474426\n",
      "epoch = 44 train accuracy = 0.6628571152687073 test accuracy = 0.5666666626930237\n",
      "epoch = 45 train accuracy = 0.6714285612106323 test accuracy = 0.5149999856948853\n",
      "epoch = 46 train accuracy = 0.6607142686843872 test accuracy = 0.5566666722297668\n",
      "epoch = 47 train accuracy = 0.7407142519950867 test accuracy = 0.5800000429153442\n",
      "epoch = 48 train accuracy = 0.741428554058075 test accuracy = 0.6000000238418579\n",
      "epoch = 49 train accuracy = 0.6507142782211304 test accuracy = 0.5666666626930237\n",
      "epoch = 50 train accuracy = 0.6628571152687073 test accuracy = 0.5616666674613953\n"
     ]
    }
   ],
   "source": [
    "print(\"-- LSTM report 2 --\")\n",
    "for i in range(41):\n",
    "    print(\"epoch =\", i+10, \"train accuracy =\", train_acc_32[i], \"test accuracy =\", test_acc_32[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b336ea6b",
   "metadata": {},
   "source": [
    "-- try 3: increase number of topwords used --\n",
    "- top_words set to 20000, epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73bc6aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start... epochs = 10\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, 753, 32)           640000    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 657,025\n",
      "Trainable params: 657,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 34s 171ms/step - loss: 0.6929 - binary_accuracy: 0.5307\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 24s 169ms/step - loss: 0.6590 - binary_accuracy: 0.5879\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 24s 169ms/step - loss: 0.5610 - binary_accuracy: 0.6771\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 0.5070 - binary_accuracy: 0.6729\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 24s 168ms/step - loss: 0.5292 - binary_accuracy: 0.6536\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 0.4873 - binary_accuracy: 0.6643\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 24s 170ms/step - loss: 0.4743 - binary_accuracy: 0.6843\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 23s 168ms/step - loss: 0.4702 - binary_accuracy: 0.6600\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 0.4653 - binary_accuracy: 0.6864\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 24s 168ms/step - loss: 0.4634 - binary_accuracy: 0.6864\n",
      "evaluating...\n",
      "140/140 [==============================] - 16s 102ms/step - loss: 0.4630 - binary_accuracy: 0.6864\n",
      "60/60 [==============================] - 6s 102ms/step - loss: 1.0801 - binary_accuracy: 0.5533\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_more_topwords(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(20000, 32),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm_more_topwords(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_more_topwords(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "print(\"-- 70% L --\")\n",
    "res_lstm_70_more_topwords = fit_train_lstm_more_topwords(train_padded_70, train_y, \n",
    "                                                         test_padded_70, test_y, L_70, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a80c1d",
   "metadata": {},
   "source": [
    "-- try 4: use whole dictionary  --\n",
    "- this time set top_words to 38900, almost equal to #unique_words, epoch = 10\n",
    "- accuracy can hit 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "debac405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 70% L --\n",
      "training start... epochs = 10\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,261,825\n",
      "Trainable params: 1,261,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 34s 173ms/step - loss: 0.6915 - binary_accuracy: 0.5300\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 24s 174ms/step - loss: 0.6803 - binary_accuracy: 0.5879\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.5744 - binary_accuracy: 0.6707\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 0.5098 - binary_accuracy: 0.6857\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 24s 172ms/step - loss: 0.4860 - binary_accuracy: 0.6657\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 24s 172ms/step - loss: 0.4694 - binary_accuracy: 0.6936\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.4748 - binary_accuracy: 0.6936\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 24s 172ms/step - loss: 0.4824 - binary_accuracy: 0.6800\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 24s 172ms/step - loss: 0.4837 - binary_accuracy: 0.6700\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 24s 171ms/step - loss: 0.4712 - binary_accuracy: 0.6879\n",
      "evaluating...\n",
      "140/140 [==============================] - 16s 100ms/step - loss: 0.4652 - binary_accuracy: 0.6864\n",
      "60/60 [==============================] - 6s 100ms/step - loss: 0.7270 - binary_accuracy: 0.6017\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_whole_dict(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(38900, 32),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        #layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm_whole_dict(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_whole_dict(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "print(\"-- 70% L --\")\n",
    "res_lstm_70_whole_dict = fit_train_lstm_whole_dict(train_padded_70, train_y, \n",
    "                                                         test_padded_70, test_y, L_70, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2869e",
   "metadata": {},
   "source": [
    "-- try 5: removal of stopwords  --\n",
    "- epoch = 15, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d0190e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topwords index list = [17, 102, 110, 791, 56, 240, 17044, 6821, 30, 165, 10703, 1198, 16209, 18, 58, 14, 227, 50, 37, 6225, 808, 9, 66, 324, 35, 82, 51, 18930, 504, 46, 48, 27, 692, 16, 10, 113, 144, 728, 6, 21, 32, 124, 24, 70, 115, 34, 36, 95, 247, 76, 90, 192, 397, 2, 26, 1, 3, 19, 55, 49, 86, 11, 290, 98, 4, 31, 23, 13, 12, 43, 353, 152, 57, 122, 221, 145, 84, 812, 1754, 5, 33, 45, 146, 7, 41, 20, 92, 104, 380, 214, 1111, 101, 239, 123, 39, 47, 100, 169, 99, 38, 96, 156, 211, 148, 44, 65, 75, 52, 121, 60, 770, 29, 61, 187, 177, 42, 62, 89, 80, 8, 22, 54, 67, 53, 112, 164, 142]\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \n",
    "             \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \n",
    "             \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \n",
    "             \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \n",
    "             \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \n",
    "             \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \n",
    "             \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \n",
    "             \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \n",
    "             \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \n",
    "             \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\",\n",
    "             \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \n",
    "             \"should\", \"now\"]\n",
    "\n",
    "t = keras.preprocessing.text.Tokenizer()\n",
    "t.fit_on_texts(train_X)\n",
    "dictionary = t.word_index\n",
    "dict_index_list = []\n",
    "for word in stopwords:\n",
    "    dict_index_list.append(dictionary[word])\n",
    "print(\"stopwords index list =\", dict_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58a90db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_padded_70 = padded_70\n",
    "for i in range(0,2000):\n",
    "    text = pruned_padded_70[i]\n",
    "    for j in range(0,text.shape[0]):\n",
    "        if pruned_padded_70[i][j] in dict_index_list:\n",
    "            pruned_padded_70[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f437e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample output:\n",
      " [ 5115     0     0  2515   476     0     0     0   601     0     0   489\n",
      "     0  5656     0    25   949  1283     0   259     0   232   117  8358\n",
      " 12944     0     0  2959     0     0     0  4168   801     0     0     0\n",
      " 18954     0     0  2976 11821  4949  5670   349     0  4643  4436     0\n",
      "  1006  6243 12306     0     0  8439   272     0     0  4158 19120   143\n",
      "     0  1521     0 11153     0     0  1889  5838   831 31854   375 11513\n",
      "     0     0  7545   516     0   161     0     0  1671     0     0  2253\n",
      "     0  8930  1827 31855     0     0 31856     0     0     0     0     0\n",
      "  2399   218     0   135     0     0     0   193  4643     0     0   141\n",
      "     0   503  2666   322     0    87   511   588     0     0   160     0\n",
      "     0   688     0     0   131     0     0  4209     0  2129     0     0\n",
      "     0   344  7491  2121     0     0 31857  4274   403     0     0  3508\n",
      "     0   668 31858  2150 13341     0     0   596     0  2929     0 14528\n",
      " 31859   700     0  7492  2832     0   584     0     0   747  3796     0\n",
      "     0   272  4746     0     0   160     0     0 31860   387   222     0\n",
      "     0  2024  2929  2316  4949  5670   196     0   182     0   395 20902\n",
      "   693   775   908  4160  3548     0  1512   338     0   333     0  1170\n",
      "     0     0     0  2359  1432  3492     0     0     0    71     0     0\n",
      "   180     0     0    15     0     0     0    25  1178  2436     0 20293\n",
      "     0     0   328     0     0  1464     0   237   485 12110   338     0\n",
      "   599   477     0    71   325   318     0     0    93     0   337   272\n",
      "  6372  1659     0   326  1041     0   568     0     0  4616     0  1838\n",
      " 21353  4892     0     0   337   272     0   162     0   199     0     0\n",
      "     0   594 12051  6412  9274     0     0     0     0     0   272     0\n",
      "  3361     0 12873  9356     0 12755     0   253     0   901  5115     0\n",
      "   489     0   811     0  4415   949     0  4643     0  4881   846 31861\n",
      "  1330  9937   617     0     0   448     0     0 31862     0     0    15\n",
      "   111     0   234     0     0   828     0     0     0 14767  6220   482\n",
      "     0    28     0  8204   120     0  4643   143     0  1062     0  1551\n",
      "     0  1628   566     0     0     0     0     0   130   607     0     0\n",
      "   257  9263  6590  1257  1516    40     0    25     0     0   310     0\n",
      "  3714     0  4643     0 31863     0 18335 10844  2029     0  1223  1172\n",
      "     0   418     0     0   234     0     0     0  4643     0     0  6848\n",
      "     0  2024  2929  3611     0   189     0   786     0   326  7888     0\n",
      "  1241    94     0     0    15     0     0     0    15     0  2061  1166\n",
      "   134   346     0     0     0    64    93     0   533     0   322  3471\n",
      "   820     0     0   550    72     0    79   234    69     0  2275  5115\n",
      "    73     0     0  1110     0     0     0     0     0  4215 10387  8761\n",
      "     0     0   137     0     0   266  4949  5670    73     0    25     0\n",
      "     0  1110     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(\"sample output:\\n\",pruned_padded_70[1212])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd1cecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 15\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_28 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,261,825\n",
      "Trainable params: 1,261,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "140/140 [==============================] - 35s 179ms/step - loss: 0.6938 - binary_accuracy: 0.4993\n",
      "Epoch 2/15\n",
      "140/140 [==============================] - 25s 177ms/step - loss: 0.6910 - binary_accuracy: 0.5221\n",
      "Epoch 3/15\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.6374 - binary_accuracy: 0.6150\n",
      "Epoch 4/15\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.5558 - binary_accuracy: 0.6793\n",
      "Epoch 5/15\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.5340 - binary_accuracy: 0.6807\n",
      "Epoch 6/15\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.4938 - binary_accuracy: 0.6686\n",
      "Epoch 7/15\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.4665 - binary_accuracy: 0.7714\n",
      "Epoch 8/15\n",
      "140/140 [==============================] - 24s 174ms/step - loss: 0.5373 - binary_accuracy: 0.6857\n",
      "Epoch 9/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.4827 - binary_accuracy: 0.6979\n",
      "Epoch 10/15\n",
      "140/140 [==============================] - 24s 174ms/step - loss: 0.4121 - binary_accuracy: 0.8143\n",
      "Epoch 11/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.6484 - binary_accuracy: 0.6757\n",
      "Epoch 12/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.4829 - binary_accuracy: 0.6886\n",
      "Epoch 13/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.4869 - binary_accuracy: 0.7221\n",
      "Epoch 14/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.4452 - binary_accuracy: 0.7979\n",
      "Epoch 15/15\n",
      "140/140 [==============================] - 24s 173ms/step - loss: 0.5112 - binary_accuracy: 0.6800\n",
      "evaluating...\n",
      "140/140 [==============================] - 16s 102ms/step - loss: 0.5305 - binary_accuracy: 0.6857\n",
      "60/60 [==============================] - 6s 102ms/step - loss: 0.7717 - binary_accuracy: 0.5700\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_stopwords(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(38900, 32),\n",
    "        layers.LSTM(32, dropout=0.2),\n",
    "        #layers.Dropout(0.2),\n",
    "        #layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm_stopwords(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_stopwords(l)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "lstm_70_stopwords_15 = fit_train_lstm_stopwords(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d79d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 25\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_29 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 256)               8448      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,261,825\n",
      "Trainable params: 1,261,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 36s 182ms/step - loss: 0.6938 - binary_accuracy: 0.4764\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 25s 180ms/step - loss: 0.6902 - binary_accuracy: 0.5393\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.6233 - binary_accuracy: 0.6321\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 24s 174ms/step - loss: 0.5724 - binary_accuracy: 0.6700\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.5230 - binary_accuracy: 0.6736\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 25s 177ms/step - loss: 0.4893 - binary_accuracy: 0.6686\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.4724 - binary_accuracy: 0.6821\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.4647 - binary_accuracy: 0.6829\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.4693 - binary_accuracy: 0.6814\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.4576 - binary_accuracy: 0.6943\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.4714 - binary_accuracy: 0.6857\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.4644 - binary_accuracy: 0.6864\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.4632 - binary_accuracy: 0.6879\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.4487 - binary_accuracy: 0.6943\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 25s 180ms/step - loss: 0.4380 - binary_accuracy: 0.6993\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 25s 181ms/step - loss: 0.4295 - binary_accuracy: 0.7164\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 25s 182ms/step - loss: 0.4172 - binary_accuracy: 0.7221\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 25s 175ms/step - loss: 0.4650 - binary_accuracy: 0.6843\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 0.4455 - binary_accuracy: 0.7050\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 25s 177ms/step - loss: 0.4226 - binary_accuracy: 0.7229\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 25s 180ms/step - loss: 0.4349 - binary_accuracy: 0.7200\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 25s 178ms/step - loss: 0.4712 - binary_accuracy: 0.6786\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 24s 175ms/step - loss: 0.4599 - binary_accuracy: 0.6886\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 25s 176ms/step - loss: 0.4582 - binary_accuracy: 0.6800\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 25s 179ms/step - loss: 0.4661 - binary_accuracy: 0.6850\n",
      "evaluating...\n",
      "140/140 [==============================] - 17s 103ms/step - loss: 0.4585 - binary_accuracy: 0.6879\n",
      "60/60 [==============================] - 6s 101ms/step - loss: 0.9537 - binary_accuracy: 0.5567\n"
     ]
    }
   ],
   "source": [
    "lstm_70_stopwords_25 = fit_train_lstm_stopwords(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a80f7",
   "metadata": {},
   "source": [
    "-- try 6: try 5 plus slower learning rate --\n",
    "- there were accuracy drops between epochs, try to adapt to a slower learning rate\n",
    "- learning rate set to 0.0001, epoch = 8, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2054ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 8\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_38 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "140/140 [==============================] - 61s 346ms/step - loss: 0.6933 - binary_accuracy: 0.4686\n",
      "Epoch 2/8\n",
      "140/140 [==============================] - 48s 340ms/step - loss: 0.6928 - binary_accuracy: 0.5214\n",
      "Epoch 3/8\n",
      "140/140 [==============================] - 47s 339ms/step - loss: 0.6921 - binary_accuracy: 0.5379\n",
      "Epoch 4/8\n",
      "140/140 [==============================] - 48s 340ms/step - loss: 0.6888 - binary_accuracy: 0.6407\n",
      "Epoch 5/8\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.6421 - binary_accuracy: 0.7393\n",
      "Epoch 6/8\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.3896 - binary_accuracy: 0.8750\n",
      "Epoch 7/8\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.1549 - binary_accuracy: 0.9536\n",
      "Epoch 8/8\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0796 - binary_accuracy: 0.9821\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 205ms/step - loss: 0.0391 - binary_accuracy: 0.9957\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 0.5486 - binary_accuracy: 0.7617\n"
     ]
    }
   ],
   "source": [
    "def fit_train_lstm_stopwords_lr(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_stopwords(l)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "lstm_70_stopwords_lr_8 = fit_train_lstm_stopwords_lr(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a8d34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 12\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "140/140 [==============================] - 62s 354ms/step - loss: 0.6931 - binary_accuracy: 0.4986\n",
      "Epoch 2/12\n",
      "140/140 [==============================] - 48s 342ms/step - loss: 0.6928 - binary_accuracy: 0.5136\n",
      "Epoch 3/12\n",
      "140/140 [==============================] - 48s 341ms/step - loss: 0.6924 - binary_accuracy: 0.5371\n",
      "Epoch 4/12\n",
      "140/140 [==============================] - 48s 341ms/step - loss: 0.6905 - binary_accuracy: 0.5929\n",
      "Epoch 5/12\n",
      "140/140 [==============================] - 48s 343ms/step - loss: 0.6744 - binary_accuracy: 0.6686\n",
      "Epoch 6/12\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.5003 - binary_accuracy: 0.8086\n",
      "Epoch 7/12\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.2273 - binary_accuracy: 0.9121\n",
      "Epoch 8/12\n",
      "140/140 [==============================] - 48s 344ms/step - loss: 0.0847 - binary_accuracy: 0.9750\n",
      "Epoch 9/12\n",
      "140/140 [==============================] - 48s 340ms/step - loss: 0.0651 - binary_accuracy: 0.9821\n",
      "Epoch 10/12\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0229 - binary_accuracy: 0.9964\n",
      "Epoch 11/12\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0361 - binary_accuracy: 0.9871\n",
      "Epoch 12/12\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.0186 - binary_accuracy: 0.9979\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 205ms/step - loss: 0.0129 - binary_accuracy: 0.9971\n",
      "60/60 [==============================] - 12s 201ms/step - loss: 0.9606 - binary_accuracy: 0.7583\n"
     ]
    }
   ],
   "source": [
    "lstm_70_stopwords_lr_12 = fit_train_lstm_stopwords_lr(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de4880b",
   "metadata": {},
   "source": [
    "-- try 7: BRNN - Bidirectional LSTM --\n",
    "- more commonly used for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58e1e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 7\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_41 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 64)               16640     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "140/140 [==============================] - 63s 362ms/step - loss: 0.6934 - binary_accuracy: 0.4836\n",
      "Epoch 2/7\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6928 - binary_accuracy: 0.5186\n",
      "Epoch 3/7\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.6922 - binary_accuracy: 0.5536\n",
      "Epoch 4/7\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6908 - binary_accuracy: 0.5529\n",
      "Epoch 5/7\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.6838 - binary_accuracy: 0.6557\n",
      "Epoch 6/7\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6322 - binary_accuracy: 0.7929\n",
      "Epoch 7/7\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 0.4237 - binary_accuracy: 0.8564\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 211ms/step - loss: 0.1968 - binary_accuracy: 0.9629\n",
      "60/60 [==============================] - 13s 208ms/step - loss: 0.6174 - binary_accuracy: 0.6850\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_Bidirectional(l):\n",
    "    model = keras.models.Sequential([\n",
    "        layers.Input(shape=(l,)),\n",
    "        layers.Embedding(38900, 32),\n",
    "        layers.Bidirectional(layers.LSTM(32, dropout=0.2)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def fit_train_lstm_Bidirectional(train_X, train_y, test_X, test_y, l, epoch):\n",
    "    print(\"training start... epochs =\", epoch)\n",
    "    model = create_lstm_Bidirectional(l)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', \n",
    "                   metrics=['binary_accuracy'])\n",
    "    model.fit(train_X, train_y, batch_size=10, epochs=epoch)\n",
    "    print(\"evaluating...\")\n",
    "    train_res = model.evaluate(train_X, train_y, batch_size=10)\n",
    "    test_res = model.evaluate(test_X, test_y, batch_size=10)\n",
    "    return [train_res[1],test_res[1]]\n",
    "\n",
    "lstm_70_Bidirectional_7 = fit_train_lstm_Bidirectional(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0861ddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 12\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_42 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/12\n",
      "140/140 [==============================] - 63s 365ms/step - loss: 0.6933 - binary_accuracy: 0.4857\n",
      "Epoch 2/12\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.6928 - binary_accuracy: 0.5186\n",
      "Epoch 3/12\n",
      "140/140 [==============================] - 48s 344ms/step - loss: 0.6922 - binary_accuracy: 0.5479\n",
      "Epoch 4/12\n",
      "140/140 [==============================] - 48s 343ms/step - loss: 0.6905 - binary_accuracy: 0.5543\n",
      "Epoch 5/12\n",
      "140/140 [==============================] - 48s 343ms/step - loss: 0.6826 - binary_accuracy: 0.6557\n",
      "Epoch 6/12\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.5950 - binary_accuracy: 0.7564\n",
      "Epoch 7/12\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.3091 - binary_accuracy: 0.8879\n",
      "Epoch 8/12\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.1166 - binary_accuracy: 0.9671\n",
      "Epoch 9/12\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0428 - binary_accuracy: 0.9921\n",
      "Epoch 10/12\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0293 - binary_accuracy: 0.9929\n",
      "Epoch 11/12\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.0155 - binary_accuracy: 0.9979\n",
      "Epoch 12/12\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0088 - binary_accuracy: 0.9986\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 207ms/step - loss: 0.0042 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 0.6829 - binary_accuracy: 0.7750\n"
     ]
    }
   ],
   "source": [
    "lstm_70_Bidirectional_12 = fit_train_lstm_Bidirectional(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "524851de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start... epochs = 13\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_45 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/13\n",
      "140/140 [==============================] - 62s 357ms/step - loss: 0.6933 - binary_accuracy: 0.4936\n",
      "Epoch 2/13\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.6928 - binary_accuracy: 0.5429\n",
      "Epoch 3/13\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.6921 - binary_accuracy: 0.5750\n",
      "Epoch 4/13\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.6899 - binary_accuracy: 0.5879\n",
      "Epoch 5/13\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.6839 - binary_accuracy: 0.7086\n",
      "Epoch 6/13\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.6373 - binary_accuracy: 0.8407\n",
      "Epoch 7/13\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.5002 - binary_accuracy: 0.8186\n",
      "Epoch 8/13\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.2482 - binary_accuracy: 0.9171\n",
      "Epoch 9/13\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.1034 - binary_accuracy: 0.9750\n",
      "Epoch 10/13\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0467 - binary_accuracy: 0.9914\n",
      "Epoch 11/13\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.0288 - binary_accuracy: 0.9950\n",
      "Epoch 12/13\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0129 - binary_accuracy: 0.9993\n",
      "Epoch 13/13\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0093 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 203ms/step - loss: 0.0074 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 199ms/step - loss: 0.8662 - binary_accuracy: 0.7117\n",
      "training start... epochs = 14\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_46 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/14\n",
      "140/140 [==============================] - 62s 357ms/step - loss: 0.6932 - binary_accuracy: 0.4857\n",
      "Epoch 2/14\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.6927 - binary_accuracy: 0.5586\n",
      "Epoch 3/14\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.6916 - binary_accuracy: 0.5857\n",
      "Epoch 4/14\n",
      "140/140 [==============================] - 48s 344ms/step - loss: 0.6875 - binary_accuracy: 0.6471\n",
      "Epoch 5/14\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.6713 - binary_accuracy: 0.6914\n",
      "Epoch 6/14\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.5694 - binary_accuracy: 0.7950\n",
      "Epoch 7/14\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.3282 - binary_accuracy: 0.8843\n",
      "Epoch 8/14\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.1636 - binary_accuracy: 0.9536\n",
      "Epoch 9/14\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0815 - binary_accuracy: 0.9807\n",
      "Epoch 10/14\n",
      "140/140 [==============================] - 49s 346ms/step - loss: 0.0450 - binary_accuracy: 0.9893\n",
      "Epoch 11/14\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.0188 - binary_accuracy: 0.9993\n",
      "Epoch 12/14\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 0.0191 - binary_accuracy: 0.9957\n",
      "Epoch 13/14\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0127 - binary_accuracy: 0.9986\n",
      "Epoch 14/14\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.0076 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 206ms/step - loss: 0.0090 - binary_accuracy: 0.9986\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 0.9131 - binary_accuracy: 0.7033\n",
      "training start... epochs = 15\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_47 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_15 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "140/140 [==============================] - 63s 361ms/step - loss: 0.6932 - binary_accuracy: 0.4671\n",
      "Epoch 2/15\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6928 - binary_accuracy: 0.5314\n",
      "Epoch 3/15\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6921 - binary_accuracy: 0.5550\n",
      "Epoch 4/15\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.6898 - binary_accuracy: 0.5921\n",
      "Epoch 5/15\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6889 - binary_accuracy: 0.6693\n",
      "Epoch 6/15\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.5767 - binary_accuracy: 0.7936\n",
      "Epoch 7/15\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.3234 - binary_accuracy: 0.8993\n",
      "Epoch 8/15\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.1462 - binary_accuracy: 0.9607\n",
      "Epoch 9/15\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0622 - binary_accuracy: 0.9893\n",
      "Epoch 10/15\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.0358 - binary_accuracy: 0.9964\n",
      "Epoch 11/15\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0214 - binary_accuracy: 0.9979\n",
      "Epoch 12/15\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0131 - binary_accuracy: 0.9993\n",
      "Epoch 13/15\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0099 - binary_accuracy: 0.9993\n",
      "Epoch 14/15\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0079 - binary_accuracy: 0.9993\n",
      "Epoch 15/15\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0071 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 206ms/step - loss: 0.0059 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 0.9013 - binary_accuracy: 0.7217\n",
      "training start... epochs = 16\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_48 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_16 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/16\n",
      "140/140 [==============================] - 65s 372ms/step - loss: 0.6935 - binary_accuracy: 0.4921\n",
      "Epoch 2/16\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.6928 - binary_accuracy: 0.5157\n",
      "Epoch 3/16\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.6926 - binary_accuracy: 0.5193\n",
      "Epoch 4/16\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.6910 - binary_accuracy: 0.5629\n",
      "Epoch 5/16\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.6856 - binary_accuracy: 0.6550\n",
      "Epoch 6/16\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.6346 - binary_accuracy: 0.7536\n",
      "Epoch 7/16\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.3868 - binary_accuracy: 0.9121\n",
      "Epoch 8/16\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 0.1463 - binary_accuracy: 0.9529\n",
      "Epoch 9/16\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 0.0702 - binary_accuracy: 0.9771\n",
      "Epoch 10/16\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0250 - binary_accuracy: 0.9929\n",
      "Epoch 11/16\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0082 - binary_accuracy: 0.9993\n",
      "Epoch 12/16\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0115 - binary_accuracy: 0.9971\n",
      "Epoch 13/16\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0030 - binary_accuracy: 1.0000\n",
      "Epoch 14/16\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0032 - binary_accuracy: 0.9993\n",
      "Epoch 15/16\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 16/16\n",
      "140/140 [==============================] - 49s 346ms/step - loss: 0.0024 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 207ms/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 0.8936 - binary_accuracy: 0.7433\n",
      "training start... epochs = 17\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_49 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_17 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/17\n",
      "140/140 [==============================] - 64s 364ms/step - loss: 0.6932 - binary_accuracy: 0.4993\n",
      "Epoch 2/17\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6927 - binary_accuracy: 0.5243\n",
      "Epoch 3/17\n",
      "140/140 [==============================] - 49s 351ms/step - loss: 0.6922 - binary_accuracy: 0.5379\n",
      "Epoch 4/17\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 0.6900 - binary_accuracy: 0.6043\n",
      "Epoch 5/17\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.6783 - binary_accuracy: 0.6929\n",
      "Epoch 6/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.5941 - binary_accuracy: 0.7750\n",
      "Epoch 7/17\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.3250 - binary_accuracy: 0.9014\n",
      "Epoch 8/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.1103 - binary_accuracy: 0.9657\n",
      "Epoch 9/17\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0439 - binary_accuracy: 0.9900\n",
      "Epoch 10/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0281 - binary_accuracy: 0.9936\n",
      "Epoch 11/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0122 - binary_accuracy: 0.9986\n",
      "Epoch 12/17\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0058 - binary_accuracy: 1.0000\n",
      "Epoch 13/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 14/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0027 - binary_accuracy: 1.0000\n",
      "Epoch 15/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 16/17\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 17/17\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 207ms/step - loss: 8.9942e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 0.9475 - binary_accuracy: 0.7583\n",
      "training start... epochs = 18\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_50 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Epoch 1/18\n",
      "140/140 [==============================] - 65s 369ms/step - loss: 0.6933 - binary_accuracy: 0.4893\n",
      "Epoch 2/18\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.6928 - binary_accuracy: 0.5214\n",
      "Epoch 3/18\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.6920 - binary_accuracy: 0.5493\n",
      "Epoch 4/18\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.6898 - binary_accuracy: 0.5929\n",
      "Epoch 5/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.6776 - binary_accuracy: 0.7079\n",
      "Epoch 6/18\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.5431 - binary_accuracy: 0.7993\n",
      "Epoch 7/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.2556 - binary_accuracy: 0.9129\n",
      "Epoch 8/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.1704 - binary_accuracy: 0.9450\n",
      "Epoch 9/18\n",
      "140/140 [==============================] - 48s 345ms/step - loss: 0.0822 - binary_accuracy: 0.9800\n",
      "Epoch 10/18\n",
      "140/140 [==============================] - 48s 346ms/step - loss: 0.0320 - binary_accuracy: 0.9943\n",
      "Epoch 11/18\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0167 - binary_accuracy: 0.9979\n",
      "Epoch 12/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0105 - binary_accuracy: 0.9993\n",
      "Epoch 13/18\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 0.0086 - binary_accuracy: 0.9986\n",
      "Epoch 14/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0098 - binary_accuracy: 0.9986\n",
      "Epoch 15/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0081 - binary_accuracy: 0.9993\n",
      "Epoch 16/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0061 - binary_accuracy: 0.9986\n",
      "Epoch 17/18\n",
      "140/140 [==============================] - 49s 347ms/step - loss: 0.0065 - binary_accuracy: 0.9993\n",
      "Epoch 18/18\n",
      "140/140 [==============================] - 48s 342ms/step - loss: 0.0059 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 206ms/step - loss: 0.0033 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 201ms/step - loss: 1.2686 - binary_accuracy: 0.7100\n",
      "training start... epochs = 19\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_51 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/19\n",
      "140/140 [==============================] - 64s 365ms/step - loss: 0.6933 - binary_accuracy: 0.4793\n",
      "Epoch 2/19\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6928 - binary_accuracy: 0.5236\n",
      "Epoch 3/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.6922 - binary_accuracy: 0.5571\n",
      "Epoch 4/19\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.6893 - binary_accuracy: 0.6407\n",
      "Epoch 5/19\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6701 - binary_accuracy: 0.6664\n",
      "Epoch 6/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.5405 - binary_accuracy: 0.8300\n",
      "Epoch 7/19\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.2454 - binary_accuracy: 0.9250\n",
      "Epoch 8/19\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0958 - binary_accuracy: 0.9729\n",
      "Epoch 9/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0404 - binary_accuracy: 0.9921\n",
      "Epoch 10/19\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0272 - binary_accuracy: 0.9943\n",
      "Epoch 11/19\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0084 - binary_accuracy: 0.9993\n",
      "Epoch 12/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0128 - binary_accuracy: 0.9986\n",
      "Epoch 13/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0033 - binary_accuracy: 1.0000\n",
      "Epoch 14/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 15/19\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 16/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 17/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0022 - binary_accuracy: 1.0000\n",
      "Epoch 18/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 6.4461e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/19\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 208ms/step - loss: 7.1455e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 0.9336 - binary_accuracy: 0.7600\n",
      "training start... epochs = 20\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_52 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "140/140 [==============================] - 66s 380ms/step - loss: 0.6933 - binary_accuracy: 0.4743\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6929 - binary_accuracy: 0.5157\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6922 - binary_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.6905 - binary_accuracy: 0.5829\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.6778 - binary_accuracy: 0.6800\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.5684 - binary_accuracy: 0.7714\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.2392 - binary_accuracy: 0.9307\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0881 - binary_accuracy: 0.9779\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0390 - binary_accuracy: 0.9921\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0210 - binary_accuracy: 0.9964\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0160 - binary_accuracy: 0.9957\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.0039 - binary_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0037 - binary_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 49s 352ms/step - loss: 0.0093 - binary_accuracy: 0.9986\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 9.3737e-04 - binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 49s 348ms/step - loss: 7.5837e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 49s 349ms/step - loss: 6.4508e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 49s 350ms/step - loss: 0.0139 - binary_accuracy: 0.9971\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 206ms/step - loss: 0.0062 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 0.7838 - binary_accuracy: 0.7050\n",
      "training start... epochs = 21\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_53 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_21 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "140/140 [==============================] - 64s 368ms/step - loss: 0.6932 - binary_accuracy: 0.5114\n",
      "Epoch 2/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.6927 - binary_accuracy: 0.5307\n",
      "Epoch 3/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.6918 - binary_accuracy: 0.5514\n",
      "Epoch 4/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.6898 - binary_accuracy: 0.6043\n",
      "Epoch 5/21\n",
      "140/140 [==============================] - 49s 353ms/step - loss: 0.6754 - binary_accuracy: 0.6921\n",
      "Epoch 6/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.5287 - binary_accuracy: 0.7993\n",
      "Epoch 7/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.2621 - binary_accuracy: 0.9114\n",
      "Epoch 8/21\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.0871 - binary_accuracy: 0.9793\n",
      "Epoch 9/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0396 - binary_accuracy: 0.9936\n",
      "Epoch 10/21\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0231 - binary_accuracy: 0.9964\n",
      "Epoch 11/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0138 - binary_accuracy: 0.9993\n",
      "Epoch 12/21\n",
      "140/140 [==============================] - 50s 357ms/step - loss: 0.0157 - binary_accuracy: 0.9986\n",
      "Epoch 13/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0086 - binary_accuracy: 0.9993\n",
      "Epoch 14/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0075 - binary_accuracy: 0.9993\n",
      "Epoch 15/21\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0071 - binary_accuracy: 0.9993\n",
      "Epoch 16/21\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.0109 - binary_accuracy: 0.9971\n",
      "Epoch 17/21\n",
      "140/140 [==============================] - 50s 356ms/step - loss: 0.0182 - binary_accuracy: 0.9964\n",
      "Epoch 18/21\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.0061 - binary_accuracy: 0.9993\n",
      "Epoch 19/21\n",
      "140/140 [==============================] - 50s 354ms/step - loss: 0.0061 - binary_accuracy: 0.9993\n",
      "Epoch 20/21\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0083 - binary_accuracy: 0.9986\n",
      "Epoch 21/21\n",
      "140/140 [==============================] - 50s 355ms/step - loss: 0.0063 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 206ms/step - loss: 0.0052 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 1.0692 - binary_accuracy: 0.7400\n",
      "training start... epochs = 22\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_54 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_22 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/22\n",
      "140/140 [==============================] - 66s 380ms/step - loss: 0.6933 - binary_accuracy: 0.4850\n",
      "Epoch 2/22\n",
      "140/140 [==============================] - 51s 362ms/step - loss: 0.6929 - binary_accuracy: 0.5136\n",
      "Epoch 3/22\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.6920 - binary_accuracy: 0.5836\n",
      "Epoch 4/22\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.6896 - binary_accuracy: 0.6107\n",
      "Epoch 5/22\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.6831 - binary_accuracy: 0.6400\n",
      "Epoch 6/22\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.6046 - binary_accuracy: 0.7343\n",
      "Epoch 7/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.4935 - binary_accuracy: 0.8021\n",
      "Epoch 8/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.3610 - binary_accuracy: 0.8929\n",
      "Epoch 9/22\n",
      "140/140 [==============================] - 50s 357ms/step - loss: 0.2193 - binary_accuracy: 0.9321\n",
      "Epoch 10/22\n",
      "140/140 [==============================] - 50s 357ms/step - loss: 0.1206 - binary_accuracy: 0.9707\n",
      "Epoch 11/22\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.0577 - binary_accuracy: 0.9857\n",
      "Epoch 12/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0344 - binary_accuracy: 0.9936\n",
      "Epoch 13/22\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0183 - binary_accuracy: 0.9971\n",
      "Epoch 14/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0268 - binary_accuracy: 0.9957\n",
      "Epoch 15/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0074 - binary_accuracy: 1.0000\n",
      "Epoch 16/22\n",
      "140/140 [==============================] - 50s 357ms/step - loss: 0.0086 - binary_accuracy: 0.9993\n",
      "Epoch 17/22\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 18/22\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 19/22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 20/22\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0137 - binary_accuracy: 0.9957\n",
      "Epoch 21/22\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 22/22\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 209ms/step - loss: 8.3273e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 206ms/step - loss: 0.9539 - binary_accuracy: 0.7683\n",
      "training start... epochs = 23\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_55 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_23 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "140/140 [==============================] - 67s 388ms/step - loss: 0.6933 - binary_accuracy: 0.4979\n",
      "Epoch 2/23\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.6930 - binary_accuracy: 0.5221\n",
      "Epoch 3/23\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.6922 - binary_accuracy: 0.5500\n",
      "Epoch 4/23\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.6910 - binary_accuracy: 0.5864\n",
      "Epoch 5/23\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.6857 - binary_accuracy: 0.6479\n",
      "Epoch 6/23\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.6303 - binary_accuracy: 0.7500\n",
      "Epoch 7/23\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.3416 - binary_accuracy: 0.8914\n",
      "Epoch 8/23\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.1318 - binary_accuracy: 0.9607\n",
      "Epoch 9/23\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0519 - binary_accuracy: 0.9886\n",
      "Epoch 10/23\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0268 - binary_accuracy: 0.9936\n",
      "Epoch 11/23\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0116 - binary_accuracy: 0.9993\n",
      "Epoch 12/23\n",
      "140/140 [==============================] - 50s 358ms/step - loss: 0.0157 - binary_accuracy: 0.9979\n",
      "Epoch 13/23\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0122 - binary_accuracy: 0.9979\n",
      "Epoch 14/23\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0074 - binary_accuracy: 0.9993\n",
      "Epoch 15/23\n",
      "140/140 [==============================] - 51s 362ms/step - loss: 0.0132 - binary_accuracy: 0.9979\n",
      "Epoch 16/23\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.0061 - binary_accuracy: 0.9993\n",
      "Epoch 17/23\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.0054 - binary_accuracy: 0.9993\n",
      "Epoch 18/23\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.0054 - binary_accuracy: 0.9993\n",
      "Epoch 19/23\n",
      "140/140 [==============================] - 50s 360ms/step - loss: 0.0034 - binary_accuracy: 0.9993\n",
      "Epoch 20/23\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0036 - binary_accuracy: 0.9993\n",
      "Epoch 21/23\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0028 - binary_accuracy: 0.9993\n",
      "Epoch 22/23\n",
      "140/140 [==============================] - 51s 361ms/step - loss: 0.0017 - binary_accuracy: 0.9993\n",
      "Epoch 23/23\n",
      "140/140 [==============================] - 50s 359ms/step - loss: 0.0074 - binary_accuracy: 0.9986\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 206ms/step - loss: 0.0022 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 1.0763 - binary_accuracy: 0.7417\n",
      "training start... epochs = 24\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_56 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_24 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/24\n",
      "140/140 [==============================] - 69s 400ms/step - loss: 0.6934 - binary_accuracy: 0.5014\n",
      "Epoch 2/24\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.6930 - binary_accuracy: 0.5357\n",
      "Epoch 3/24\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6924 - binary_accuracy: 0.5364\n",
      "Epoch 4/24\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.6904 - binary_accuracy: 0.5821\n",
      "Epoch 5/24\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.6826 - binary_accuracy: 0.6914\n",
      "Epoch 6/24\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.6248 - binary_accuracy: 0.7586\n",
      "Epoch 7/24\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.3946 - binary_accuracy: 0.8486\n",
      "Epoch 8/24\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.1379 - binary_accuracy: 0.9636\n",
      "Epoch 9/24\n",
      "140/140 [==============================] - 52s 368ms/step - loss: 0.0851 - binary_accuracy: 0.9807\n",
      "Epoch 10/24\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0203 - binary_accuracy: 0.9964\n",
      "Epoch 11/24\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0128 - binary_accuracy: 0.9979\n",
      "Epoch 12/24\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0122 - binary_accuracy: 0.9993\n",
      "Epoch 13/24\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0070 - binary_accuracy: 0.9993\n",
      "Epoch 14/24\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0071 - binary_accuracy: 0.9993\n",
      "Epoch 15/24\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0062 - binary_accuracy: 0.9993\n",
      "Epoch 16/24\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0085 - binary_accuracy: 0.9986\n",
      "Epoch 17/24\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0044 - binary_accuracy: 0.9993\n",
      "Epoch 18/24\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0049 - binary_accuracy: 0.9993\n",
      "Epoch 19/24\n",
      "140/140 [==============================] - 51s 364ms/step - loss: 0.0038 - binary_accuracy: 0.9993\n",
      "Epoch 20/24\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 0.0035 - binary_accuracy: 0.9993\n",
      "Epoch 21/24\n",
      "140/140 [==============================] - 51s 364ms/step - loss: 0.0282 - binary_accuracy: 0.9893\n",
      "Epoch 22/24\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0031 - binary_accuracy: 0.9993\n",
      "Epoch 23/24\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0071 - binary_accuracy: 0.9979\n",
      "Epoch 24/24\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.0046 - binary_accuracy: 0.9986\n",
      "evaluating...\n",
      "140/140 [==============================] - 32s 205ms/step - loss: 0.0017 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 0.9788 - binary_accuracy: 0.7383\n",
      "training start... epochs = 25\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_57 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "140/140 [==============================] - 70s 404ms/step - loss: 0.6932 - binary_accuracy: 0.4943\n",
      "Epoch 2/25\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.6929 - binary_accuracy: 0.5307\n",
      "Epoch 3/25\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6923 - binary_accuracy: 0.5621\n",
      "Epoch 4/25\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.6905 - binary_accuracy: 0.6143\n",
      "Epoch 5/25\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.7133 - binary_accuracy: 0.6400\n",
      "Epoch 6/25\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6851 - binary_accuracy: 0.5429\n",
      "Epoch 7/25\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.6741 - binary_accuracy: 0.6186\n",
      "Epoch 8/25\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.5986 - binary_accuracy: 0.7879\n",
      "Epoch 9/25\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.3631 - binary_accuracy: 0.9057\n",
      "Epoch 10/25\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.1528 - binary_accuracy: 0.9614\n",
      "Epoch 11/25\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0862 - binary_accuracy: 0.9757\n",
      "Epoch 12/25\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0427 - binary_accuracy: 0.9929\n",
      "Epoch 13/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0181 - binary_accuracy: 0.9979\n",
      "Epoch 14/25\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0150 - binary_accuracy: 0.9979\n",
      "Epoch 15/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0096 - binary_accuracy: 0.9993\n",
      "Epoch 16/25\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0079 - binary_accuracy: 0.9993\n",
      "Epoch 17/25\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0065 - binary_accuracy: 0.9993\n",
      "Epoch 18/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0064 - binary_accuracy: 0.9986\n",
      "Epoch 19/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0165 - binary_accuracy: 0.9957\n",
      "Epoch 20/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0059 - binary_accuracy: 0.9993\n",
      "Epoch 21/25\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0054 - binary_accuracy: 0.9993\n",
      "Epoch 22/25\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0066 - binary_accuracy: 0.9993\n",
      "Epoch 23/25\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0051 - binary_accuracy: 0.9993\n",
      "Epoch 24/25\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0096 - binary_accuracy: 0.9986\n",
      "Epoch 25/25\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0048 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 209ms/step - loss: 0.0039 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 205ms/step - loss: 0.9253 - binary_accuracy: 0.7267\n",
      "training start... epochs = 26\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_58 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_26 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/26\n",
      "140/140 [==============================] - 70s 405ms/step - loss: 0.6933 - binary_accuracy: 0.4864\n",
      "Epoch 2/26\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.6929 - binary_accuracy: 0.5071\n",
      "Epoch 3/26\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.6923 - binary_accuracy: 0.5321\n",
      "Epoch 4/26\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.6909 - binary_accuracy: 0.6029\n",
      "Epoch 5/26\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.6847 - binary_accuracy: 0.6486\n",
      "Epoch 6/26\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 0.6285 - binary_accuracy: 0.7429\n",
      "Epoch 7/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.4148 - binary_accuracy: 0.8571\n",
      "Epoch 8/26\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.2026 - binary_accuracy: 0.9350\n",
      "Epoch 9/26\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.1092 - binary_accuracy: 0.9736\n",
      "Epoch 10/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0435 - binary_accuracy: 0.9914\n",
      "Epoch 11/26\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.0405 - binary_accuracy: 0.9914\n",
      "Epoch 12/26\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.0893 - binary_accuracy: 0.9750\n",
      "Epoch 13/26\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0074 - binary_accuracy: 0.9993\n",
      "Epoch 14/26\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.0042 - binary_accuracy: 1.0000\n",
      "Epoch 15/26\n",
      "140/140 [==============================] - 51s 362ms/step - loss: 0.0025 - binary_accuracy: 1.0000\n",
      "Epoch 16/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0045 - binary_accuracy: 0.9986\n",
      "Epoch 17/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 18/26\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 19/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 20/26\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 7.3018e-04 - binary_accuracy: 1.0000\n",
      "Epoch 21/26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 51s 368ms/step - loss: 7.1521e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/26\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 23/26\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 7.3131e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/26\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 4.9144e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/26\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 3.6718e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/26\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 3.6375e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 207ms/step - loss: 2.8130e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 1.1654 - binary_accuracy: 0.7450\n",
      "training start... epochs = 27\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_59 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_27 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/27\n",
      "140/140 [==============================] - 70s 402ms/step - loss: 0.6932 - binary_accuracy: 0.4986\n",
      "Epoch 2/27\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 0.6927 - binary_accuracy: 0.5479\n",
      "Epoch 3/27\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.6922 - binary_accuracy: 0.5650\n",
      "Epoch 4/27\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.6901 - binary_accuracy: 0.6150\n",
      "Epoch 5/27\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.6802 - binary_accuracy: 0.6807\n",
      "Epoch 6/27\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 0.5893 - binary_accuracy: 0.7479\n",
      "Epoch 7/27\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.3199 - binary_accuracy: 0.8793\n",
      "Epoch 8/27\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.1252 - binary_accuracy: 0.9629\n",
      "Epoch 9/27\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0584 - binary_accuracy: 0.9850\n",
      "Epoch 10/27\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0237 - binary_accuracy: 0.9964\n",
      "Epoch 11/27\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0154 - binary_accuracy: 0.9971\n",
      "Epoch 12/27\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 0.0043 - binary_accuracy: 1.0000\n",
      "Epoch 13/27\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 14/27\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 15/27\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0020 - binary_accuracy: 1.0000\n",
      "Epoch 16/27\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 17/27\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0060 - binary_accuracy: 0.9986\n",
      "Epoch 18/27\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0100 - binary_accuracy: 0.9993\n",
      "Epoch 19/27\n",
      "140/140 [==============================] - 52s 368ms/step - loss: 7.6594e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/27\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 4.8123e-04 - binary_accuracy: 1.0000\n",
      "Epoch 21/27\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 4.0679e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/27\n",
      "140/140 [==============================] - 51s 364ms/step - loss: 3.1065e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/27\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 4.0885e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/27\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 2.8678e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/27\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 2.6590e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/27\n",
      "140/140 [==============================] - 51s 363ms/step - loss: 2.2378e-04 - binary_accuracy: 1.0000\n",
      "Epoch 27/27\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 1.7421e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 207ms/step - loss: 2.0832e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 205ms/step - loss: 1.3245 - binary_accuracy: 0.7533\n",
      "training start... epochs = 28\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_60 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_28 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "140/140 [==============================] - 70s 400ms/step - loss: 0.6930 - binary_accuracy: 0.5064\n",
      "Epoch 2/28\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 0.6928 - binary_accuracy: 0.5050\n",
      "Epoch 3/28\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.6917 - binary_accuracy: 0.5507\n",
      "Epoch 4/28\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6852 - binary_accuracy: 0.6650\n",
      "Epoch 5/28\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6213 - binary_accuracy: 0.7614\n",
      "Epoch 6/28\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 0.3879 - binary_accuracy: 0.8479\n",
      "Epoch 7/28\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.2045 - binary_accuracy: 0.9386\n",
      "Epoch 8/28\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 0.2007 - binary_accuracy: 0.9314\n",
      "Epoch 9/28\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.1009 - binary_accuracy: 0.9829\n",
      "Epoch 10/28\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0446 - binary_accuracy: 0.9907\n",
      "Epoch 11/28\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0342 - binary_accuracy: 0.9914\n",
      "Epoch 12/28\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0232 - binary_accuracy: 0.9957\n",
      "Epoch 13/28\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0151 - binary_accuracy: 0.9964\n",
      "Epoch 14/28\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0107 - binary_accuracy: 0.9986\n",
      "Epoch 15/28\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0041 - binary_accuracy: 1.0000\n",
      "Epoch 16/28\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0554 - binary_accuracy: 0.9857\n",
      "Epoch 17/28\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 18/28\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 19/28\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0086 - binary_accuracy: 0.9993\n",
      "Epoch 20/28\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0018 - binary_accuracy: 1.0000\n",
      "Epoch 21/28\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 22/28\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 23/28\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0016 - binary_accuracy: 1.0000\n",
      "Epoch 24/28\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 9.0972e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/28\n",
      "140/140 [==============================] - 52s 368ms/step - loss: 0.0067 - binary_accuracy: 0.9993\n",
      "Epoch 26/28\n",
      "140/140 [==============================] - 52s 368ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 27/28\n",
      "140/140 [==============================] - 51s 365ms/step - loss: 6.3483e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/28\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 4.5335e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 206ms/step - loss: 3.5732e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 1.0940 - binary_accuracy: 0.7633\n",
      "training start... epochs = 29\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_61 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_29 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/29\n",
      "140/140 [==============================] - 71s 409ms/step - loss: 0.6933 - binary_accuracy: 0.4914\n",
      "Epoch 2/29\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.6929 - binary_accuracy: 0.5343\n",
      "Epoch 3/29\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 0.6918 - binary_accuracy: 0.5286\n",
      "Epoch 4/29\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.6870 - binary_accuracy: 0.6557\n",
      "Epoch 5/29\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.6239 - binary_accuracy: 0.7757\n",
      "Epoch 6/29\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.3309 - binary_accuracy: 0.8893\n",
      "Epoch 7/29\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0996 - binary_accuracy: 0.9736\n",
      "Epoch 8/29\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.0499 - binary_accuracy: 0.9907\n",
      "Epoch 9/29\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0180 - binary_accuracy: 0.9979\n",
      "Epoch 10/29\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0085 - binary_accuracy: 0.9986\n",
      "Epoch 11/29\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 12/29\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.0023 - binary_accuracy: 1.0000\n",
      "Epoch 13/29\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 14/29\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 15/29\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0091 - binary_accuracy: 0.9986\n",
      "Epoch 16/29\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 8.3137e-04 - binary_accuracy: 1.0000\n",
      "Epoch 17/29\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0048 - binary_accuracy: 0.9986\n",
      "Epoch 18/29\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 5.8775e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/29\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 4.3845e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/29\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0019 - binary_accuracy: 1.0000\n",
      "Epoch 21/29\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0011 - binary_accuracy: 1.0000\n",
      "Epoch 22/29\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 2.3417e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/29\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 2.5897e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/29\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0176 - binary_accuracy: 0.9957\n",
      "Epoch 25/29\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 1.9710e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/29\n",
      "140/140 [==============================] - 51s 367ms/step - loss: 1.8981e-04 - binary_accuracy: 1.0000\n",
      "Epoch 27/29\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 1.5916e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/29\n",
      "140/140 [==============================] - 51s 368ms/step - loss: 1.4053e-04 - binary_accuracy: 1.0000\n",
      "Epoch 29/29\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 1.2066e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 207ms/step - loss: 1.2487e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 202ms/step - loss: 1.3472 - binary_accuracy: 0.7467\n",
      "training start... epochs = 30\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_62 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_30 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "140/140 [==============================] - 72s 408ms/step - loss: 0.6932 - binary_accuracy: 0.4971\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.6927 - binary_accuracy: 0.5150\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.6920 - binary_accuracy: 0.5600\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.6892 - binary_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.7326 - binary_accuracy: 0.5664\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6874 - binary_accuracy: 0.5514\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 53s 377ms/step - loss: 0.6756 - binary_accuracy: 0.5879\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.5956 - binary_accuracy: 0.7621\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.3915 - binary_accuracy: 0.8907\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.2089 - binary_accuracy: 0.9550\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.1035 - binary_accuracy: 0.9743\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0811 - binary_accuracy: 0.9786\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0389 - binary_accuracy: 0.9964\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.0213 - binary_accuracy: 0.9986\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0167 - binary_accuracy: 0.9979\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0120 - binary_accuracy: 0.9993\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0092 - binary_accuracy: 0.9993\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.0077 - binary_accuracy: 0.9993\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.0291 - binary_accuracy: 0.9929\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0082 - binary_accuracy: 0.9993\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 0.0067 - binary_accuracy: 0.9993\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0060 - binary_accuracy: 0.9993\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0053 - binary_accuracy: 0.9993\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 0.0073 - binary_accuracy: 0.9979\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 51s 366ms/step - loss: 0.0059 - binary_accuracy: 0.9993\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 0.0051 - binary_accuracy: 0.9993\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 52s 370ms/step - loss: 0.0047 - binary_accuracy: 0.9993\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0047 - binary_accuracy: 0.9993\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 0.0046 - binary_accuracy: 0.9993\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 0.0040 - binary_accuracy: 0.9993\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 208ms/step - loss: 0.0038 - binary_accuracy: 0.9993\n",
      "60/60 [==============================] - 12s 203ms/step - loss: 1.0263 - binary_accuracy: 0.7450\n",
      "training start... epochs = 31\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_63 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_31 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/31\n",
      "140/140 [==============================] - 72s 416ms/step - loss: 0.6932 - binary_accuracy: 0.4921\n",
      "Epoch 2/31\n",
      "140/140 [==============================] - 54s 387ms/step - loss: 0.6927 - binary_accuracy: 0.5100\n",
      "Epoch 3/31\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.6923 - binary_accuracy: 0.5464\n",
      "Epoch 4/31\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.6902 - binary_accuracy: 0.5957\n",
      "Epoch 5/31\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.6782 - binary_accuracy: 0.7021\n",
      "Epoch 6/31\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 0.6194 - binary_accuracy: 0.7543\n",
      "Epoch 7/31\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 0.4504 - binary_accuracy: 0.9057\n",
      "Epoch 8/31\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.2247 - binary_accuracy: 0.9479\n",
      "Epoch 9/31\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0988 - binary_accuracy: 0.9729\n",
      "Epoch 10/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0476 - binary_accuracy: 0.9886\n",
      "Epoch 11/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0263 - binary_accuracy: 0.9943\n",
      "Epoch 12/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0221 - binary_accuracy: 0.9950\n",
      "Epoch 13/31\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.0073 - binary_accuracy: 0.9986\n",
      "Epoch 14/31\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 15/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 0.0013 - binary_accuracy: 1.0000\n",
      "Epoch 16/31\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 9.1083e-04 - binary_accuracy: 1.0000\n",
      "Epoch 17/31\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 6.5994e-04 - binary_accuracy: 1.0000\n",
      "Epoch 18/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 6.8411e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/31\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0201 - binary_accuracy: 0.9936\n",
      "Epoch 20/31\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 21/31\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 5.3369e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/31\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 3.5942e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/31\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 3.2183e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/31\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 2.1708e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/31\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 1.9050e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/31\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 1.9478e-04 - binary_accuracy: 1.0000\n",
      "Epoch 27/31\n",
      "140/140 [==============================] - 52s 372ms/step - loss: 1.6001e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/31\n",
      "140/140 [==============================] - 52s 375ms/step - loss: 1.6141e-04 - binary_accuracy: 1.0000\n",
      "Epoch 29/31\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 1.0464e-04 - binary_accuracy: 1.0000\n",
      "Epoch 30/31\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 1.9623e-04 - binary_accuracy: 1.0000\n",
      "Epoch 31/31\n",
      "140/140 [==============================] - 52s 369ms/step - loss: 1.9445e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 208ms/step - loss: 4.8344e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 1.2666 - binary_accuracy: 0.7250\n",
      "training start... epochs = 32\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_64 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_32 (Bidirecti  (None, 64)               16640     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/32\n",
      "140/140 [==============================] - 73s 421ms/step - loss: 0.6932 - binary_accuracy: 0.4993\n",
      "Epoch 2/32\n",
      "140/140 [==============================] - 54s 387ms/step - loss: 0.6928 - binary_accuracy: 0.5207\n",
      "Epoch 3/32\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.6921 - binary_accuracy: 0.5636\n",
      "Epoch 4/32\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.6896 - binary_accuracy: 0.6229\n",
      "Epoch 5/32\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.6727 - binary_accuracy: 0.7121\n",
      "Epoch 6/32\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.5126 - binary_accuracy: 0.8286\n",
      "Epoch 7/32\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 0.2275 - binary_accuracy: 0.9243\n",
      "Epoch 8/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0891 - binary_accuracy: 0.9779\n",
      "Epoch 9/32\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0318 - binary_accuracy: 0.9943\n",
      "Epoch 10/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0140 - binary_accuracy: 0.9979\n",
      "Epoch 11/32\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 0.0232 - binary_accuracy: 0.9936\n",
      "Epoch 12/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0047 - binary_accuracy: 1.0000\n",
      "Epoch 13/32\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0028 - binary_accuracy: 1.0000\n",
      "Epoch 14/32\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.0098 - binary_accuracy: 0.9986\n",
      "Epoch 15/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0084 - binary_accuracy: 0.9993\n",
      "Epoch 16/32\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 0.0021 - binary_accuracy: 1.0000\n",
      "Epoch 17/32\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 0.0014 - binary_accuracy: 1.0000\n",
      "Epoch 18/32\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 7.1936e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/32\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 0.0042 - binary_accuracy: 0.9986\n",
      "Epoch 20/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0010 - binary_accuracy: 1.0000\n",
      "Epoch 21/32\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 6.6789e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/32\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 4.2083e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/32\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 4.4835e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/32\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 4.2219e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/32\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 3.8325e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/32\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 5.4784e-04 - binary_accuracy: 1.0000\n",
      "Epoch 27/32\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 4.7848e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/32\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 1.9846e-04 - binary_accuracy: 1.0000\n",
      "Epoch 29/32\n",
      "140/140 [==============================] - 52s 371ms/step - loss: 1.7944e-04 - binary_accuracy: 1.0000\n",
      "Epoch 30/32\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 2.1122e-04 - binary_accuracy: 1.0000\n",
      "Epoch 31/32\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 1.3783e-04 - binary_accuracy: 1.0000\n",
      "Epoch 32/32\n",
      "140/140 [==============================] - 52s 373ms/step - loss: 0.0054 - binary_accuracy: 0.9971\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 208ms/step - loss: 0.0024 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 1.4047 - binary_accuracy: 0.5783\n",
      "training start... epochs = 33\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_65 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_33 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/33\n",
      "140/140 [==============================] - 73s 421ms/step - loss: 0.6932 - binary_accuracy: 0.5007\n",
      "Epoch 2/33\n",
      "140/140 [==============================] - 55s 396ms/step - loss: 0.6928 - binary_accuracy: 0.5057\n",
      "Epoch 3/33\n",
      "140/140 [==============================] - 55s 391ms/step - loss: 0.6921 - binary_accuracy: 0.5479\n",
      "Epoch 4/33\n",
      "140/140 [==============================] - 55s 393ms/step - loss: 0.6895 - binary_accuracy: 0.5964\n",
      "Epoch 5/33\n",
      "140/140 [==============================] - 54s 387ms/step - loss: 0.6613 - binary_accuracy: 0.6900\n",
      "Epoch 6/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.5803 - binary_accuracy: 0.7507\n",
      "Epoch 7/33\n",
      "140/140 [==============================] - 55s 390ms/step - loss: 0.3436 - binary_accuracy: 0.8693\n",
      "Epoch 8/33\n",
      "140/140 [==============================] - 55s 391ms/step - loss: 0.1631 - binary_accuracy: 0.9521\n",
      "Epoch 9/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.0895 - binary_accuracy: 0.9807\n",
      "Epoch 10/33\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.0424 - binary_accuracy: 0.9907\n",
      "Epoch 11/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.0367 - binary_accuracy: 0.9914\n",
      "Epoch 12/33\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0169 - binary_accuracy: 0.9971\n",
      "Epoch 13/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.0135 - binary_accuracy: 0.9971\n",
      "Epoch 14/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.0129 - binary_accuracy: 0.9979\n",
      "Epoch 15/33\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.0044 - binary_accuracy: 0.9993\n",
      "Epoch 16/33\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0045 - binary_accuracy: 1.0000\n",
      "Epoch 17/33\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.0012 - binary_accuracy: 1.0000\n",
      "Epoch 18/33\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 9.6878e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.0047 - binary_accuracy: 0.9986\n",
      "Epoch 20/33\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 8.6795e-04 - binary_accuracy: 1.0000\n",
      "Epoch 21/33\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 5.5373e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/33\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 4.4572e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/33\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.0017 - binary_accuracy: 1.0000\n",
      "Epoch 24/33\n",
      "140/140 [==============================] - 54s 388ms/step - loss: 4.5678e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 3.5997e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/33\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.0018 - binary_accuracy: 0.9993\n",
      "Epoch 27/33\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 3.9132e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/33\n",
      "140/140 [==============================] - 54s 389ms/step - loss: 4.1869e-04 - binary_accuracy: 1.0000\n",
      "Epoch 29/33\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 2.6977e-04 - binary_accuracy: 1.0000\n",
      "Epoch 30/33\n",
      "140/140 [==============================] - 52s 374ms/step - loss: 2.0821e-04 - binary_accuracy: 1.0000\n",
      "Epoch 31/33\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 1.7319e-04 - binary_accuracy: 1.0000\n",
      "Epoch 32/33\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 0.1066 - binary_accuracy: 0.9657\n",
      "Epoch 33/33\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 0.0203 - binary_accuracy: 0.9971\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 210ms/step - loss: 5.7105e-04 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 205ms/step - loss: 1.0115 - binary_accuracy: 0.7283\n",
      "training start... epochs = 34\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_66 (Embedding)    (None, 753, 32)           1244800   \n",
      "                                                                 \n",
      " bidirectional_34 (Bidirecti  (None, 64)               16640     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,278,337\n",
      "Trainable params: 1,278,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/34\n",
      "140/140 [==============================] - 73s 422ms/step - loss: 0.6932 - binary_accuracy: 0.5057\n",
      "Epoch 2/34\n",
      "140/140 [==============================] - 54s 388ms/step - loss: 0.6929 - binary_accuracy: 0.5057\n",
      "Epoch 3/34\n",
      "140/140 [==============================] - 54s 388ms/step - loss: 0.6920 - binary_accuracy: 0.5257\n",
      "Epoch 4/34\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 0.6884 - binary_accuracy: 0.6379\n",
      "Epoch 5/34\n",
      "140/140 [==============================] - 54s 386ms/step - loss: 0.6562 - binary_accuracy: 0.6993\n",
      "Epoch 6/34\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.4510 - binary_accuracy: 0.8593\n",
      "Epoch 7/34\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 0.1626 - binary_accuracy: 0.9507\n",
      "Epoch 8/34\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 0.0586 - binary_accuracy: 0.9843\n",
      "Epoch 9/34\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 0.0238 - binary_accuracy: 0.9957\n",
      "Epoch 10/34\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0087 - binary_accuracy: 0.9993\n",
      "Epoch 11/34\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 0.0034 - binary_accuracy: 1.0000\n",
      "Epoch 12/34\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 0.0026 - binary_accuracy: 1.0000\n",
      "Epoch 13/34\n",
      "140/140 [==============================] - 54s 383ms/step - loss: 0.0015 - binary_accuracy: 1.0000\n",
      "Epoch 14/34\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 0.0454 - binary_accuracy: 0.9893\n",
      "Epoch 15/34\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 8.1488e-04 - binary_accuracy: 1.0000\n",
      "Epoch 16/34\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 5.0326e-04 - binary_accuracy: 1.0000\n",
      "Epoch 17/34\n",
      "140/140 [==============================] - 53s 381ms/step - loss: 5.3446e-04 - binary_accuracy: 1.0000\n",
      "Epoch 18/34\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 3.5664e-04 - binary_accuracy: 1.0000\n",
      "Epoch 19/34\n",
      "140/140 [==============================] - 54s 382ms/step - loss: 3.1193e-04 - binary_accuracy: 1.0000\n",
      "Epoch 20/34\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 6.0501e-04 - binary_accuracy: 1.0000\n",
      "Epoch 21/34\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 2.9442e-04 - binary_accuracy: 1.0000\n",
      "Epoch 22/34\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 2.1677e-04 - binary_accuracy: 1.0000\n",
      "Epoch 23/34\n",
      "140/140 [==============================] - 54s 385ms/step - loss: 5.6973e-04 - binary_accuracy: 1.0000\n",
      "Epoch 24/34\n",
      "140/140 [==============================] - 53s 382ms/step - loss: 1.7721e-04 - binary_accuracy: 1.0000\n",
      "Epoch 25/34\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 1.4654e-04 - binary_accuracy: 1.0000\n",
      "Epoch 26/34\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 2.4299e-04 - binary_accuracy: 1.0000\n",
      "Epoch 27/34\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 1.6588e-04 - binary_accuracy: 1.0000\n",
      "Epoch 28/34\n",
      "140/140 [==============================] - 54s 384ms/step - loss: 1.0695e-04 - binary_accuracy: 1.0000\n",
      "Epoch 29/34\n",
      "140/140 [==============================] - 53s 377ms/step - loss: 9.6395e-05 - binary_accuracy: 1.0000\n",
      "Epoch 30/34\n",
      "140/140 [==============================] - 53s 375ms/step - loss: 7.8860e-05 - binary_accuracy: 1.0000\n",
      "Epoch 31/34\n",
      "140/140 [==============================] - 53s 376ms/step - loss: 6.6495e-05 - binary_accuracy: 1.0000\n",
      "Epoch 32/34\n",
      "140/140 [==============================] - 53s 378ms/step - loss: 7.6972e-05 - binary_accuracy: 1.0000\n",
      "Epoch 33/34\n",
      "140/140 [==============================] - 53s 379ms/step - loss: 9.7263e-05 - binary_accuracy: 1.0000\n",
      "Epoch 34/34\n",
      "140/140 [==============================] - 53s 380ms/step - loss: 1.0546e-04 - binary_accuracy: 1.0000\n",
      "evaluating...\n",
      "140/140 [==============================] - 33s 209ms/step - loss: 7.8193e-05 - binary_accuracy: 1.0000\n",
      "60/60 [==============================] - 12s 204ms/step - loss: 1.4753 - binary_accuracy: 0.7367\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(13,35):\n",
    "    lstm_70_Bidirectional = fit_train_lstm_Bidirectional(pruned_padded_70[:1400], train_y, pruned_padded_70[1400:], test_y, L_70, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa44b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
